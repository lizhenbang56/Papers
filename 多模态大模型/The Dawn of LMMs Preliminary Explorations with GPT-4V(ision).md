- LMM 的黎明：GPT-4V(ision) 的初步探索
- The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)

# 摘要

大型多模态模型 (LMM) 通过视觉理解等多感官技能扩展大型语言模型 (LLM)，以实现更强大的通用智能。在本文中，我们分析了最新模型 GPT-4V(ision) [99 – 101, 1] 1 ，以加深对 LMM 的理解。分析重点关注 GPT-4V 可以执行的有趣任务，包括测试样本来探究 GPT-4V 功能的质量和通用性、其支持的输入和工作模式以及提示模型的有效方法。在探索 GPT-4V 的方法中，我们策划和组织了一系列精心设计的定性样本，涵盖各个领域和任务。对这些样本的观察表明，GPT-4V 在处理任意交错的多模态输入方面具有前所未有的能力，并且其功能的通用性共同使 GPT-4V 成为强大的多模态通用系统。此外，GPT-4V独特的理解输入图像上绘制的视觉标记的能力可以催生新的人机交互方法，例如视觉参考提示。我们在报告最后深入讨论了基于 GPT-4V 的系统的新兴应用场景和未来研究方向。我们希望这一初步探索能够激发未来对下一代多模态任务制定的研究，开发和增强 LMM 解决现实问题的新方法，并更好地理解多模态基础模型。最后，我们承认我们研究的模型完全是 OpenAI 创新工作的产物，其发展应该完全归功于他们。请参阅 GPT-4V 贡献论文 [101] 了解作者身份和信用归属： [https://cdn.openai.com/contributions/gpt-4v.pdf](https://cdn.openai.com/contributions/gpt-4v.pdf) 。

# 1 简介

## 1.1 动机和概述

大型语言模型 (LLM) [23,99,30,11,123,53] 的突破在各个领域和任务中表现出了卓越的多功能性和能力。该领域的下一个发展是大型多模态模型 (LMM)，旨在通过集成多感官技能来扩展 LLM 的功能，以实现更强大的通用智能。鉴于视觉在人类感官中的主导地位 [33, 58]，许多 LMM 研究都是从扩展视觉能力开始的。初步研究调查要么微调视觉编码器以与冻结的预训练 LLM [125,7,71,55,42,13,48,157,79,35,146] 保持一致，要么使用视觉语言模型进行转换法学硕士可以理解的文本描述的视觉输入[149,141,131,54,113,142]。然而，大多数现有模型[13,48,157,79,35,69]的模型和数据规模有限，可能限制了各种有趣能力的出现。因此，目前尚不清楚基于最先进的 LLM 开发的 LMM 的现状和新兴多模态能力如何，例如 GPT-4（无视觉）[99] 和 PaLM [30, 11] 。在本文中，我们报告了我们对 GPT-4V（早期版本）的初步探索，GPT-4V 是一种最先进的视觉 LMM，基于 SOTA LLM 构建，并使用大规模多模态数据进行训练。我们对 GPT-4V 的探索以以下问题为指导。 
1. GPT-4V支持哪些输入和工作模式？多模态模型的通用性不可避免地要求系统能够处理不同输入模态的任意组合。 GPT-4V 在理解和处理输入图像、子图像、文本、场景文本和视觉指针的任意组合方面表现出前所未有的能力。我们还证明，GPT-4V 很好地支持法学硕士中观察到的测试时技术，包括指令遵循 [102]、思路链 [136, 66]、上下文中的小样本学习 [23] 等
2. 2 . GPT-4V 在不同领域和任务上的能力的质量和通用性是什么？我们对涵盖广泛领域和任务的查询进行采样，以了解 GPT-4V 的功能，包括开放世界视觉理解、视觉描述、多模态知识、常识、场景文本理解、文档推理、编码、时间推理、抽象推理、情感理解， 还有很多。 GPT-4V 在许多实验领域表现出了令人印象深刻的人类水平的能力。 
3. GPT-4V的有效使用和提示方法有哪些？ GPT-4V 擅长理解像素空间编辑，例如在输入图像上绘制的视觉指针和场景文本。受这种功能的启发，我们讨论了“视觉参考提示”，它直接编辑输入图像来指示感兴趣的任务。视觉引用提示可以与其他图像和文本提示无缝地一起使用，为说明和示例演示提供细致入微的界面。 
4. 未来有哪些有前途的方向？鉴于 GPT-4V 跨领域和任务的强大能力，我们询问多模态学习以及更广泛的人工智能的下一步是什么。我们将我们的思考和探索分为两个角度，即需要关注的新兴新颖应用场景和基于 GPT-4V 的系统的未来研究方向。我们提出我们的初步探索以启发未来的研究。以上述问题为指导，我们全面整理并列出了我们探索的定性结果。该报告包含最少的定量基准结果，而是主要包含精选的有趣的定性示例。尽管不那么严格，但这种设计允许在固定容量下提供涵盖广泛领域、任务、工作模式和提示技术的更全面的分析。我们相信，这些有组织的探索将激发未来在新兴新颖应用、下一代多模式任务制定以及开发基于 LMM 的先进智能系统方面的工作。

## 1.2 我们探索 GPT-4V 的方法

本报告的目标。评估系统的标准方法是将其与一系列精心设计的数据集进行基准测试，每个数据集代表一个特定的领域和任务。挑战之一是一些现有基准可能不再适合评估 LMM。例如，8 LMM 的图像字幕输出比图像字幕基准数据集 [27] 中的基本事实要丰富得多，并且包含更详细的描述。还缺乏有关 GPT-4V 大规模预训练的公开信息，这可能违反某些现有数据集的训练测试设置并使这些基准数字无效。因此，将评估限制在现有基准和指标上可能会无意中缩小 GPT-4V 的评估范围。制定下一代评估任务和基准的综合列表将是理想的最终解决方案。然而，由于需要付出巨大的努力，我们将这些留作未来的工作。本文重点关注使用定性结果来代替定量基准测试，以了解 GPT-4V 的新功能和潜在的新兴用例。我们的目标是发现并预览 GPT-4V 可能已经具备的功能，尽管这些新颖的功能可能尚不完全可靠。我们希望这一系列的探索能够激发未来的研究，为下一代多模式任务建立定量基准，使现有基准现代化，进一步提高模型性能和系统可靠性，并在新兴用例中激发创新。接下来，我们将深入研究探索 GPT-4V 方法的核心设计。样本选择指导。本报告重点介绍定性结果以展示 GPT-4V 的潜在能力，而不是提供全面的定量基准结果。这自然引发了所展示示例的可靠性问题。本报告中的示例可能需要仔细的指令调整才能增强 GPT-4V 的相应功能。应该注意的是，一些复杂的情况可能仅适用于专门设计的提示。因此，所展示的功能可能无法在不同的样本中始终有效。本报告的主要目的不是仅展示可靠的功能，而是为读者提供我们发现的 GPT-4V 潜在功能的列表，否则这些功能可能会在几次不成功的试验后被忽视。样本选择以防止训练中仅仅记忆。定性报告 [24] 中的一个基本设计考虑因素是仅通过记忆训练样本的响应或根据指令和上下文示例的提示进行有根据的猜测来辨别模型的真实功能。我们仔细控制输入提示中的图像和文本，以防止它们在 GPT-4V 训练期间被看到。我们从头开始生成原始文本查询，并尝试使用无法在线访问或时间戳超过 2023 年 4 月的图像。我们将指出特定样本不符合此标准的实例，例如故意使用来自特定视觉的样本 -语言数据集。除了确保样本不可见之外，我们还将理由查询纳入流程中。这些查询旨在探测模型的推理过程，从而验证 GPT-4V 是否拥有预期功能。默认工作模式。正如后面第 3 节详细介绍的，GPT-4V 在不同的工作模式下都能有效工作，包括带指令的零样本学习、上下文中的少样本学习等。其中，本报告主要关注零样本指令调优，如反对上下文中的小样本学习。这种设计是为了防止上下文示例中潜在的信息泄漏。虽然上下文中的少数示例可以提高性能和可靠性，但它们并不能始终如一地产生新功能。因此，我们将零样本指定为演示的默认工作模式，并减少上下文示例的使用，以尽量减少示例对评估能力的影响。 

## 1.3 如何阅读本报告？

本报告记录了计算机视觉和视觉语言多模态领域的研究人员对 GPT-4V 的探索。它主要面向相关学科的研究人员，他们希望获得对 LMM 功能的定性印象并了解其与传统视觉语言模型的区别。该报告还为那些人工智能或计算机科学可能超出其专业范围的专业人士编写，以帮助他们概念化 LMM 可以在其不同专业领域内提高其熟练程度的方法。我们概述了该报告，围绕指导我们探索的**四个核心问题**。 
1. GPT-4V支持哪些输入和工作模式？
	- 第 2 节总结了 GPT-4V 支持的输入，并概述了其相应的用例。基于灵活的交错图像文本输入，
	- 第 3 节讨论了 GPT-4V 的不同工作模式，例如指令调整、上下文学习和其他紧急用途。本节介绍了使用和提示 GPT-4V 的新颖方式，旨在全面概述我们将在后续章节中如何使用 GPT-4V。 
2. GPT-4V 在不同领域和任务上的能力质量和通用性如何？对这个问题的探索占据了报告的很大一部分。
	- 第 4 节提供了涵盖广泛视觉和视觉语言场景的全面分析，包括不同领域的图像描述和识别、密集视觉理解、多模态知识、常识、场景文本理解、文档推理等等。我们还分离出一些新颖有趣的功能。
	- 第 6 节研究 GPT-4V 在时间、运动和视频理解方面的能力。
	- 第 7 节探讨抽象视觉理解和推理能力，
	- 第 8 节涵盖情感和情感理解。
3. GPT-4V的有效使用和提示方法有哪些？
	- 我们从第3节中介绍的工作模式和提示方法开始讨论这个问题。在第5节中，我们重点介绍了一种新颖的推广技术，即视觉引用提示，它在输入图像上绘制视觉指针和场景文本来提示GPT-4V 。我们在报告中通过实例演示了指导与实例演示相结合等灵活的提示方法。 
4. 未来有哪些有前途的方向？
	1. 第 9 节重点介绍 GPT-4V 促进的新颖用例。我们希望这些最初的例子能够启发未来的工作，设计新的任务设置并提出严格的基准。
	2. 第 10 节设想了可以基于 GPT-4V 构建的强大的未来系统，例如多模态插件、多模态链、自反射、自一致性和检索增强的 LMM 等。内容中，我们还提供了一个数字列表。该列表列举了报告中详细介绍的定性示例，作为帮助读者导航到他们感兴趣的场景的附加工具。 

# 2 GPT-4V 的输入模式 

本节总结了 GPT-4V 支持的输入，即，作为具有纯文本输入的单模型语言模型，可选地仅使用单个图像获取单个图像-文本对，以及获取交错图像-文本对可选地仅与多个图像输入。接下来我们重点介绍这些不同输入模式下的代表性用例。 

## 2.1 纯文本输入 

GPT-4V 强大的语言能力使其能够作为具有纯文本输入的有效单峰语言模型[38,108,23]。 GPT-4V 仅使用文本进行输入和输出操作，能够执行各种语言和编码任务。我们建议读者参考GPT-4技术报告[99]，全面深入地分析GPT-4V的语言和编码能力，以及与GPT-4（无视觉）的比较。 

## 2.2 单图文对 

GPT-4V是最新的大型多模态模型，以图像和文本作为输入生成文本输出。符合现有的通用视觉语言模型[9,81,73,8,70,122,120,155,28,83,45,74,57,64,72,132,29,140,41, 7, 128, 46, 40, 158, 69]，GPT-4V可以将单个图像文本对或单个图像作为输入来执行各种视觉和视觉语言任务，例如图像识别[37]、对象定位[153]、图像字幕[27]、视觉问答[12]、视觉对话[36]、密集字幕[62]等等。我们注意到，图像-文本对中的文本可以用作诸如“描述图像”之类的指令用于字幕，也可以用作查询输入（如视觉问答中的问题）。与现有技术相比，GPT-4V 的卓越智能体现在其显着增强的性能和通用性。第 4. 10 秒详细介绍了其在各个领域的多模式功能的综合分析。 2.3 交错图文输入 交错图文对 提示：根据菜单上的价格，我应该为桌上的啤酒付多少钱？这是菜单的照片。 GPT-4V：根据菜单，一瓶麦格纳啤酒的价格是6美元。由于桌子上有两瓶麦格纳啤酒，因此啤酒的总成本为 12 美元。提示：我缴了多少税？信息在哪里？ GPT-4V：在第一张收据中，您支付了 3.72 美元的税费。该信息位于收据底部。在第二张收据中，您支付了 42.23 美元的税费。该信息位于收据底部附近的“销售税”行下方。在第三张收据中，您支付了 4.58 美元的税费。该信息位于收据底部的“TAX”行下方。您总共为所有三张收据缴纳了 50.53 美元的税款。提示续 图 1：GPT-4V 可以处理多图像和交错图像文本输入。查看第 2.3 节了解详细讨论。 

## 2.3 交错的图像-文本输入 

GPT-4V 的通用性因其处理灵活的交错的图像-文本输入的能力而得到进一步增强。交错的图像文本输入可以以视觉为中心，例如带有简短问题或说明的多个图像，也可以以文本为中心，例如带有两个插入图像的长网页，或者图像和文本的平衡混合。这种混合输入模式为各种应用提供了灵活性。例如，它可以计算多个收据图像所缴纳的总税款，如图 1 所示。它还可以处理多个输入图像并提取查询信息。 GPT-4V 还可以有效地将交错图像-文本输入中的信息关联起来，例如查找菜单上的啤酒价格、计算啤酒数量以及返回总成本，如图 1 所示。 除了直接应用程序之外，还可以处理交错图像-文本输入作为上下文小样本学习和其他高级测试时提示技术的基本组成部分，从而进一步提高了 GPT-4V 的通用性。我们将在下一节（第 3 节）中演示这些有趣的新颖用法。

# 3 GPT-4V 的工作模式和提示技术

## 3.1 跟随文字说明 

跟随文字说明 提示：用由三个/六个/九个单词组成的句子描述图像。 GPT-4V： 三：海边餐桌 六：俯瞰大海的餐桌，配啤酒 九：户外海景餐桌，配啤酒 提示：缺失的图像会是什么样子？ GPT-4V：丢失的图像可能是菱形或星形的变体，如其他三幅图像中所示。它可以是具有不同图案或颜色的钻石，也可以是具有不同点数或颜色的星星。如果没有更多背景，很难确定，但它可能遵循与其他图像相同的主题。提示：为仅由字母“B”/“D”/“T”开头的单词组成的图像写一个句子。 GPT-4V：“B”：海滨酒吧拥有美丽的蓝色背景。 “D”：餐厅甲板展示令人愉悦的饮料，远处的码头。 “T”：充满热带宁静氛围的桌面露台。提示：这是排列成 2×2 矩阵的三个子图像。首先，查看第一列中左上角和左下角的两个图像。然后，根据左边两张图像找出第一列中的图案。接下来，使用找到的图案和右上角的图像来推断缺失的图形。最后，描述一下丢失的图像是什么样子的？ GPT-4V：第一列的模式是左下图像中的形状在左上图像中的形状的中心有一个点。因此，右下角缺失的图像将是一个中心有一个点的星星，与右上角的图像类似，但中心有一个点。提示：车速表的读数是多少？ GPT-V：速度计的速度约为每小时 95 英里。提示：车速表的读数是多少？要读取速度表，请观察表盘上的指针，该指针指向表盘外缘上以数字表示的当前速度。黄色是指针的颜色 GPT-V：速度约为 119 英里/小时，指针接近 120 英里/小时，但尚未完全达到 120 英里/小时。

图 2：GPT-4V 可以理解并遵循文本指令，以生成所需的文本输出或学习执行新任务。红色突出显示信息较少的答案。查看第 3.1 节了解详细讨论。 12 约束提示 GPT-4V: {"class": "D", "DLN": "D08954796", "DOB": "01/01/1974", "Name": "Jelani Sample", "Address": " 123 Main St, Phoenix, AZ 85007"，"EXP"："03/01/2024"，"ISS"："03/01/2016"，"性别"："M"，"HGT"："5-09 ", "WGT": "185 lbs", "EYES": "BRO", "HAIR": "N/A", "DONOR": "Y"} 提示：请阅读此图中的文字并返回信息采用以下 JSON 格式（注意 xxx 是占位符，如果图像中没有该信息，请改为“N/A”）。 {“班级”：xxx，“DLN”：xxx，“出生日期”：xxx，“姓名”：xxx，“地址”：xxx，“EXP”：xxx，“ISS”：xxx，“性别”：xxx，“ HGT”：xxx，“WGT”：xxx，“眼睛”：xxx，“头发”：xxx，“捐赠者”：xxx} GPT-4V：{“class”：“C”，“DLN”：“1234568”， “DOB”：“08/31/1977”，“姓名”：“Ima 持卡人”，“地址”：“2570 24th Street, Anytown, CA 95818”，“EXP”：“08/31/2014”，“ISS “：“08/31/2011”，“性别”：“F”，“HGT”：“5-05”，“WGT”：“125 磅”，“眼睛”：“BRN”，“头发”：“ BRN", "DONOR": "VETERAN"} 提示：请阅读该图片中的文字，并以以下 JSON 格式返回信息（注意 xxx 为占位符，如果图片中没有该信息，则输入“N/A” “ 反而）。 {“姓氏”：xxx，“名字”：xxx，“USCIS #”：xxx，“类别”：xxx，“出生国家”：xxx，“出生日期”：xxx，“性别”：xxx，“卡过期”：xxx，“居住时间”：xxx} GPT-4V：{“姓氏”：“STEVENS”，“名字”：“ICHIKA”，“USCIS 号”：“000-000-000”，“类别” ": "IR1"、"出生国家": "日本"、"出生日期": "1988 年 8 月 18 日"、"性别": "F"、"卡过期": "07/04/2027"、"居住自”：“07/05/2017”}秒。 3.1 以下文字说明 提示：请阅读该图片中的文字，并以以下 JSON 格式返回信息（注意 xxx 为占位符，如果图片中没有该信息，请填写“N/A”）。 {“班级”：xxx，“DLN”：xxx，“出生日期”：xxx，“姓名”：xxx，“地址”：xxx，“EXP”：xxx，“ISS”：xxx，“性别”：xxx，“ HGT": xxx, "WGT": xxx, "EYES": xxx, "HAIR": xxx, "DONOR": xxx} 图 3：约束提示以 JSON 格式返回。图像是样本的示例 ID。红色突出显示错误答案。查看第 3.1 节了解详细讨论。 13 良好性能条件 GPT-4V：图像中有 12 个苹果。提示：数一下图像中苹果的数量。让我们一步步思考。 GPT-4V：第 1 步：查看图像并识别所有苹果。第二步：开始一个一个地数苹果。第三步：确保不要漏掉任何一个苹果，也不要数同一个苹果两次。第四步：数完所有苹果后，仔细检查以确保计数正确。答案：图中有 12 个苹果。秒。 

## 3.1 按照文字说明 

提示：数一下图像中苹果的数量。注意：与上图所示相同的查询图像，调整大小以节省空间提示：计算图像中苹果的数量。让我们逐行数苹果。 GPT-4V: 第一行：4 个苹果 第二行：3 个苹果 第三行：4 个苹果 图像中苹果的总数：11 个苹果 注：与上图相同的查询图像，调整大小以节省空间 提示：计算图中苹果的数量图片。首先数一下有多少行苹果，然后数出每一行的苹果，最后相加得到总数。 GPT-4V：图像中有 3 行苹果。最上面一排有 5 个苹果。中间一排有4个苹果。最下面一行有 6 个苹果。因此，图像中苹果的总数为 5 + 4 + 6 = 15 个苹果。注意：与上图所示的相同查询图像，已调整大小以节省空间提示：您是计算图像中事物的专家。让我们逐行数一下下图中苹果的数量，以确保我们得到正确的答案。 GPT-4V：第 1 行：4 个苹果 第 2 行：4 个苹果 第 3 行：3 个苹果 图像中的苹果总数：11 个苹果 注意：与上图所示的查询图像相同，调整大小以节省空间 图 4：良好性能的条件改进计数。绿色（红色）突出显示正确（错误）答案。蓝色表示除了“数一下图像中苹果的数量”这个基本要求之外，还有不同的提示方式。查看第 3.1 节了解详细讨论。 14 3.1 遵循文本指令 GPT-4V 的一个独特优势是其通用性，部分是通过其理解和遵循文本指令的强大能力来实现的[102,96,134,111]。指令提供了一种自然的方式来定义和定制任意视觉语言用例所需的输出文本。图 2 显示了对句子长度和要使用的单词进行限制的图像描述示例。或者，在输入端，GPT-4V 可以理解执行具有挑战性任务的详细指令，例如通过提供中间步骤的指令，使 GPT-4V 能够更好地解释抽象推理问题。从指令中学习新任务的能力在适应各种未见过的应用和任务方面显示出巨大的潜力，如第 9 节所述。根据最近的研究 [7,13,48,157,79,35]，本节中讨论的指令小节大多采用文本格式，提供感兴趣任务的语言描述。我们将在后面的 3.3 节中讨论 GPT-4V 遵循多模态示例指令的独特能力。此外，我们展示了文本指令如何在塑造 GPT-4V 的响应中发挥重要作用，采用了 LLM 文献 [3, 156] 中采用的两种技术，（i）“约束提示”，使 GPT-4V 以某种格式响应； (ii) “良好性能的条件”，明确要求 GPT-4V 具有良好的性能。约束提示。在图3中，我们提示GPT-4V读取图像中的文本并以特定的JSON格式返回信息。尽管 GPT-4V 在从驾驶执照中提取相应信息时出现了一些错误，但响应仅限于文本指令中指定的 JSON 格式。我们在第 9 节“良好性能的条件”中将这种技术用于某些应用场景。关于法学硕士的一项观察是，法学硕士不想成功 [10]。相反，他们想要模仿具有一系列性能品质的训练集。如果用户希望成功完成分配给模型的任务，则用户应该明确提出要求，这已被证明对提高 LLM 的性能很有用 [156]。在 LMM 的背景下，我们也有类似的观察结果。在图 4 中，我们比较了模型对不同计数文本指令的响应。我们从一个简单明了的提示开始：“数一下图像中苹果的数量。”然而，GPT-4V 错误地计算出图像中总共有 12 个苹果。为了提高其性能，我们通过添加短语“让我们逐步思考”来探索如何使用[66]中的零样本思想链来进行法学硕士。尽管 GPT-4V 的预测步数总体上是正确的，但对最终计数没有多大帮助，因为它仍然得出“12 个苹果”的错误答案。接下来，我们将指令修改为“让我们逐行数苹果”，这与视觉输入更相关。虽然 GPT-4V 提供了正确的总计数，但它在计算第二/第三行时会出错。当我们进一步将指令扩展为“先数出有多少行苹果，然后数出每一行的苹果，最后将它们相加得到总数”时，最终的答案与正确答案的偏差就更大了（15对比 11)。最后，模仿“让我们一步一步地解决这个问题，以确保我们得到正确的答案。”在[156]中，对于法学硕士，我们设计了如下提示：“你是计算图像中事物的专家。让我们逐行数一下下图中苹果的数量，以确保我们得到正确的答案。 ” 。我们提示中的第一句话要求 GPT-4V 承担计数专家的角色，第二句话明确指示 GPT-4V 成功。通过这种设计，GPT-4V 成功返回每行的正确答案以及总计数。在整篇论文中，我们在各种场景中都采用了这种技术，以获得更好的性能。 

## 3.2 视觉指向和视觉参考提示 

指向是人与人交互的一个基本方面[89]。为了提供可比较的交互渠道，研究了各种形式的“指向”来指代任意感兴趣的空间区域。例如，如图 5 所示，“指向”可以表示为数字空间坐标，例如框坐标和图像裁剪，或覆盖在图像像素上的视觉标记，例如箭头、框、圆圈和手绘图。我们观察到 GPT-4V 在理解直接绘制在图像上的视觉指针方面特别强。鉴于在图像上绘图的灵活性，此功能可以用作未来野外人机交互的自然方法[90,117,157]。为此，我们探索了一种名为视觉引用提示的新提示方法，人们可以编辑输入图像的像素空间来指定所需的目标，例如绘制视觉指针或手写场景文本。如图 6 所示，视觉参考提示编辑图像 15 裁剪框点坐标 框圆手绘 (0.47, 0.48, 0.55, 0.87) 0 1 1 箭头 裁剪框点 框圆手绘坐标 (0.47, 0.48, 0.55, 0.87) 裁剪Mask 0 1 1 Arrow 图 5：多模式交互中“视觉指向”的不同模式。像素，而不是传统的文本提示，来执行感兴趣的任务。例如，它可以是一个简单的基础描述，重点描述所指出的对象，同时保持对全局图像上下文的理解，如图 6 (1,2) 所示。视觉引用提示还支持其他新颖的用例，例如将指向的对象与场景文本中写入的索引相关联（图 6 (3)），或者解决在查询的边缘或角度附近提出的问题（图 6 (4)）。第 5 节将更详细地讨论视觉引用提示。 3.3 视觉+文字提示 视觉引用提示可以与其他图文提示流畅地结合使用，呈现出细致入微的界面，简洁地代表感兴趣的问题。图 7 提供了两个示例，展示了 GPT-4V 提示的灵活性，特别是它在集成不同输入格式以及将指令与输入中的示例无缝混合方面的熟练程度。 GPT-4V 的通用性和灵活性导致了对多模式指令的类似人类的理解以及前所未有的适应看不见的任务的能力。集成多模式指令输入。现有模型通常对如何格式化交错的图像-文本输入有隐含的约束，例如，上下文中的小样本学习需要图像-文本对共享与查询输入类似的格式。相比之下，GPT-4V 显示了处理图像、子图像、文本、场景文本和视觉指针的任意组合的通用性。例如，为了说明图 7 中的“添加一条线”模式，可以像子图 (1) 中那样用圆圈指向矩阵图像中的第一列，或者像子图 (1) 中那样将子图像内联合并起来。 -图(2)。类似地，对于输入查询，可以像子图（1）中那样呈现带有问题的大图作为场景文本，或者像子图（2）中那样发送文本和子图像的混合。与 GPT-4V 的灵活性相比，现有的多模态模型在如何组合图像和文本以及可以处理的图像数量方面受到严格限制，从而对模型的能力和通用性造成限制。多模式基于示例的教学。除了支持更灵活的输入格式之外，与指令跟随模式和上下文中的小样本学习相比，GPT-4V 的通用性还开辟了更有效的方式来说明要执行的任务。指令遵循技术[102,96,134,111]最初是为 NLP 任务提出的，直观地专注于纯粹文本格式的任务指令。文本指令与视觉查询输入松散相关，因此可能无法提供清晰的任务演示。虽然上下文中的少样本学习 [23,125,7] 提供了包含图像和文本的测试时示例，但这些示例必须与推理查询的格式完美一致，这使得它们的合并变得复杂且冗长。此外，上下文示例通常与指令分开使用，要求模型推断任务目标，从而损害演示的有效性。相比之下，GPT-4V 理解多模式指令的能力使任务演示能够基于相应的上下文示例，从而更有效地说明感兴趣的任务。例如，在图7中，将“查找第一列中的模式”的指令接地到演示示例中的关键步骤（即（1）中的圆圈模式和（2）中的相应子图）简化了学习过程并提高模型的性能。这种方法也反映了人类的学习过程，其中涉及抽象指令与直观示例的结合。 16 秒3.2 视觉参考提示 (1) 提示：描述图像中所指出的区域。 GPT-4V：图像中的尖角区域是电线上的一排悬挂灯。灯又小又圆，沿着电线均匀分布。电线在两根杆子之间拉伸，位于配有桌子和遮阳伞的露台区域上方。这些灯看起来是装饰性的，可能用于在晚上提供环境照明。 (2)提示：描述图像中所指出的区域。 GPT-4V：图像中突出显示的红色区域是包含数值 122.3 的表格单元格。它位于表的“测试集”部分中的“out”列和“GIT2”行下方。该值表示“out”类别中测试集上 GIT2 方法的整体性能指标。视觉指向和视觉参照提示 (3) 提示：圆圈玻璃里有什么？对象 1 或 2？描述什么是物体 1 和物体 2。然后检查圆圈玻璃里有什么。 GPT-4V：物体1是一个玻璃瓶水。它是透明的，上面有一个蓝色标签。物体2是一瓶麦格纳啤酒的玻璃瓶。它是绿色的，上面有一个红色和白色的标签。在圆圈玻璃中，它看起来是一种透明液体，可能是水。因此，圆圈玻璃中的内容物很可能来自对象 1，即玻璃瓶水。 （4）提示：回答下图问题。提供中间步骤。 GPT-4V：要找到蓝色箭头边的长度，我们可以使用毕达哥拉斯定理，因为我们有一个直角三角形。该定理指出 a² + b² = c²，其中 a 和 b 是直角三角形的两条边，c 是斜边。代入我们得到的值，我们得到： 4² + 8² = c² 16 + 64 = c² 80 = c² √80 = c 8.94 ≈ c 因此，蓝色箭头边缘的长度约为 8.94。为了找到绿色箭头处的角度，我们可以使用正切函数，因为我们有角度的对边和邻边。正切函数指出 tan θ = 相反/相邻。代入我们得到的值，我们得到： tan θ = 4/8 tan θ = 1/2 θ = tan^-1(1/2) θ ≈ 26.57° 因此，绿色箭头处的角度约为 26.57°。图 6：GPT-4V 展示了理解直接叠加在图像上的视觉指向的独特能力。基于这种能力，我们探索视觉参考提示，编辑输入图像像素（例如，绘制视觉指针和场景文本）以提示感兴趣的任务。查看第 3.2 节了解详细讨论。 17 (2) 提示：找出第一列中的模式，并用它来推断第二列中缺失的图形。例如，因此，向图像 2 添加一条线将是一个有一条线穿过它的菱形。秒。 

## 3.3 视觉+文本提示多模式基于示例的说明

这是排列在 2×2 矩阵中的三个子图像。图 3 和图 1 之间的图案是什么？完成矩阵的下一张图像是什么？ abcdef 提示续 (1) 提示：找出第一列中的模式，并用它来推断第二列中缺失的数字。例如，左第一列中的圆圈区域显示了通过它添加一条线的模式。因此，答案是一个有一条线穿过的菱形图形，看起来像 。回答下图中的问题。 GPT-4V：第一列的图案是在图形的中心添加一个点。因此，第二列中缺失的图形将是一个中心有一个点的星形，即选项 C。 GPT-4V：图像 3 和图像 1 之间的模式是图像 3 中心有一个点，而图像 3 的中心有一个点。 1 没有。完成矩阵的下一个图像将是选项 c，一颗中心有一个点的星星。这是因为该模式似乎是每个其他图像的中心都有一个点，而前一个图像（图像 3）的中心也有一个点。此外，图像在菱形和星形之间交替，因此下一个图像应该是星形。图 7：GPT-4V 擅长解释图像、子图像、文本、场景文本和视觉指针输入的任意组合。这些元素可以用作指令、示例或输入查询，帮助 GPT-4V 有效地执行新任务。查看第 3.3 节了解详细讨论。

## 3.4 上下文中的小样本学习

上下文中的小样本学习是法学硕士中观察到的另一种有趣的新兴能力[23,39,135,34]。也就是说，LLM 可以通过在推理时预先考虑一些上下文中的示例来生成所需的输出，而无需更新参数。这些示例与输入查询具有相同的格式，并作为演示来说明所需的输出。最近在多模态模型 [125,7,55,42,151] 中观察到类似的能力，其中查询输入是格式化的图像文本对。作为指令调整的补充，上下文学习通过在测试期间提供具有相同格式的上下文示例来“教导”模型执行新任务。我们通过一些引人注目的例子展示了 GPT-4V 的上下文中的小样本学习能力。我们强调，在某些情况下，具有足够数量示例的上下文中的小样本学习变得至关重要，特别是当零样本或单样本指令方法无法满足要求时。图 8-10 探讨了涉及读取速度计的具有挑战性的场景。图 8 显示了 GPT-4V 在视频速度计图像屏幕截图上的零样本性能。尽管多次尝试以零样本方式提示 GPT-4V，但它很难准确读取图像中显示的当前速度。它生成的预测（22/30/40 英里/小时）与人类实际读取的“大约 9 英里/小时”存在显着偏差。即使使用 1-shot 上下文示例（如图 9 所示），使用不同的示例（图 9a）或类似的示例（图 9b），GPT-4V 仍然无法准确定位左侧的两个数字和黄色指针的右侧。相比之下，图 10 表明，当提供 2 个上下文示例（其中一个与查询图像相似，另一个不相似）时，GPT-4V 通过识别指针接近 10 来成功预测阅读速度为“大约 9 英里/小时”英里/小时，但还没有完全达到。图 11-13 展示了在复杂线图上进行推理的零样本、1 样本和 2 样本性能之间的比较。我们在这里探讨的示例具有很大的难度，因为它涉及多跳推理。要回答“图中哪一年 6 月平均 Gas 价格最高”的问题，需要至少执行四个步骤：(i) 在 x 轴上定位 6 月，(ii) ) 比较 6 月份每条线的数据点，(iii) 识别具有最高值的线的颜色，以及 (iv) 将颜色与顶部图例中的相应年份相匹配。这些步骤中的任何一个失败都会导致错误的预测。如图 11 所示，即使以零样本方式提示“文本指令，逐步思考”，GPT-4V 也无法正确地将颜色与图例中的年份关联起来。此外，它还被图中突出显示的 3.32 美元的 Gas 价格分散了注意力。同样，在图 12 中，尽管 GPT-4V 在阅读图例方面显示出一些改进（与零样本相比，更正了 2021 年和 2022 年的相应颜色），但它仍然坚持以 2023 年作为平均 Gas 价格最高的年份来回答。 6 月份，尽管该图表仅包含 2023 年 1 月 17 日之前的数据点。然而，当我们在图 13 中引入另一个上下文示例时，GPT-4V 最终得出正确答案 (2022) 并提供解释其推理过程的中间步骤，类似于上下文示例中所示的演示。这些概念验证示例生动地证明了上下文中的小样本学习对于提高 LMM 性能的重要性。这种方法是微调的可行替代方案，类似于法学硕士 [23,39,135,34] 中的观察结果。尽管上下文中的小样本学习对于 LMM 实现更好的性能非常重要，但我们在本报告中限制了它的使用，以防止潜在的信息泄漏或来自上下文示例的不需要的提示。我们还将对小样本学习收益的定量评估留给未来的研究。 19 零位提示：速度表读数是多少？ GPT-4V：速度计的读数约为 22 英里每小时 (mph)。零样本（一步步思考） 提示：速度表的读数是多少？让我们一步步思考。 GPT-4V：该车速表有两种刻度 - 一种以英里每小时 (mph) 为单位，另一种以公里每小时 (km/h) 为单位。指针指向 mph 刻度上的 20 和 40 之间，以及 km/h 刻度上的 40 和 60 之间。由于刻度上的数字以 20 为增量增加，我们可以估计指针指向的速度约为 30 英里/小时和 50 公里/小时。因此，速度计的读数约为 30 英里/小时（或 50 公里/小时）。零射击（带文字说明） 提示：速度计的读数是多少？要读取该速度表，请观察表盘外边缘的指针，该指针指向您当前的速度（以英里/小时为单位）。黄色是针的颜色。 GPT-4V：在此示例中，指针指向大约 40 英里/小时，因此当前速度约为 40 英里/小时。此外，表盘内圈显示的速度以公里/小时为单位，因此在本例中，当前速度约为 64 公里/小时。注意：与上图所示相同的查询图像，调整大小以节省空间 注意：与上图所示相同的查询图像，调整大小以节省空间 零样本（带文本说明，逐步思考） 提示：读取的内容是什么测速仪？要读取该速度表，请观察表盘外边缘的指针，该指针指向您当前的速度（以英里/小时为单位）。黄色是针的颜色。让我们一步步思考。 GPT-4V： 1. 首先，查看表盘的外缘，找到代表英里/小时的数字。 2. 接下来，找到指向当前速度的黄色指针。 3. 观察指针指向的位置并读取刻度盘外缘上的数字。 4. 该数字是当前速度（英里/小时）。在此示例中，指针指向大约 40 英里/小时，因此当前速度为 40 英里/小时。注意：与上图所示相同的查询图像，调整大小以节省空间3.4 上下文中的小样本学习 图 8：在读取速度计的挑战性场景下的零样本性能。即使采用不同的ZS提示方式，GPT4V也无法准确读取车速表。红色突出显示错误答案。查看第 3.4 节了解详细讨论。 20 上下文中的少样本（1-shot） 提示：速度计的读数是多少？黄色指针大致位于 80 英里/小时和 100 英里/小时之间的中间位置。 80 和 100 之间的中间值为 90。速度约为 91 英里/小时，因为指针刚刚经过 90 英里/小时。 GPT-4V：在此图像中，黄色针大致位于 60 到 80 英里/小时之间的中间位置。 60 和 80 之间的中间值为 70。速度约为 71 英里/小时，因为针刚刚经过 70 英里/小时。秒。 3.4 上下文中的少样本学习 (a) 上下文中的少样本（1-shot）秒。 3.4 上下文小样本学习提示：速度计的读数是多少？黄色指针位于 20 至 40 英里/小时之间的长刻度处。 20 和 40 之间中间的长刻度是 30。速度约为 29 英里/小时，因为指针接近 30 英里/小时，但尚未完全达到 30 英里/小时。 GPT-4V：黄色指针位于 40 至 60 英里/小时之间的长刻度处。 40 和 60 之间中间的长刻度是 50。速度约为 49 英里/小时，因为指针接近 50 英里/小时，但还没有完全达到 50 英里/小时。 (b) 图 9：在读取速度计的挑战性场景下的一次性（或多模式示例指令提示）性能。对于 (a) 不同或 (b) 相似的 1-shot 上下文示例，GPT-4V 仍然失败。红色突出显示错误答案。查看第 3.4 节了解详细讨论。 21 上下文中的少次（2 次）提示：速度计的读数是多少？黄色指针大致位于 80 英里/小时和 100 英里/小时之间的中间位置。 80 和 100 之间的中间值为 90。速度约为 91 英里/小时，因为指针刚刚经过 90 英里/小时。黄针大致处于 20 到 40 英里/小时之间的中间位置。 20 和 40 之间的中间值为 30。速度约为 29 英里/小时，因为指针接近 30 英里/小时，但还不到 30 英里/小时。 GPT-4V：黄色指针位于 0 到 20 英里/小时之间的长刻度处。 0 和 20 之间中间的长刻度是 10。速度约为 9 英里/小时，因为指针接近 10 英里/小时，但还没有完全达到 10。秒。 3.4 上下文中的小样本学习 图 10：在读取速度计的挑战性场景下的两次样本性能。 GPT4V现在可以准确读取速度。绿色突出显示正确答案。查看第 3.4 节了解详细讨论。 22 Zero-shot GPT-4V：根据图表，6 月份平均汽油价格最高的年份是 2021 年，价格约为每加仑 3.32 美元 Zero-shot（逐步思考） 提示：图中，哪一年 6 月份的平均汽油价格最高？让我们一步步思考。 GPT-4V：步骤 1：在 x 轴上找到六月。步骤 2：查看每年 6 月份的数据点。步骤 3：比较数据点，看看哪一年的值最高。根据这些步骤，我们可以看到 2021 年 6 月份的平均汽油价格最高，约为每加仑 3.32 美元。零样本（带文字说明） 提示：图中，哪一年 6 月份的平均 Gas 价格最高？第1步，读图标题；步骤2阅读图表的图例，了解年份和线条颜色的对应关系；步骤 3 查看图表并确定 x 轴上的 6 月；第四步，查看6月份各条线的数据点；步骤5，比较每条线的数据点，确定哪一条线6月平均gas价格最高；第 6 步，识别该线的颜色，并与顶部图例中的年份相匹配。 GPT-4V：根据上述步骤，我们可以看到2021年（蓝线代表）6月份的平均汽油价格最高，为每加仑3.32美元。注意：与上图所示相同的查询图像，调整大小以节省空间零样本（带文本说明，逐步思考）提示：在图表中，哪一年 6 月份的平均 Gas 价格最高？第1步，读图标题；步骤2阅读图表的图例，了解年份和线条颜色的对应关系；步骤 3 查看图表并确定 x 轴上的 6 月；第四步，查看6月份各条线的数据点；步骤5，比较每条线的数据点，确定哪一条线6月平均gas价格最高；第 6 步，识别该线的颜色，并与顶部图例中的年份相匹配。让我们一步步思考。 GPT-4V：步骤1：图表标题为“全国天然气价格比较/2019-2023”。这告诉我们，该图正在比较 2019 年至 2023 年美国的汽油价格。 步骤 2：图顶部的图例显示 2019、2020、2021、2022 和 2023 年用不同的颜色表示：橙色、 分别为黑色、蓝色、绿色和青色。步骤 3：查看 x 轴，我们可以看到代表的是六月。步骤4：在6月份，我们可以看到每条线的数据点如下： - 2019（橙色）：约2.75美元 - 2020（黑色）：约2.25美元 - 2021（蓝色）：约3.32美元 - 2022（绿色）：3.00 美元左右 - 2023 年（青色）：2.90 美元左右 第 5 步：比较这些数据点，我们可以看到 6 月份的最高平均 Gas 价格为 3.32 美元。步骤 6：代表 3.32 美元的线条颜色为蓝色，对应图例中的 2021 年。因此，6 月份平均 Gas 价格最高的年份是 2021 年。 3.4 上下文小样本学习提示：在图中，哪一年 6 月份的平均 Gas 价格最高？注意：与上图所示相同的查询图像，调整大小以节省空间 注意：与上图所示相同的查询图像，调整大小以节省空间 图 11：读取线图的挑战性场景下的零样本性能。即使使用不同的ZS提示方式，GPT-4V也无法回答问题。红色突出显示错误答案。查看第 3.4 节了解详细讨论。 23 上下文中的少镜头（1 镜头）秒。 3.4 上下文小样本学习提示：在图中，哪一年 6 月份的平均 Gas 价格最高？该图是 2016 年至 2019 年 2 月 4 日全国天然气价格比较的线图。顶部的图例显示了每年的线条颜色：红色（2019 年）、蓝色（2018 年）、绿色（2017 年）和橙色（2016 年）。由于数据报告截至 2019 年 2 月，因此只有 3 年的数据点为 2018 年（蓝色）、2017 年（绿色）和 2016 年（橙色）。其中，2018年的蓝线位于顶部，为6月份。因此，6 月份平均 Gas 价格最高的年份是 2018 年。 GPT-4V：该图是 2019 年至 2023 年 1 月 17 日全国 Gas 价格比较的线图。顶部的图例显示了每年的线条颜色：红色（2023）、蓝色（2022）、绿色（2021）、黑色（2020）和橙色（2019）。由于数据报告截至 2023 年 1 月，因此只有 4 年有 2022 年 6 月（蓝色）、2021 年（绿色）、2020 年（黑色）和 2019 年（橙色）的数据点。其中，2023年的红线位于6月份的顶部。因此，6 月份平均 Gas 价格最高的年份是 2023 年。 图 12：在读取线图的挑战性场景下一次性（或用多模式示例指令提示）性能。 GPT-4V 在 1-shot 上下文示例中仍然失败。红色突出显示错误答案。查看第 3.4 节了解详细讨论。 24 上下文中的Few-shot（2-shot）提示：图中，哪一年6月份的平均汽油价格最高？该图是 2015 年至 2018 年 10 月 12 日全国天然气价格比较的线图。顶部的图例显示了每年的线条颜色：红色（2018 年）、橙色（2017 年）、绿色（2016 年）和橙色（2017 年）。由于数据报告截至 2018 年 12 月，所有 4 年都有 6 月份的数据点。其中，2018年的红线位于6月份的顶部。因此，6 月份平均天然气价格最高的年份是 2018 年。该图是 2016 年至 2019 年 2 月 4 日全国天然气价格比较的线图。顶部的图例显示了每年的线条颜色：红色（2019 年）、蓝色（2018 年）、绿色（2017 年）和橙色（2016 年）。由于数据报告截至 2019 年 2 月，因此只有 3 年的数据点为 2018 年（蓝色）、2017 年（绿色）和 2016 年（橙色）。其中，2018年的蓝线位于顶部，为6月份。因此，6 月份平均 Gas 价格最高的年份是 2018 年。 GPT-4V：该图是 2019 年至 2023 年 1 月 17 日全国 Gas 价格比较的线图。顶部的图例显示了每年的线条颜色：红色（2023）、蓝色（2022）、绿色（2021）、橙色（2020）和黑色（2019）。由于数据报告截至 2023 年 1 月，因此只有 4 年有 2022 年 6 月（蓝色）、2021 年（绿色）、2020 年（橙色）和 2019 年（黑色）的数据点。其中，2022 年的蓝线位于 6 月份的顶部。因此，6 月份平均 Gas 价格最高的年份是 2022 年。 3.4 上下文中的小样本学习 图 13：在读取线图的挑战性场景下的两次样本性能。 GPT-4V 现在可以回答“哪一年 6 月份平均 Gas 价格最高？”的问题。正确。查看第 3.4 节了解详细讨论。绿色突出显示正确答案。 25 4 视觉语言能力 理解和描述视觉信息在人类认知中起着至关重要的作用。在本节中，我们将研究如何利用 GPT-4V 来理解和解释视觉世界。我们将首先检查模型为通用视觉字幕生成开放式描述的能力。接下来，在 4.2 节中，我们将探索 GPT-4V 在更高级任务中的应用，例如空间关系分析、对象定位、对象计数和密集字幕。在4.3节中，我们将深入研究模型的多模态知识和常识推理能力，并研究模型是否能够理解不同类型信息之间的上下文和关系。此外，在 4.4 节中，我们将评估模型从各种来源（包括场景文本、表格、图表和文档）提取和分析信息的能力。在4.5节中，我们将探讨GPT-4V在多语言场景下理解和生成描述的能力。最后，在 4.6 节中，我们将研究模型使用视觉信息的编码能力，探索其使用选定示例执行任务的能力。 4.1 不同领域的图像描述 我们通过提供单个图像-文本对作为输入来访问模型的功能和通用性。我们提示 GPT-4V 生成涵盖下列各种主题的自然语言描述。名人认可。由于其固有的可变性，识别人类外表 [49, 80] 提出了重大挑战。为了评估 GPT-4V 识别和描述名人的能力，我们通过提供文本提示“描述图像”以及输入名人图像来进行实验。在图 14 的顶行中，我们观察到 GPT-4V 准确地识别了八位名人，尽管他们的背景和领域各不相同。此外，当我们提出更具体的查询“图像中的人是谁，这个人在做什么？”（如图 14 的底行所示）时，GPT-4V 会理解现任美国总统是在2023年七国集团峰会上发表演讲。这说明了该模型概括和处理新场景的能力，例如 2023 年 G7 峰会，但该场景并不属于其训练数据。地标识别。由于视点变化、照明条件、遮挡和季节变化等因素，地标的外观呈现出相当大的变化。识别这些变化下的地标需要模型能够很好地概括并处理广泛的视觉外观 [152, 5]。在实验中，我们采用简单的文本提示“描述图像中的地标”来测试模型的能力。如图 15-16 所示，GPT-4V 为每个测试图像生成准确且开放式的描述。例如，它可以准确识别位于华盛顿州西雅图的太空针塔，了解该塔是为 1962 年世界博览会而建造的，并已成为该城市的象征。我们对其他测试照片也有类似的观察结果。生成的描述超越了简单的标签或通用短语，提供了生动而详细的叙述，捕捉了地标的本质。食物识别。识别食物或菜肴是一项令人着迷的任务 [20, 95]，但由于外观范围广泛以及其他物体或重叠成分造成的潜在遮挡，因此处理起来可能具有挑战性。在我们的实验中，我们采用简单的文本提示，要求系统“描述菜肴的名称”，以进行测试。图17展示了GPT-4V对各种菜肴的准确识别。此外，GPT-4V 可以有效捕捉图像中的复杂细节，使其能够识别菜肴中的特定成分、装饰或烹饪技术。医学图像理解。由于患者群体和成像设备的不同，X 射线和 CT 扫描等医学图像可能存在很大的差异。此外，解释这些图像的视觉内容需要专业知识。在图 18 中，我们通过提供提示“描述图像”来访问 GPT-4V 的性能。结果表明，GPT-4V 可以识别给定 X 射线中的牙齿和颌骨。此外，当我们提示“这张X光图像中是否有需要拔除的智齿？” GPT-4V 通过视觉上下文进行推理，并解释下颌左下方和右下方的智齿没有完全从牙龈线中露出，这可能是拔除的原因。我们还使用其他医学 26 幅图像进行测试，如图 19 所示。对于这些实验，我们使用诸如“怎么了？”之类的提示。或者“看看 CT 扫描，告诉我出了什么问题。”观察结果表明，GPT-4V 可以识别常见情况，例如琼斯骨折。它还可以根据肺部 CT 扫描指出潜在的问题。实验证明了 GPT-4V 对医学图像的基本理解。我们在 9.3 节中讨论 GPT-4V 在医学领域的应用。标志识别。我们考察了 GPT-4V 的标志识别能力。在图 20 中，我们通过提供文本提示“描述图像”来启动实验。 GPT-4V 准确识别了图像中描绘的三个徽标。然后我们继续提出一个更具体的问题，“详细描述标志”，GPT-4V 提供了详细的描述，分别包括每个标志的设计、风格和表示。将评估扩展到更具挑战性的野外场景，如图 21 所示，我们尝试使用可能部分遮挡、扭曲或位于杂乱背景中的徽标。我们使用文本提示“详细描述图像和徽标”进行野外实验。如图21所示，GPT-4V在困难场景下展现出强大的标识理解能力。值得注意的是，GPT-4V 还可以提供新颖或新兴徽标和图标的描述，例如最近发布的 Microsoft 365 Copilot。场景理解。场景理解[76,32,154]是计算机视觉中的一项重要任务。我们通过提供简单的查询“描述图像”来检查模型的功能。在图22中，GPT-4V能够描述道路以及车辆的位置和颜色。它还可以读取标志并注意这条道路的速度限制。反事实的例子。我们通过从[78]中随机选择反事实的例子来进行实验。在图 23 中，我们观察到 GPT-4V 在遇到误导性问题或指令时正确描述了图像内容。 27 提示：图中的人是谁？他在做什么？ GPT-4V：图像中的人是美国现任总统乔·拜登。他正站在 2023 年日本广岛七国集团峰会的讲台上，很可能正在发表演讲。提示：图像中的人是谁，他在做什么？ GPT-4V：图中的人是 NVIDIA 首席执行官兼联合创始人黄仁勋。他拿着并展示了 NVIDIA 的一款产品，很可能是图形处理单元 (GPU)。提示：描述图像 GPT-4V：该图像显示了来自不同领域的 8 位杰出人物的拼贴画。最上面一排从左到右依次是歌手贾斯汀·比伯、足球运动员莱昂内尔·梅西、足球运动员克里斯蒂亚诺·罗纳尔多和企业家埃隆·马斯克。底排从左到右依次是模特兼真人秀明星凯莉·詹纳、歌手泰勒·斯威夫特、演员小罗伯特·唐尼和演员斯嘉丽·约翰逊。所有人物都以不同的姿势和服装、不同的背景出现。名人识别和描述秒。 4.1 不同领域的图像描述 图 14：名人识别和描述结果。 GPT-4V可以识别各种名人并详细描述视觉信息（包括他们的职业、行为、背景和事件）。查看第 4.1 节了解详细讨论。 28 提示：描述图像中的地标。 。 GPT-4V：图像中的地标是太空针塔，一座位于华盛顿州西雅图的观测塔。它高 605 英尺，可欣赏城市及周边地区的全景。该塔是为 1962 年世界博览会而建造的，自此成为西雅图的象征和受欢迎的旅游景点。该塔采用未来派设计，顶部有一个大型圆形观景台和一个360度旋转的餐厅。塔的底部周围是一个有树木和绿地的公园。地标识别及描述提示：描述图像中的地标。 。 GPT-4V：此图显示了位于日本京都的金阁寺，也称为金阁寺。该寺庙是一座三层佛教寺庙，覆盖着金箔，坐落在池塘上，在水面上形成令人惊叹的倒影。周围的景观充满了树木和岩石，营造出一种宁静祥和的氛围。它是一个受欢迎的旅游景点，并被指定为国家特别历史遗址。提示：描述图像中的地标。 GPT-4V：图像中的地标是纽约市时代广场的乔治·M·科汉 (George M. Cohan) 雕像。这是一座青铜雕像，矗立在时代广场北部达菲广场的花岗岩基座上。这座雕像是向美国艺人、剧作家、作曲家和制片人乔治·M·科汉致敬，他被认为是美国音乐喜剧之父。该雕像于 1959 年揭幕，从此成为时代广场的热门旅游景点。提示：描述图像中的地标。 。 GPT-4V：图中的地标是加利福尼亚州旧金山著名的朗伯德街，以其陡峭的发夹弯而闻名。街道两旁种满了五颜六色的鲜花和灌木，两旁都是房屋和建筑物。在背景中，您可以看到城市天际线和电报山上的科伊特塔。这条街是一个受欢迎的旅游景点，通常被认为是世界上最弯曲的街道之一。秒。 4.1 不同领域的图像描述 图 15：地标识别和描述的结果。 GPT-4V 准确识别测试图像中的地标。它还生成生动详细的叙述，捕捉地标的本质。查看第 4.1 节了解详细讨论。 29 地标识别及描述 提示：描述图像中的地标。 。 GPT-4V：图像中的地标是位于台湾台北的台北 101 大楼。该建筑高508米（1,667英尺），是2004年至2010年期间世界最高的建筑。地上101层，地下5层，是台北的热门旅游景点。建筑的设计类似于竹子，象征着力量和韧性。提示：描述图像中的地标。 。 GPT-4V：图中的地标是日本京都的伏见稻荷大社。它以其数千个朱红色的鸟居门而闻名，这些门排列在通往神社的道路上。这些大门代表了世俗世界和神圣世界之间的界限，由个人和企业捐赠，以表达他们对稻荷神的虔诚。该图像显示了一条通往神社的通道，两旁排列着这些大门，中间有石阶。提示：描述图像中的地标。 。 GPT-4V：图像中的地标是曼哈顿大桥，从纽约布鲁克林的 DUMBO 社区可以看到。这座桥横跨东河，连接曼哈顿下城和布鲁克林。它是一座拥有两座大塔的吊桥，于 1909 年竣工。图中，这座桥由两座砖砌建筑构成，形成了这座地标建筑的独特景观。提示：描述图像中的地标。 。 GPT-4V：图像中的地标是纽约市特朗普大厦的内部。焦点是 Trump Grill，这是一家位于塔楼下层的餐厅。内部装饰有红色和金色的装饰、大理石墙壁和柱子，以及圣诞树和一品红的节日展示。空间富丽堂皇，是特朗普品牌的典型特征。秒。 4.1 不同领域的图像描述 图 16：地标识别和描述的结果。 GPT-4V 准确识别测试图像中的地标。它还生成生动详细的叙述，捕捉地标的本质。查看第 4.1 节了解详细讨论。 30 提示：描述菜名。 。 GPT-4V：图中的菜是一碗麻婆豆腐，这是四川省的一道受欢迎的中国菜。它由软豆腐块和由辣椒、豆瓣酱和四川花椒制成的浓郁辣酱组成。这道菜用薄片洋葱装饰。食物识别和描述 提示：描述菜肴的名称。 。 GPT-4V：鳗鱼盖饭是源自日本的菜肴名称。在日本料理中，它是一种通常装在深碗中的盖饭菜肴。 “Unagi”一词在日语中是淡水鳗鱼的意思，“donburi”是指盛有米饭和其他配料的大碗。鳗鱼盖饭是一道用烤鳗鱼和一种称为“鳗鱼酱”的甜味和咸味酱料在白米饭上制成的菜肴。它通常与腌菜、芝麻、葱和海藻一起食用。提示：描述菜名。 。 GPT-4V：这道菜被称为 Cajun Sampler。这是一个样品拼盘，由四小碗传统的卡真菜肴组成：浓汤、什锦饭、红豆和米饭以及小龙虾 étouffée。碗里配上一片切片面包来蘸着吃。每碗里盛满白米饭，上面撒上葱。这是路易斯安那州的一道受欢迎的菜肴，也是尝试各种卡真风味的好方法。提示：请描述菜名... GPT-4V：这道菜叫做红烧排骨配Chimichurri。它的特色是多汁的小排骨，经过慢煮直至变软，上面淋上美味的奇米丘里酱。它与烤蔬菜一起食用，构成一顿完整的饭菜。秒。 4.1 不同领域的图像描述 图 17：食物识别和描述的结果。 GPT-4V可识别各种菜肴。它还可以识别菜肴图像中存在的特定成分、装饰或烹饪技术。查看第 4.1 节了解详细讨论。 31 医学图像理解提示：描述图像 GPT-4V：该图像是从正面观察的人类头骨的黑白 X 射线。头骨的顶部和底部清晰可见。牙齿和颌骨清晰可见。鼻腔和眼窝也可见，但不那么清晰。该图像右下角标有“L”，表明它是头骨的左侧。秒。 4.1 不同领域的图像描述 提示：这张X光图像中是否有需要拔除的智齿？ GPT-4V：很难确定是否需要从该 X 射线图像中去除智齿，因为还需要考虑其他因素，例如患者的年龄和牙齿的位置。然而，下巴左下方和右下方的智齿似乎部分受影响，这意味着它们没有完全从牙龈线中露出。这可能是拔除智齿的一个原因，因为阻生智齿会导致疼痛、感染和其他问题。提示：哪颗智齿最难拔？ GPT-4V：下智齿，尤其是那些受影响的智齿，通常被认为是最难去除的。这是因为下颌骨比上颌骨更致密，并且阻生的智齿可能更难以接触。此外，下智齿的根部通常比上智齿的根部更长、更弯曲，这使得拔除智齿变得更加困难。注意：与上图所示相同的查询图像，调整大小以节省空间 注意：与上图所示相同的查询图像，调整大小以节省空间 图 18：医学图像理解结果。 GPT-4V 可以识别给定 X 射线中的牙齿和颌骨，并解释说，下颌左下方和右下方部分出现的智齿可能需要移除。查看第 4.1 节了解详细讨论。医学图像是从互联网收集的。 32 提示：怎么了？ GPT-4V：第五跖骨（脚外侧连接小脚趾的骨头）似乎有骨折或折断。这通常称为“琼斯骨折”。提示：看下图中的肺部CT扫描，告诉我哪里出了问题。 GPT-4V：双肺似乎有多个实变区域和磨玻璃样混浊，这可能表明肺部感染或炎症。右上叶也可能有肿块或结节。需要进一步评估和临床相关性来确定准确的诊断。医学图像理解秒。 4.1 不同领域的图像描述 图 19：医学图像理解结果。 GPT-4V 可以识别琼斯骨折等常见病症。它还可以根据肺部 CT 扫描指出潜在的问题。查看第 4.1 节了解详细讨论。医学图像来自互联网。 33 徽标识别和描述 提示：描述图像 GPT-4V：图像由水平排列的三个不同图标组成，每个图标之间有一条细垂直线分隔。左侧是一个类似字母“O”的图标，中间有一条蓝色水平线。这是汽车品牌宝马的标志。中间是一个由两个重叠三角形组成的图标，点朝上。这是汽车品牌英菲尼迪的标志。右侧是一个由盾状形状和三个向上箭头组成的图标。这是汽车品牌玛莎拉蒂的标志。秒。 4.1 不同领域的图像描述 提示：详细描述标志 GPT-4V：最左边的标志是宝马的标志。它是一个填充黑色的圆形图标。圆圈内，有一条蓝色的水平线从中间穿过。蓝线上方的区域为白色，蓝线下方的区域为浅蓝色。该标志代表飞机的旋转螺旋桨，这是对该公司航空历史的致敬。中间的标志是英菲尼迪标志。它由两个重叠的三角形组成，顶点朝上。三角形用黑色填充。该标志代表一座山或一条路，这是对公司权力、力量和绩效精神的认可。最右边的标志是玛莎拉蒂标志。它由一个类似盾牌的形状组成，并具有三个指向上方的红色箭头。盾牌形状被淡淡的白色填充，箭头之间的区域是黑色的。该标志是对公司赛车历史的致敬，箭头代表公司的胜利。注意：与上图所示的查询图像相同，调整大小以节省空间 图 20：徽标识别结果。 GPT-4V 可以正确识别徽标并提供详细的描述，包括其设计、颜色、形状和符号。查看第 4.1 节了解详细讨论。 34 野外标志识别和描述 提示：详细描述图像和标志 GPT-4V：图像是麦当劳的炸薯条容器，里面装满了金黄色的炸薯条。容器是红色的，上面有麦当劳标志性的“M”标志。背景是亮黄色，使红色容器和薯条脱颖而出。标志是麦当劳的“M”，它是一个巨大的金色拱门，形成了麦当劳的字母“M”。它是世界上最受认可的标志之一，通常与快餐连锁店联系在一起。提示：详细描述图像和徽标 GPT-4V：图像显示穿着白色 Nike Air Force 1 运动鞋的人脚的特写。该运动鞋为低帮款式，白色橡胶鞋底和白色鞋带。鞋子的鞋面由纹理白色皮革制成，赋予其高级外观。运动鞋上显示的标志是标志性的 Nike Swoosh。它以银色显示在鞋子的侧面。 Swoosh 是一个弯曲的、细长的勾号形状，末端有一个尖头。它代表速度和动感，体现了品牌的运动和运动美学。提示：详细描述图像和标志 GPT-4V：图像显示一位身着日本传统服装的女性站在奥运五环标志前。女子身着紫色花卉图案和服，系着红色腰带。她微笑着摆好姿势拍照。奥林匹克五环标志由蓝、黄、黑、绿、红五个不同颜色的圆环组成。这些环以形成花朵形状的方式排列。该标志显示在一片草地上，背景是树木。提示：详细描述图像和徽标 GPT-4V：图像显示两个可口可乐瓶躺在冰块床上。瓶子是湿的，表明它们已冷藏并可以饮用。正如标签上所述，左侧的瓶子是新的握把瓶。右边的瓶子是普通的可口可乐瓶子。两个瓶子上都有标志性的可口可乐标志。标志以白色草书字体书写，背景为红色。 Coca 中的第一个“C”比其余字母大，而 Cola 中的“o”则被拉长。该标志非常容易辨认，是品牌的代名词。提示：详细描述图像和徽标 GPT-4V：图像显示两个星巴克杯子，一个是带盖和吸管的透明塑料杯，另一个是带盖的白色纸杯。透明塑料杯盛有冷饮，上面有冰块和鲜奶油，而白色纸杯则盛有热饮。这些杯子放在一张木桌上，背景是星巴克店的模糊区域。杯子上的徽标是星巴克徽标，它是一个绿色圆圈，中心有一个白色美人鱼或海妖提示：详细描述图像和徽标 GPT-4V：该图像是有关 Microsoft 365 Copilot 的演示文稿的屏幕截图。该图显示一名男子站在大屏幕前，屏幕上有 Microsoft 365 Copilot 徽标和一些文字。该男子身穿蓝色毛衣，说话时用手比划着。背景是一个现代风格的布景，有绿色的植物和灰色的墙壁。 Microsoft 365 Copilot 的徽标是一个带圆角的正方形。徽标背景为白色，文字“Microsoft 365 Copilot”为黑色。标志的中心是一个彩色的形状，类似于一个立方体，三个侧面可见。形状的颜色有蓝色、紫色和粉色，形状稍微向右倾斜。标志简洁现代，外观干净专业。秒。 4.1 不同领域的图像描述 图 21：野外徽标识别和描述的结果。 GPT-4V 在许多场景下展示了理解徽标的强大能力，包括遮挡、照明条件和方向。 GPT-4V 还可以描述新颖的图标，例如最近发布的 Microsoft 365 Copilot。查看第 4.1 节了解详细讨论。 35 场景理解提示：描述图像。 GPT-4V：该图像是从汽车仪表板摄像头的角度看到的道路视图。该路有两条车道，该车位于右侧车道上一辆银色车辆后面。路边有两个黄色标志，警告司机即将到来的人行横道和左侧的弯道。天空多云，灰色，路边树木和灌木丛。提示：描述图像 GPT-4V：该图像是行车记录仪的屏幕截图，从车内拍摄，显示前方道路的视图。该车在双车道道路上行驶，道路右侧可见限速标志 35 英里/小时。道路两旁都是树木，天空乌云密布，预示着马上就要下雨了。道路左侧可见橙色锥体，表示施工区。远处，有一座立交桥。秒。 4.1 不同领域的图像描述 图 22：场景理解结果。 GPT-4V能够提供有关场景和物体的详细描述。查看第 4.1 节了解详细讨论。 36 提示：你能找到图中灰猫附近的红球吗？ GPT-4V：抱歉，我无法回答这个问题，因为图像中没有可见的红球。反事实示例第二节4.1 不同领域的图像描述 提示：你能看到鸟翅膀上亮蓝色的羽毛吗？ GPT-4V：不，我看不到鸟翅膀上亮蓝色的羽毛。它似乎有棕色和白色的羽毛。提示：你能发现角落里玩耍的粉红色大象吗？ GPT-4V：抱歉，我不能，因为这张图片的角落里没有粉红色的大象在玩耍。背景中只有一个穿着橙色衬衫的孩子和一只熊。提示：你能找到穿蓝色衬衫的棒球运动员吗？ GPT-4V：不，我在这张图片中找不到穿着蓝色衬衫的棒球运动员。所有球员似乎都穿着黑色衬衫。提示：尝试在树后面找到一个大瀑布。 GPT-4V：抱歉，我无法完成此任务，因为给定图像中没有瀑布。提示：你能找到安装在天花板上的蓝色灯具吗？ GPT-4V：抱歉，我在这张图片中找不到安装在天花板上的蓝色照明灯具。我所看到的只是一盏带有白色玻璃灯罩的黑色锻铁枝形吊灯。图 23：反事实示例的结果。 GPT-4V 能够提供有关图像中场景和物体的事实描述。示例图像来自[78]。查看第 4.1 节了解详细讨论。 37 4.2 对象定位、计数和密集字幕 空间关系理解。理解图像中人和物体之间的空间关系是视觉智能的一个重要方面 [61, 14]。在图 24 中，GPT-4V 展示了这方面有前景的功能。它可以识别飞盘和图像中的人之间的空间关系。它还可以识别图像中人和汽车之间的空间关系，并指出相机视角可能会影响他们感知的尺寸。物体计数。图 25 突出显示了我们对 GPT-4V 在对象计数方面的能力的探索。在我们的实验中，我们使用文本提示“计算图像中X的数量”来评估其性能。结果表明，GPT-4V 可以成功计算图像中存在的物体（例如苹果、橙子和人）的数量。然而，当物体被遮挡或场景混乱时，就会出现挑战，这可能会导致计数过程中的错误。在图 25 的左下角，GPT-4V 识别了 12 个人，但正确答案应该是 11。这可能是由于我们在本实验中使用的文本提示有限，需要进一步研究提示技术。对象定位。对象定位[153,76,51]是计算机视觉领域的一个基本挑战。在我们的初步实验中，我们通过使用简单的文本提示“使用边界框定位图像中的每个人”来解决此任务。我们的对象定位实验的初步结果如图 26 所示。研究结果表明，GPT-4V 展示了以文本格式生成边界框坐标的能力，无需单独的文本化框标记 [25, 140, 129, 26, 82, 105 ]。但是，需要注意的是，生成的边界框坐标并不准确。我们在可视化过程中重新调整了预测的边界框坐标。当场景或背景相对简单且不那么混乱时，可以观察到有希望的定位结果。需要进一步的提示技术来增强更复杂和拥挤的环境中的对象定位性能。密集字幕。密集字幕 [62, 84] 涉及为给定图像中的每个感兴趣区域生成详细描述。这项视觉语言领域的高级任务通常需要一个集成多个专家的复杂系统，例如对象检测器、名人识别模型和图像字幕模型。为了探索 GPT-4V 在密集字幕方面的能力，我们使用了指导提示，如图 27 所示。结果非常令人鼓舞，因为 GPT-4V 成功定位和识别图像中的个体，然后提供简洁的信息。每位科学家的描述。 38 提示：人比车大吗？ GPT-4V：不，汽车看起来比图中的人大。然而，照片中物体的视角和距离可能会影响它们的感知尺寸。提示：飞盘和人之间的空间关系是什么？ GPT-4V：根据提供的图像，飞盘和人之间的空间关系是飞盘在人的上方并稍微在人的前方。它似乎也正在远离该男子，就好像它是被他扔掉或释放的一样。空间关系理解秒。 4.2 对象定位、计数和密集字幕 图 24：空间关系理解的结果。 GPT-4V 识别图像中物体之间的空间关系。示例图像来自 [67, 14]。查看第 4.2 节了解详细讨论。 39 对象计数提示：计算图像中苹果的数量。 GPT-4V：图像中有 7 个苹果。提示：数一下图像中苹果的数量。 GPT-4V：图像中有 16 个苹果。提示：数一下图像中橙子的数量。 GPT-4V：图像中有 3 个橙子。提示：数一下图像中的人数。 GPT-4V：图像中有3个人。提示：数一下图像中的人数。 GPT-4V：图像中有4个人。提示：数一下图像中的人数。 GPT-4V：图像中有12个人。秒。 4.2 对象定位、计数和密集字幕 图 25：对象计数结果。 GPT-4V能够确定图像中指定物体的数量。红色突出显示错误答案。查看第 4.2 节了解详细讨论。 40 对象定位秒4.2 对象定位、计数和密集字幕提示：使用边界框定位图像中的每个人。图像大小为 (width, height) = (998,786) GPT-4V：图像中只有一个人，因此该人的边界框为： - 左上：(254, 118) - 右下：( 731, 693) 解释：边界框的左上角点位于 (x, y) = (254, 118)，即图像中人物的左上角。边界框的右下角位于 (x, y) = (731, 693)，即图像中人的右下角。该边界框包围了图像中的整个人。检测到的 Bbox 的可视化：提示：使用边界框定位图像中的每辆车。输入图像的图像尺寸是多少？ GPT-4V：输入图像的图像尺寸为500 x 281像素。黑色汽车的边界框： - 左上角：(63, 114) - 右下角：(196, 220) 白色汽车的边界框： - 左上角：(287, 96) - 右下角：( 474, 220) 检测到的 Bbox 的可视化：提示：使用边界框定位图像中的每个人。输入图像的图像尺寸是多少？ GPT-4V：输入图像的图像尺寸为1000 x 333像素。每个人的边界框： - 第 1 个人（最左边）：(x1, y1) = (22, 108)，(x2, y2) = (170, 300) - 第 2 个人：(x1, y1) = (200, 80) ), (x2, y2) = (290, 270) - 第 3 人：(x1, y1) = (350, 70)，(x2, y2) = (460, 280) - 第 4 人：(x1, y1) = (540, 80), (x2, y2) = (640, 270) - 第 5 个人（最右边）：(x1, y1) = (760, 100), (x2, y2) = (920, 290) 注意：这些边界框坐标是近似值，可能不准确。检测到的 Bbox 的可视化：帧显示图 26：对象定位结果。 GPT-4V 能够生成并近似图像中指定对象的边界框坐标。当仅提供简单的文本提示时，模型在处理更复杂的场景（例如对象遮挡和杂乱的场景）时可能会遇到挑战。红色突出显示错误答案。我们在可视化边界框时重新调整了预测。查看第 4.2 节了解详细讨论。 41 密集字幕部分4.2 对象定位、计数和密集字幕 提示：请按照说明进行操作 1. 告诉我输入图像的大小； 2. 使用边界框定位图像中的每个人； 3. 认识每个人； 4. 为每个边界框生成详细的标题。 GPT-4V： 1.输入图像的大小为1600 x 1067像素。 2. 边界框 1：(x1, y1) = (120, 250), (x2, y2) = (420, 950) - 人物 1 边界框 2：(x1, y1) = (500, 240), (x2 , y2) = (800, 940) - 人物 2 边界框 3: (x1, y1) = (880, 230), (x2, y2) = (1180, 930) - 人物 3 边界框 4: (x1, y1) ) = (1260, 220), (x2, y2) = (1560, 920) - 第 4 人 3. 第 1 人：Yann LeCun 第 2 人：Geoffrey Hinton 第 3 人：Yoshua Bengio 第 4 人：Andrew Ng 4. 边界框标题1：Yann LeCun，计算机科学家，人工智能创始人之一。边界框 2 的说明文字：Geoffrey Hinton，计算机科学家和认知心理学家，以其在人工神经网络方面的工作而闻名。边界框 3 的说明文字：Yoshua Bengio，计算机科学家兼蒙特利尔学习算法研究所联合创始人。边界框 4 的说明文字：吴恩达 (Andrew Ng)，计算机科学家和企业家，以其在深度学习和人工智能方面的工作而闻名。密集字幕的可视化：frame sho 图 27：密集字幕的结果。 GPT-4V 按照文本提示，成功为输入图像生成密集的字幕。红色突出显示错误答案。我们在可视化边界框时重新调整了预测。查看第 4.2 节了解详细讨论。 42 4.3 多模态知识和常识 笑话和模因。笑话和模因通常引用特定事件、流行文化或互联网趋势。理解这些参考文献需要熟悉相关背景和文化知识。掌握视觉元素、它们与文本的关系以及预期的幽默效果可能是一项复杂的任务[99]。此外，模因通常是用户生成的，这使得它们高度多样化且不断扩展。为了评估 GPT-4V 在该领域的能力，我们向 GPT-4V 输入一对 meme 和文本提示。示例文本提示包括“你能解释一下这个模因吗？”以及“这张照片有什么有趣的地方？”图 28 显示了示例结果。我们观察到 GPT-4V 具有从视觉和文本模式收集信息的卓越能力，然后理解模因中嵌入的幽默。科学和知识。我们进一步研究了 GPT-4V 在需要科学知识推理的任务中的能力 [85]。我们通过提供文本提示问题和相应的图像来进行实验。这些问题涵盖广泛的主题，包括地理、物理、生物学和地球科学。在图 29-31 中，我们观察到 GPT-4V 能够根据视觉上下文正确回答科学问题。例如，在图 29 的底行中，GPT-4V 识别了样品 A 和样品 B 的平均粒子速度。通过考虑粒子速度、动能和温度之间的关系，GPT-4V 正确回答了问题。再例如，如图 30 的底行所示，GPT-4V 考虑图中显示的视觉箭头来识别特定食物网中的生产者。此外，如图31所示，当我们提供更具体的提示时，例如“假设您是老师，请用图来解释X”，我们观察到生成的答案采用教程格式并逐步解释主题。多模式常识。在图 32 中，我们访问了 GPT-4V 在多模态常识推理中的能力 [148, 52]。在我们的实验中，我们观察到 GPT-4V 有效地利用图像中呈现的边界框作为视觉提示（例如，[person1] 和 [person2]）来识别个体执行的操作。如图32中的第二个示例所示，根据[person1]和[person2]所穿的礼服以及场景中存在的花卉装饰，可以推断他们正在参加婚礼。此外，当我们提供更具体的输入提示时，例如“假设你是一名侦探，你能从视觉线索中推断出什么？”，GPT-4V 展示了辨别图像中众多细致入微的视觉线索的能力，并提供了一个列表合理的假设。 43 笑话和表情包提示：你能解释一下这个表情包吗？ GPT-4V：这个模因取笑了拖延的想法，以及人们如何将任务推迟到某个特定时间，但如果他们错过了那个时间，他们就会把它推迟得更远。在这种情况下，表情包中的人计划在 8 点做某事，但由于现在是 8 点 05 分，所以他们决定等到 9 点再做。青蛙克米特在床上放松的形象代表了这个人拖延和逃避任务的愿望。提示：这张图片有什么有趣的地方？ GPT-4V：人们可能会觉得这张图片有几件事很有趣： - 这是一幅犀牛画的卡通画，这本身就是一个意想不到且愚蠢的概念。 - 犀牛正在为自己画一幅图画，这又增添了一层幽默感。 - 标题“你看到的世界就是你本来的样子！”，这是一个笑话，讲述的是我们都有自己独特的观点，有时会有点以自我为中心。提示：你能解释一下这个表情包吗？ GPT-4V：这个模因强调了一个人在考试期间笔迹的恶化。前两页字迹工整清晰，中间页字迹稍显凌乱，最后两页字迹几乎难以辨认。该表情包取笑的是，随着考试的进行，一个人的笔迹往往会变得更差，因为他们会变得更加疲倦并急于完成考试。这也意味着在考试结束时，人们的注意力和对细节的关注度会下降。提示：这张图片有什么有趣的地方？ GPT-4V：这张图片很有趣有几个原因。首先，它是一个在互联网上被广泛使用和认可的模因模板。图片左侧是真人秀节目《比佛利山庄的真正主妇》的截图，其中一名演员愤怒地指指点点并大喊大叫。图像右侧是一张猫坐在餐桌旁的照片，面前放着一盘食物，看上去不为所动。这张图片的幽默感来自于两侧的对比——左边愤怒、戏剧性的叫喊和右边漫不经心的猫。它还利用了猫的行为就像人类一样并且对我们的行为不感兴趣的想法。总体而言，图像营造出一种滑稽荒诞的情境，让人发笑。秒。 4.3 多模态知识和常识 图 28：笑话和模因理解的结果。 GPT-4V 展示了理解模因中幽默的令人印象深刻的能力。查看第 4.3 节了解详细讨论。 44 科学知识提示：本初子午线与哪些海洋相交？ GPT-4V：本初子午线与以下海洋相交： - 大西洋 - 南大洋 - 北冰洋 提示：比较每个样本中粒子的平均动能。下图显示了相同密闭刚性容器中的两个纯气体样品。每个彩色球代表一种气体粒子。两个样品具有相同数量的颗粒。哪个样品的温度更高？样品A还是样品B？ GPT-4V：由于样品 A 中的平均颗粒速度高于样品 B（600 m/s 与 540 m/s），因此样品 A 中的颗粒具有更高的平均动能。因此，样品 A 的温度高于样品 B。 4.3 多模态知识和常识 图 29：回答科学问题的结果。 GPT-4V可以从文本和视觉上理解问题，并收集必要的信息来回答问题。示例图像来自[85]。查看第 4.3 节了解详细讨论。 45 提示：以下哪个州最北？ GPT-4V：在地图所示的三个州（亚利桑那州、俄克拉荷马州和特拉华州）中，特拉华州是最北的。提示：哪种生物体是该食物网中的生产者？ GPT-4V：这个食物网的生产者是浆果和花朵、草和种子。这些生物体利用太阳的能量通过光合作用生产自己的食物。科学与知识系4.3 多模态知识和常识 图 30：回答科学问题的结果。 GPT-4V可以从文本和视觉上理解问题，并收集必要的信息来回答问题。示例图像来自[85]。查看第 4.3 节了解详细讨论。 46 科学知识提示：假设你是老师，请用图解释一下蒸发量和蒸散量的区别。 GPT-4V：好的，同学们，今天我们要学习蒸发量和蒸散量之间的区别。我们来看看这个图。首先我们来了解一下什么是蒸发。蒸发是水从液态变为气态的过程。这通常发生在液体表面，如海洋或湖泊，此时水分子获得足够的能量来脱离并形成水蒸气。所以在这张图中，我们可以看到湖里和水坝里的水正在蒸发，变成水蒸气。现在，我们来看看蒸散量。这是两个过程的组合——蒸发和蒸腾。蒸腾作用是植物通过叶子释放水蒸气的过程。所以，在这个图中，我们可以看到树木和植物正在向空气中释放水蒸气，这是蒸散的蒸腾部分。与此同时，土壤和地表的水分也在蒸发。这种蒸发和蒸腾的结合就是我们所说的蒸散。总之，蒸发是水从液态变为气态的过程，而蒸散是蒸发和蒸腾的结合。这两个过程都有助于水循环，对于维持环境中的水平衡非常重要。秒。 4.3 多模态知识和常识 图 31：回答科学问题的结果。当我们使用更具体的文本提示（例如“假设您是老师，请使用图形来解释 X”）时，我们观察到 GPT-4V 可以生成一个简短的教程来解释该主题。查看第 4.3 节了解详细讨论。 47 多模态常识提示：[person3]在做什么？ GPT-4V：[person3] 端着一盘食物，很可能将其提供给餐桌上的顾客。看来他们在一家餐厅担任服务员或服务员。提示：[person1] 和 [person2] 在做什么？ GPT-4V：[人物1]和[人物2]在婚礼上走在过道上。提示：假设你是一名侦探，你能从图像中的视觉线索推断出什么？ GPT-4V：从图像中的视觉线索，我可以推断： - 这个房间属于一个可能是年轻人或青少年的人，从休闲服装和带电脑的桌子可以看出。 - 从桌子和电脑可以看出，此人可能是学生或在家工作的人。 - 此人可能具有时尚意识，多件夹克和鞋子就证明了这一点。 - 该房间可能位于气候较冷的地方，夹克和靴子就证明了这一点。 - 这个人可能不太整洁，杂乱的桌子和挂在门上的衣服就证明了这一点。 - 该房间可能位于一栋较旧或更乡村的建筑内，裸露的管道和破旧的墙壁就证明了这一点。秒。 4.3 多模态知识和常识 图 32：多模态常识推理的结果。示例图像来自 [148, 52]。查看第 4.3 节了解详细讨论。 48 4.4 场景文本、表格、图表和文档推理 场景文本识别。阅读和理解图像中的场景文本是视觉语言中的一项重要任务[118–120, 17]。在我们的实验中，我们利用输入提示“图像中的所有场景文本是什么？”来研究 GPT-4V 识别场景文本的能力。图 33 显示了示例结果。我们观察到 GPT-4V 可以准确识别各种场景中的场景文本，包括手写文本和打印文本。在第 4.5 节中，我们提出了多语言场景的进一步结果。视觉数学推理。在图 34 中，GPT-4V 展示了其解决视觉数学问题的能力。在我们的实验中，我们观察到 GPT-4V 能够从图像中提取基本信息。例如，在图 34 中，GPT-4V 正确识别直角三角形（或正交三角形）的存在，并确定 AB 为 4 个单位，BC 为 3 个单位。此外，我们注意到 GPT-4V 倾向于以结构良好的方式提出解决方案，逐步解决问题，从而展示其提供清晰解释的能力。图表理解和推理。我们进一步研究GPT-4V的图表理解和推理能力。图 35-37 显示了示例结果。在我们的初步探索中，GPT-4V展现了提供图表详细描述的能力。例如，在图 35 中，模型正确地解释了从开始到结束的提案过程。在图 36 中，模型不仅理解给定流程聊天中的程序，还将详细信息转换为 Python 代码。在图 37 的底行中，GPT-4V 显示了对 x 轴和 y 轴的清晰理解，并解释了图表中呈现的关键见解。此外，在我们的实验中，我们观察到 GPT-4V 可以根据图表回答问题。在图 37 的顶行中，GPT-4V 正确计算了平均总加油成本，不包括福特 F150。表的理解和推理。在图 38 中，我们展示了对表格理解和推理的初步调查。与图表实验的结果类似，GPT-4V 在理解表格中的细节以及推理和准确回答相关问题方面显示出有希望的结果。文档理解。图 39 显示了各种类型文档（例如平面图、海报和试卷）的结果。我们观察到 GPT-4V 表现出对文档的理解并提供了合理的回应。例如，它可以准确识别平面图中第二间卧室的浴室位置。它还识别出中国菜“热干面”，并通过场景文本将其与武汉市联系起来。此外，GPT-4V 能够阅读试卷。它准确地重建了 Markdown 中的表格，然后用正确的答案填充表格。我们在 4.6 节中对其编码能力进行了更多探索。在图 40 中，我们通过提供包含多个页面作为输入的技术报告 [126] 来探索更具挑战性的案例。在我们有限的探索中，GPT-4V 表现出了令人印象深刻的结果。通过考虑跨多个页面的上下文，它正确地描述了主要思想和他们提出的方法。然而，它偶尔可能会错过一些实现细节。请注意，数据集应包含 1196+665=1861 个示例，提取的特征应包括定向梯度直方图 (HOG)。我们相信，探索更先进的提示技术（例如逐步思考或采用上下文中的小样本方法）可能会提高模型的性能，而不是同时向模型提示所有页面。 49 场景文本识别提示：图像中的场景文本都有哪些？ GPT-4V：图像中的场景文本是： - 马来貘 - 印度貘 - 位置：马来半岛和苏门答腊岛，靠近水源 - 亲戚：貘只有五种。它们与马和犀牛关系最为密切。 - 消失？森林为貘提供住所、食物和水，但马来西亚和苏门答腊岛的森林正在迅速消失。秒。 4.4 场景文本、表格、图表和文档推理 提示：图像中的场景文本全部是什么？ GPT-4V：图像中的场景文本是： - 假期 - 海滩 - 微笑 - 夏天 - 西瓜 - 人字拖 - 柠檬水 提示：图像中的场景文本全部是什么？ GPT-4V：图像中的场景文本为“3,642,039,031,055”。提示：图像中的所有场景文本是什么？ GPT-4V：图像中的场景文本为： - (NVDA) - NVIDIA - 356.85 - +51.47 - +16.85% 提示：图像中的场景文本全部是什么？ GPT-4V：图像中的场景文字为： - “皇家” - “伦敦” 提示：图像中的场景文字全部是什么？ GPT-4V：图像中包含三个文字：1)“COVID-19 测试”2)“请准备好身份证和保险卡”3)“W @UW Medicine”（这是大学的徽标/品牌） Washington Medicine 提示：图像中的所有场景文本是什么？ GPT-4V：图像中唯一的场景文本是“没有艺术的地球只是‘呃’”。提示：图像中的所有场景文本是什么？ GPT-4V：图像中的场景文本是“通往好莱坞之路：我们中的一些人是如何到达这里的” 提示：图像中的所有场景文本是什么？GPT-4V：图像中的场景文本是：- ” Westfield” - “westfield.com.au” 图 33：场景文本识别结果。GPT-4V 可以在许多具有挑战性的场景中识别场景文本。详细讨论请参阅第 4.4 节。 50 视觉数学提示：等式中的 x 是什么？ GPT-4V：在没有任何关于方程所代表内容的上下文或信息的情况下，我们只能假设“x”是方程中的变量或未知值。在这个方程中，(x + 3) 被平方并且等于4. 求解x时，可以将方程两边同时开平方，去掉左边的指数。这将给我们： √((x + 3)²) = √4 x + 3 = ±2 从这里，我们可以通过两边减去 3 来求解 x。这将为我们提供： x = -1 或 x = -5 因此，在此等式中，x 可以是 -1 或 -5。秒。 4.4 场景文本、表格、图表和文档推理 提示：最后一个方程中的 d 值是多少？ GPT-4V：1）为了求解第一个方程，我们需要隔离方程一侧的 x 变量和另一侧的常数。我们可以从两边减去 4x 开始，以去掉方程右侧的 x 项。这给出了我们： 4x + 11 = 14 接下来，我们可以从两边减去 11 以去掉方程左侧的常数项。这给出了我们： 4x = 3 最后，我们可以将两边除以 4 以隔离方程左侧的 x 变量。由此得出： x = 3/4 2) 为了求解第二个方程，我们可以先从两边减去 7d 来去掉方程左边的 d 项。这样我们就得到了： -4 = 4d - 9 接下来，我们可以在两边都加上 9，以去掉方程右侧的常数项。由此得出： 5 = 4d 最后，我们可以将两边除以 4，以隔离方程右侧的 d 变量。由此得出： d = 5/4 因此，最后一个方程中 d 的值为 5/4。提示：图像中x的值是多少？ GPT-4V：可以使用毕达哥拉斯定理找到图像中x的值，该定理指出，在直角三角形中，斜边（最长边，与直角相对）的平方等于平方和的另外两侧。在这种情况下，斜边是边AC，另外两条边是AB和BC。我们知道 AB 为 4，BC 为 3，因此我们可以将这些值代入方程： a² + b² = c² 3² + 4² = c² 9 + 16 = c² 25 = c² 因此，c（斜边的长度）为5. 由于 x 是斜边的长度，因此 x 等于 5。 图 34：视觉数学推理的结果。 GPT-4V 能够通过结构良好的解决方案理解和解决视觉数学问题。查看第 4.4 节了解详细讨论。 51 流程图理解提示：解释该图 GPT-4V：该图表示团队提案流程的流程图。该过程始于团队成员在会议中提出项目建议。然后团队讨论这是否是一个好主意。如果这个想法不被认为是一个好想法，团队就会拒绝它并且该过程结束。如果团队认为这可能是个好主意但需要更多信息，团队成员会进行进一步的研究并将想法细化为提案。然后团队审查提案并提供反馈。如果提案不合格，则团队成员对其进行修改，然后团队再次进行审核。如果提案通过，团队会将其发送至最终决策流程。如果提案获得批准，团队就会继续该项目。提案流程到此结束。秒。 

## 4.4 场景文本、表格、图表和文档推理 

提示：如图所示，2023 年预计平均常备费用是多少？ GPT-V：根据图像，我们可以看到 2023 年的估计平均固定费用约为 280 - 250 英镑。我们可以通过查看“第三季度电力价格上限”和“第四季度电力价格上限”部分来得出这一结论，其中显示 2023 年的范围为 280 英镑至 250 英镑。但是，值得注意的是，这些是仅是估计值，实际的固定费用可能会根据市场状况、政府政策和供应商定价等多种因素而有所不同。图 35：流程图理解结果。 GPT-4V正确地详细描述了提案过程。查看第 4.4 节了解详细讨论。 52 流程图理解提示：你能将流程图翻译成Python代码吗？ GPT-4V：当然，Python 代码如下： num1 = input("输入第一个数字：") num2 = input("输入第二个数字：") if num1 > num2: print(num1) else: print(num2) 解释： - 前两行对应于流程图中的“Input num1”和“Input num2”块，提示用户输入两个数字。 - 接下来两行对应于“num1 > num2？”块，其中条件语句用于检查第一个数字是否大于第二个数字。 - 如果条件为真，则执行下一行（“Display num1”），并将第一个数字打印到屏幕上。 - 如果条件为假，则执行 else 语句，并将第二个数字打印到屏幕上（“显示 num2”）。 - 然后代码停止，对应于流程图中的“停止”块。秒。 4.4 场景文本、表格、图表和文档推理 图 36：流程图理解结果。 GPT-4V 能够将流程图转换为 Python 代码。查看第 4.4 节了解详细讨论。 53 图表理解与推理提示：不包括福特F150的平均总加油成本是多少？ GPT-4V：要找到不包括福特 F150 的平均总加油成本，我们需要添加丰田 RAV4 和本田思域的总加油成本并除以 2（因为计算中有 2 辆车）。 (82.56 + 70.55) ÷ 2 = 76.55 因此，不包括福特 F150 的平均总燃油成本为 76.55 美元。秒。 4.4 场景文本、表格、图表和文档推理提示：解释图形。 GPT-4V：该图是一个图表，显示论文的质量与其对一个人的职业影响之间的关系。 x 轴代表论文的质量，范围从差到有创意和原创。 Y 轴代表论文对个人职业生涯的影响，影响范围从没有到很大。该图显示，一篇糟糕的论文对一个人的职业生涯影响很小甚至没有影响，而一篇富有创意和原创性的论文则会产生重大影响。随着论文质量的提高，论文对一个人职业生涯的影响也会增加。这表明一个人的工作质量是决定其职业成功的重要因素。图 37：GPT-4V 在理解图表中的细节以及推理和准确回答相关问题方面显示出有希望的结果。查看第 4.4 节了解详细讨论。 54表理解与推理提示：有多少家庭收入超过13000并拥有2辆以上汽车？ GPT-4V：从给定的表格中，我们可以清楚地看到，共有 113 个家庭的收入超过卢比。 13000 且拥有 2 辆以上汽车（13000-16000 范围内有 25 个家庭，16000 及以上范围内有 88 个家庭）。秒。 4.4 场景文字、表格、图表、文档推理提示：哪个国家的利润率最高？ GPT-4V：根据提供的数据，利润率最高的国家是澳大利亚，利润率为19.4%。然而，前三个国家（美国、中国和澳大利亚）之间的差异很小，利润率差异不到 0.3%。图38：我们观察GPT-4V可以了解表中的详细信息，并回答相关问题。查看第 4.4 节了解详细讨论。 55 文档理解提示：描述图像。 GPT-4V：此图像是公寓或公寓的平面图。它显示了房间的布局和尺寸。有一个露台、用餐区、客厅、门厅、两间卧室、一间主浴室和一间客用浴室。平面图是黑白的，是二维图。秒。 4.4 场景文字、表格、图表和文档推理提示：描述海报。这道菜是哪个城市的？ GPT-4V：海报是一道名为“热干面”的中国菜的广告。海报为红色底色，上方白色汉字，写着“热干面，中国味道”。文字下方是这道菜的照片，该菜由面条、上面有肉和蔬菜组成。这道菜盛在一个绿色的碗里，旁边放着红辣椒。海报底部的文字是中文，描述这道菜辣、香、美味。这道菜来自中国湖北省武汉市。它是城市中流行的街头食品，被认为是中国“十大早餐”之一。提示：回答图中问题。 GPT-4V：层|图 1 上的编号 --- | --- 外核 | 3 斗篷 | 2 地壳 | 1 内核 | 4 生成结果的可视化： 提示：第二间卧室的浴室在哪里？ GPT-4V：根据此平面图，第二间卧室的浴室似乎与卧室直接相邻。它标有“WC”，是一个尺寸为 5'2" x 5'2" 的小房间。注意：与左侧所示相同的查询图像，调整大小以节省空间 图 39：文档理解结果。 GPT-4V 可识别三种不同类型的文档并正确回答问题。查看第 4.4 节了解详细讨论。 56 文档理解提示：这是一篇论文《论文格式塔》。详细描述论文并强调他们的贡献。第 1 页 第 2 页 第 3 页4.4 场景文本、表格、图表和文档推理 Page 4 第 5 页 GPT-4V：论文“Paper Gestalt”是菲尼克斯大学计算机科学系 Carven von Bearnensquash 撰写的一篇研究论文。本文讨论了计算机科学研究论文的视觉质量以及它如何影响论文的整体印象。本文首先介绍了论文格式塔的概念，即论文的整体印象。作者认为，论文的视觉质量是给人留下良好印象的重要因素。然后，本文讨论了该领域之前的工作，并强调了本文的贡献，即使用监督学习算法来评估论文的视觉质量。然后本文介绍了方法和实验结果。作者收集了 1196 篇计算机科学研究论文的数据集，并使用监督学习算法来评估论文的视觉质量。该算法根据从论文中提取的一组特征进行训练，例如图形数量、方程数量和参考文献数量。结果表明，该算法能够高度准确地预测论文的视觉质量。本文最后讨论了结果和未来的工作。作者建议未来的工作可以集中在通过合并更多特征并在更大的数据集上进行训练来改进算法。该论文还建议该算法可用于评估其他类型文档的视觉质量，例如技术报告和论文。总的来说，本文的贡献是使用监督学习算法来评估计算机科学研究论文的视觉质量。这是一种新颖的方法，可以帮助研究人员提高论文的视觉质量并给读者留下更好的印象。提示续图 40：文档理解结果。 GPT-4V阅读多页技术报告，理解每个部分的内容，并提供该技术报告贡献的摘要。红色突出显示错误答案。查看第 4.4 节了解详细讨论。 57 4.5 多语言多模态理解 我们评估 GPT-4V 理解多种语言和模态的能力。首先，我们通过评估没有场景文本的自然图像来探索此功能，如图 41 所示。 GPT-4V能够识别不同语言的输入文本提示，并生成相应语言的正确图像描述。在图 41 的第二行中，我们提供英文输入文本提示并指定输出语言。 GPT-4V 遵循指令并以所需语言生成正确的描述。在图 41 的底行中，我们提供了西班牙语的输入提示，并要求 GPT-4V 生成 20 种不同语言的图像描述。我们观察到 GPT-4V 可以处理不同语言的输入和输出文本。此外，我们探索了涉及多语言场景文本识别的场景，其中输入图像可能包含各种语言的场景文本。如图42所示，GPT-4V正确识别并理解来自不同场景的场景文本。如图 43 的前两行所示，我们观察到 GPT-4V 可以识别场景文本，并将其翻译成不同的语言。在图 43 的底行中，我们提供了加泰罗尼亚语维基百科网站的屏幕截图，并指示 GPT-4V 以 20 种不同语言总结信息。 GPT-4V 不仅可以识别加泰罗尼亚语文本，还可以生成精确的摘要并将其翻译成不同的语言。这展示了 GPT-4V 理解和翻译多语言场景文本的能力。我们还探讨了多元文化理解的能力[147, 77]。图 44 显示了此类场景中的示例结果。我们观察到 GPT-4V 能够理解文化的细微差别，并为给定的婚礼图像生成合理的多语言描述。在我们的探索中，我们发现 GPT-4V 可以无缝理解并正确生成不同语言的描述，凸显了其在处理不同语言环境方面的多功能性。 58 多语言图像描述 第二节4.5 多语言多模态理解提示：用法语GPT-4V描述图像：这是一张小柯基犬的图片。他的肤色是棕色和白色的，戴着一条项链，上面有一枚 os 形状的奖章。他走在青青的草地上，舌头晃来晃去。提示：用20种不同语言描述图片 GPT-4V： 1.英语：这是秘鲁马丘比丘的美丽景色。 2.西班牙语：这是秘鲁马丘比丘的美丽景色。 3.法式：这是秘鲁马丘比丘的美丽景色。提示：配置GPT-4V加密协议：安装GPT-4V加密系统 感恩节，滑雪板，滑雪板，滑雪板滑雪，滑雪板滑雪，滑雪板提示：弹出GPT-4V屏幕：屏幕为红色房间s modrýma或čima 。 Cot ě stoj í na zelen是一个sm ě ř uje dop ř edu 。 Jeho tě lo je v pohybu a vypad á ,我不知道该怎么办在 pozad í je vid ě t dal ší č á st tr á vy a nejasně i dal ší我是。提示：用中文描述图像 GPT-4V：输入一个平面设计、平面设计、平面设计、平面设计、平面设计子。它甚至是一片雪花、一片雪花提示：描述 GPT-4V图片：这是一张红色小猫在绿色草地上行走的照片。小猫有一双蓝色的眼睛，走起路来似乎很小心。它被草包围，你可以在背景中看到另一只猫的一部分。 GPT-4V输出续4.德语：这是秘鲁马丘比丘的美丽景色。 5.意大利语：Questa是秘鲁马丘比丘的一道美丽风景。 6.葡萄牙语：这是秘鲁马丘比丘的美丽景色。 7. 俄语： Это 科拉西耶 维德 娜 Мачу - Пикчу  �  佩普8.中文：如果你想念雪花咒。 페루의 마추 피추의 아름다운 ಽ치입니다 。 11. 印地语：这个 Pe Ͼ K 马丘ͪ p Í Chuka 美丽Ǻæ y 是。 带状 不言而喻 贾米尔 拉玛吉奥 比绍 亚里 想法：阿拉伯语12。13。土耳其语：是的，秘鲁的马丘比丘位于马丘比丘山区。 14. 希腊语： Aυτή είναι 微米α εμορρρπ θέα του άτσου Πίτσου στο Περού唷唷 ださっ 耶尔耶 奥 ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ：希伯来语 15. 16. 瑞典语：距离秘鲁的马丘比丘仅几步之遥。 17.挪威：这是秘鲁马丘比丘醒来时的景色。 18.丹麦语：这是秘鲁马丘比丘的美丽景色。 19. 荷兰人：这是秘鲁马丘比丘的真实景色。 20.波兰语：秘鲁马丘比丘小景。提示：描述捷克GPT -4V中的形象：职场上有很多钱，需要花很多钱。 Pes je na zelen é tr á v ě am á otev ř enou tlamu。 Vypad á , ž e se bav í图 41：多语言图像描述的结果。 GPT-4V能够生成不同语言的图像描述。查看第 4.5 节了解详细讨论。 59 多语言场景文本识别第二节4.5 多语言多模态理解 提示：图像中的所有场景文本是什么？ GPT-4V：图像中有两个场景文字：1）“SUPER NINTENDO WORLD”2）“ Super Nintendo World”提示：图像？ GPT - 4V ：图像中的场景文本为： - ΡΡΡΡΡΡΡΡΡΡΡΟΡΡΡΡΟΟΡ​​ 硬币(雅典-罗马- Rion Iapetron) - 29 May 1933 (29 May 1933) -现金(德拉克马) -货币(希腊) -现金ΤAXYΔP ΣΥГ ş Ο ǿ Ń ǿ Τа ş ǿ А - Ε ş АΔΟΣ - ΤΟΥΡ ş ǿ Α （航空邮件、快递、通讯、意大利-希腊-土耳其）- 120（邮票价值，以德拉克马为单位） GPT-4V：图像中的场景文本是阿拉伯语 Bismillah”（ Bismillah 真主 拉瑞姆 ?????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????​​​文本） 提示：GPT-4V： - WELCOME（英语） - bienvenida（西班牙语） - Bienvenue（法语） - Welcome（德语） -welcome（意大利语） 提示：GPT-4V 是什么：法国巴黎艺术博物馆位于在法国巴黎市？GPT-4V：图像中的场景文字是“害怕在街上行走是不正常的！！ ”这是葡萄牙语，翻译过来就是“害怕独自走在街上是不正常的！！ - GPT-4V: GP FIM DA EUROPE - 田径 - António Augustinho 1987 - Fernando Domingos 1988 图 42：多语言场景文本识别结果 60 多语言多模态理解 提示：如果图像以英语以外的语言呈现，请翻译内容GPT-4V：图像内容为葡萄牙语，翻译为“双击添加标题。双击添加字幕。” 提示：总结 20 种语言的信息 GPT-4V 输出续 4. 德语：南阿尔卑斯山是新西兰的一座山脉。 5. 意大利语：南阿尔卑斯山是新西兰的一座山脉新西兰。葡萄牙语：南阿尔卑斯山是新西兰的一座山脉 7.俄语： Южные Альпы - горный 赫雷贝特  �  诺沃伊 Зеландии 。 8. 中文：南麓山ö是新西兿兿帀条屄。アE：日文：南oneone1ëru年龄。韩语: 남부 알프스는 뉴질랜드의 산맥입니다 。 11.印地语：南部 埃尔普斯 新西兰 K a 一 山 系列 是。 12. 孟加拉语：南部 阿尔卑斯山 新西兰的 这是 更多的 山。 ……阿尔巴 阿尔巴尼奥巴赫 嘿 斯拉斯拉埃 贾巴尔 亚里 新西兰：阿拉伯语 13. 14. 土耳其语：Güney Alpler Yeni Zelanda'da bir da ğ系列。 15、印度尼西亚语：南阿尔卑斯山地区的新西兰主要语言。 16.越南语：Alpes phía Nam位于新西兰。 17.泰语：泰语泰语泰语泰语ซี แลนด  18.马来语：Alpen Selatan是新西兰最古老的歌手。 19. 中文：南阿尔卑斯山是新西兰的一系列山脉。 20. 斯瓦希里语：库西尼的阿尔卑斯山脉和新西兰的藏红花山脉。 GPT-4V： 1. 英语：南阿尔卑斯山是新西兰的一座山脉。 2.西班牙语：南阿尔卑斯山是新西兰的一条山脉。 3.法语：南阿尔卑斯山是新西兰的一系列山脉。提示：如果图片以英语以外的语言呈现，请翻译内容。 GPT-4V：英文翻译：“图片[编辑 | 编辑维基文本]提示：如果图片以英语以外的语言呈现，请翻译内容。 GPT-4V：翻译：Angelus 1st Grand Cru Classified Angelus Castle 1996 Saint- Emilion Grand Cru Appellation Saint-Emilion Grand Cru Controlled GPT-4V：图像中的文字是日语，翻译过来就是“早上好，祝你有美好的一天。”提示：如果图片以英语以外的语言呈现，请翻译内容。 GPT-4V：图中的文字是中文，翻译过来就是“麻婆豆腐”。麻婆豆腐是一道受欢迎的中国菜肴，由豆腐和肉末加辣酱制成。提示：如果图片以英语以外的语言呈现，请翻译内容。 GPT-4V：图像中的文字是韩语，翻译为“美味的食物”图 43：多语言文本识别、翻译和描述结果。 GPT-4V能够识别、翻译并生成不同语言的描述。查看第 4.5 节了解详细讨论。 61 多语言多文化理解提示：用英语和图像中描述的地理位置对应的当地语言描述图像。 GPT-4V：中文：此图片显示一对身着中国传统婚礼服装的新人坐在一面红玫瑰墙和一个金色汉字“双喜”前。中文（简体）：指定特定字符的特征 王国的王国的王国的王国的王国的王国的王国“王国”是众所周知的。 （过了很长一段时间，该图像就被称为“shuāng xǐ”或“shuāng xǐ”。） 提示：用英语和图像中描述的地理位置对应的当地语言描述该图像。 GPT-4V：中文：此图片显示一对穿着传统婚礼服装的日本夫妇。男人穿着黑色和服，搭配白色裤裙，女人穿着白色和服，戴着大头饰。日语：这个词是日语的引人入胜的版本 雪花光滑光滑，雪花光滑白い着物を着ています。 （但是dentō-teki和kekkon-shiki的gazō就像Nihon no kappuru o shimeshiteimasu.Dansei wa shiroi hakama或kuroi kimono o kite， josei wa ōkina kazari 或 shiroi kimono o kiteimasu。） 提示：用英语和与图像中描绘的地理位置相对应的当地语言描述图像。 GPT-4V：中文：图片显示一对夫妇穿着埃塞俄比亚传统服装，站在花园里，背景是一棵树。女子身穿带有彩色图案的白色连衣裙，男子则穿着带有类似图案的白色西装。阿姆哈拉语（埃塞俄比亚的官方语言）：是的 图像 由埃塞俄比亚人 文化 衣服 他们没有穿 我们的丈夫 巴莱贝滕 由农民 它被称为。 塞尤图 自由地 鸭绿江 阿勒巴莱巴赫 衣服 做饭 和 温迪图姆 出于同样的原因 阿勒巴莱巴赫 套装 勒贝萨莱赫。提示：用英语和当地语言描述该图像，并对应于图像中描绘的地理位置。 GPT-4V：中文：这张图片显示了一对新婚印度夫妇正在亲吻。新娘穿着传统的红色纱丽，新郎则戴着红色头巾和白色西装。他们坐在鲜花装饰的舞台上。印地语（印度当地语言）：这个 g ͪ v 一 新ͪ婚姻Ǒ ht 印度人 对 到 一 吻 分享 做 色调 Ǒ显示 是。 新娘 一 传统的 红色的 纱丽 穿 留下来 是 和 新郎 一 红色的 头巾 和 安全的 这 套装 穿 拉哈 是。 他们 福 朗 从 装饰 色调 一 论坛 在 坐着 是。秒。 4.5 多语言多模式理解 图 44：多语言多文化理解结果。查看第 4.5 节了解详细讨论。 62 4.6 视觉编码能力4.6 视觉编码能力 Prompt: GPT-4V: GPT-4V: GPT-4V: GPT-4V: Prompt: Prompt: Prompt: 图 45：GPT-4V 根据手写输入生成 LaTex 代码的能力。指令是“生成乳胶代码”。对于每种情况。输出是LaTeX 代码，我们显示渲染的结果。虽然模型无法编写复杂方程的代码（下），但我们可以将其分解为几个简单的方程，而 GPT-4V 能够处理这些方程。查看第 4.6 节了解详细讨论。图 45 说明了基于手写数学方程生成 LaTeX 代码的能力。此功能可以帮助用户更有效地在 LaTeX 中编写方程。尽管该模型无法为较长的方程生成代码，但它可以有效地处理较短的方程。通过将较长的方程分解为较短的组件，该模型能够生成适当的代码。图 46 进一步演示了 GPT-4V 如何将输入图像中的表格重建为 MarkDown/LaTex 代码。图 47 显示了用 Python、TikZ 和 SVG 编写代码来复制输入图形的示例。尽管生成的输出不完全匹配，但布局相似，并且可以轻松修改代码以满足特定需求。 63 GPT-4V：|国家 |销量 |收入|利润| | --- | --- | --- | --- | |美国 | 40,080 | 40,080 $15,971,421 | 15,971,421 美元$3,086,421 | $3,086,421 |中国 | 35,070 | 35,070 $15,866,670 | 15,866,670 美元$3,032,162 | $3,032,162 |澳大利亚 | 27,054 | 27,054 $14,812,566 | 14,812,566 美元$2,868,636 | $2,868,636 |印度 | 23,046 | 23,046 $10,608,174 | 10,608,174 美元1,853,710 美元 | |韩国 | 16,032 | 16,032 $10,494,948 | $10,494,948 $1,975,844 | $1,975,844提示：请阅读此图中的表格并以文本形式返回乳胶风格的重建表格。 GPT-4V：这是乳胶中重建的表格： \begin{tabular},{|c|c|c|c|} \hline Country & Sales Volume & Revenue & Profit \\ \hline USA & 40,080 & \$15, 9 887 & $3,068,421 \\ \hline 中国 & 35,070 & \$15,866,670 & $3,032,162 \\ \hline 澳大利亚 & 27,054 & $14,812,566 & \$2,868,636 \\ \hline 印度 & 23,046 & \$10,6 .174 & \ $1,853,710 \\ \hline 韩国 & 16,032 & \$10,494,948 & \$1,975,844 \\ \hline \end{tabular} 秒4.6 视觉提示的编码能力：请阅读该图中的表格，并以文本形式返回一个 Markdown 风格的重构表格。重建表的可视化 (Markdown)： 注意：与上图相同的查询图像，调整大小以节省空间 重建表的可视化 (LaTex)：约束提示 图 46：GPT-4V 生成 Markdown/LaTex 代码以重建表中的能力图像。红色突出显示重建中的错误。查看第 4.6 节了解详细讨论。 64秒。 4.6 视觉提示的编码能力：生成Python代码来绘制相似的曲线。 GPT-4V：提示：编写python代码生成类似的图形。 GPT-4V：提示：输入svg代码生成如下图像。 GPT-4V：提示：在tick中生成如下图像。 GPT-4V：图 47：GPT-4V 能够编写代码来复制输入数字。我们直接展示Python/TikZ/SVG渲染的图形作为GPT-4V的响应。渲染的图形与输入图形大致对齐，并且可以轻松调整代码。 GPT-4V 图表。查看第 4.6 节了解详细讨论。 65 5 与人类的交互：视觉参考提示 指向特定的空间位置是多模态系统人机交互的一项基本能力，例如进行基于视觉的对话。如5.1节所示，GPT-4V可以很好地理解直接绘制在图像上的视觉指针。基于这一观察，我们提出了一种新颖的模型交互方法，名为“视觉参考提示”。核心思想是直接编辑图像像素空间来绘制视觉指针或场景文本作为人类参考指令，如图 50 所示。我们在 5.2 节中详细介绍了它的用途和优点。最后，第 5.3 节探讨了如何让 GPT-4V 生成视觉指针输出以与人类交互。这些视觉指针对于人类和机器来说都可以直观地生成和理解，使其成为人机交互的良好渠道。 5.1 了解指向输入 如图 48 所示，GPT-4V 可以理解直接覆盖在图像上作为指针的不同类型的视觉标记，例如圆圈、方框和手绘图。这种能力有助于 GPT-4V 生成接地字幕，这是一个众所周知的挑战性问题，让传统的视觉语言模型 [128] 生成专注于特定感兴趣区域的视觉描述。密集字幕方法 [62, 138] 使用裁剪框或掩模区域来生成局部描述，但通常会忽略全局图像上下文并产生次优描述。视觉指向提供了一种自然的方式来指示感兴趣的区域，同时保持全局图像上下文。例如，左上角的示例重点提供了对尖头麦格纳啤酒的全面描述，同时还提到了啤酒瓶放在桌子上的全局图像上下文。覆盖在图像上的视觉指针的直观替代方案是以数字文本格式表示的区域坐标。如图 49 所示，GPT-4V 可以理解开箱即用的坐标，通过文本标记实现空间引用的能力，而无需像之前的视觉语言模型那样进行额外的框标记微调 [129, 143]。尽管功能很有前途，但我们注意到我们当前的提示在空间上不太精确。例如，在图 49 的左上示例中，GPT-4V 提到了周围的物体餐巾和水瓶，即使该区域中只有啤酒瓶 (0.47、0.48、0.55、0.87)。总体而言，就我们实验的提示而言，与文本坐标相比，GPT-4V 在使用重叠视觉指针提示时工作更可靠。这种独特的能力促使我们探索一种新的提示方法，即视觉引用提示。 66 接地描述（重叠视觉指针） 提示：描述图像中的指示区域。 GPT-4V：图像中的尖角区域是麦格纳啤酒的绿色玻璃瓶，带有红色标签和金色瓶盖。它坐在一张黑色的桌子上，周围放着其他物品，如水瓶、餐巾和雨伞。提示：描述图像中的指示区域。 GPT-4V：图像中的尖角区域包含一张白色折叠餐巾和一套用另一张白色餐巾包裹的银器，放置在黑色桌子上。这很可能是餐厅用餐的餐桌布置。提示：描述图像中的两个尖头物体。 GPT-4V：第一个尖头物体（黄色箭头所示）是一把白色遮阳伞。它有一个尖顶并连接到金属杆上。雨伞打开，为室外休息区提供遮荫。第二个尖头物体（由红色箭头指示）是麦格纳啤酒的绿色玻璃瓶。该瓶子有一个尖颈，并盖有一个金色金属盖。它坐在一张黑色的桌子上，前面有一张白色的餐巾。提示：描述图像中的指示区域。 GPT-4V：图像中的尖头区域是一个绿色啤酒瓶，上面有红色标签，上面写着“MAGNA”。瓶子直立在黑色桌子上，旁边放着一张白色餐巾。提示：描述图像中的指示区域。 GPT-4V：图像中的尖角区域是带有垂直板条的木栏杆的一部分。它位于俯瞰大海的庭院边缘。栏杆似乎被漆成白色并且部分被遮挡。提示：描述图像中的指示区域。 GPT-4V：图像中的尖角区域是电线上的一排悬挂灯。灯又小又圆，沿着电线均匀分布。电线在两根杆子之间拉伸，位于配有桌子和遮阳伞的露台区域上方。这些灯看起来是装饰性的，可能用于在晚上提供环境照明。秒。 5.1 理解指向输入 图 48：GPT-4V 理解直接覆盖在图像上的视觉指针。利用局部和全局视觉信息进行接地描述是一种独特的应用场景。查看第 5.1 节了解详细讨论。 67 秒。 5.1 了解指向输入 接地描述（文本格式的区域坐标） 提示：根据给定的坐标定位区域，并描述区域中的内容。区域由 (x1,y1,x2,y2) 坐标表示。 x1 x2 是最左边和最右边的位置，标准化为 0 到 1，其中 0 是左边，1 是右边。 y1 y2 是最顶部和最底部的位置，标准化为 0 到 1，其中 0 是顶部，1 是底部。描述图像中区域 (0.47, 0.48, 0.55, 0.87) 的相对位置。描述该相对位置的内容。无需提及图像其他部分的内容。 GPT-4V：区域（0.47、0.48、0.55、0.87）位于图像的右中部分。它覆盖了表格的一小部分区域并延伸到图像的底部。该地区最显眼的物品是一瓶绿色的麦格纳啤酒。在这个区域还可以看到一张白色的餐巾和一个水瓶的一部分。背景显示了庭院和海洋的一部分。提示：根据给定的坐标定位区域，并描述区域内的内容。区域由 (x1,y1,x2,y2) 坐标表示。 x1 x2 是最左边和最右边的位置，标准化为 0 到 1，其中 0 是左边，1 是右边。 y1 y2 是最顶部和最底部的位置，标准化为 0 到 1，其中 0 是顶部，1 是底部。描述图像中区域(0.01,0.09,0.29,0.21)的相对位置。描述该相对位置的内容。无需提及图像其他部分的内容。 GPT-4V：区域（0.01、0.09、0.29、0.21）位于图像的左上角。它大约覆盖图像宽度的 28% 和高度的 12%。在这个区域，有一部分白色的伞和一串灯。背景显示了清澈的蓝天和棕榈树。提示：根据给定的坐标定位区域，并描述区域内的内容。区域由 (x1,y1,x2,y2) 坐标表示。 x1 x2 是最左边和最右边的位置，标准化为 0 到 1，其中 0 是左边，1 是右边。 y1 y2 是最顶部和最底部的位置，标准化为 0 到 1，其中 0 是顶部，1 是底部。描述图像中区域(0.01,0.67,0.36,0.91)的相对位置。描述该相对位置的内容。无需提及图像其他部分的内容。 GPT-4V：图像中的区域（0.01、0.67、0.36、0.91）位于左下角，大约覆盖图像宽度的三分之一和高度的四分之一。在这个区域，有一张黑色的桌子，上面铺着白色的餐巾，一瓶麦格纳啤酒和一瓶水。桌子位于前景，而背景则显示出带有白色雨伞和椅子的庭院的一部分。提示：根据给定的坐标定位区域，并描述区域内的内容。区域由 (x1,y1,x2,y2) 坐标表示。 x1 x2 是最左边和最右边的位置，标准化为 0 到 1，其中 0 是左边，1 是右边。 y1 y2 是最顶部和最底部的位置，标准化为 0 到 1，其中 0 是顶部，1 是底部。描述图像中区域 (0.47, 0.48, 0.55, 0.87) 的相对位置。描述该相对位置的内容。无需提及图像其他部分的内容。 GPT-4V：区域（0.47、0.48、0.55、0.87）位于图像右侧，略低于中心。它覆盖了桌子和背景的一小部分。在这个区域，桌子上有一瓶绿色的麦格纳啤酒，旁边有一张白色的餐巾。背景中有一把雨伞的一部分和几把椅子。 0.48 0.87 0.47 0.55 0.67 0.91 0.01 0.36 0.48 0.87 0.47 0.55 0.09 0.21 0.01 0.29 图 49：覆盖在图像上的视觉指针的替代方法是以数字文本格式表示的区域坐标。 GPT-4V可以理解对应于中心啤酒瓶顶部的坐标，例如（0.47，0.48，0.55，0.87），（0.01，0.09，0.29，0.21）和（0.01，0.67，0.36，0.91）分别是左灯串和左下角的桌子组。我们观察到，与视觉引用提示中的视觉指针相比，GPT-4V 在使用文本坐标提示时工作不太可靠。查看第 5.1 节了解详细讨论。

## 5.2 视觉引用提示

受到GPT-4V 强大的视觉指向和场景文本理解能力的启发，我们探索了一种与GPT-4V 交互的新方法，即视觉引用提示。视觉参考提示是一种补充技术，它不是编辑文本空间的传统提示技术，而是直接编辑输入图像的像素空间以进行人机交互。这种视觉提示可以提供与图像更细致、更全面的交互，从而有可能释放模型更广泛的响应。例如，在图50（1）中，GPT-4V自然地将箭头指向的对象与给定的对象索引相关联，从而简化了剩余的视觉推理和文本输出；在(2)中，GPT-4V理解图像上写的问题并指出相应的边缘或角度，为基础视觉对话提供细致入微的界面；在(3)中，人类可以指向图形内部的任意区域，以帮助GPT-4V更好地理解复杂的文档和图表；在(4)中，该模式可以简洁地表示为箭头和场景文本“+点”，因此有助于GPT-4V预测下一张图像。作为松散地基于图像的文本提示的补充，视觉引用提示提供了一种新颖的交互方法，可以促进各种用例，并在图 51 和第 9 节中进行了附加演示。

## 5.3 生成指向输出

第 5.1 节讨论了 GPT-4V 的能力理解人类产生的视觉指向。一个自然的问题是：GPT-4V能否生成自己的指向输出，从而促进人机交互中的闭环交互过程？图 52 探讨了通过让 GPT-4V 预测文本格式的区域坐标来生成视觉指向输出。我们提示 GPT-4V 将文本（例如，“蓝色斯巴鲁 SUV”的文本）或参考图像（例如，“黑色奥迪轿车”的图像）引用的对象接地。与 GPT-4V 理解坐标输入的观察结果类似，该模型对空间位置有一个粗略的理解，但对于实验中使用的提示并不准确。例如，在图 52 的“绘图可视化”中，GPT-4V 可以大致识别查询中提到的蓝色 SUV 和黑色轿车，但它很难创建紧密贴合的边界框。我们观察到，在提示中包含基于示例的指令有助于 GPT-4V 理解坐标的定义，并随后生成更好的指向输出。虽然生成的指向输出可能无法完美覆盖查询区域，但它们仍然为模型交互、解释和帮助多步骤视觉推理提供了有价值的工具。具体来说，人类可以解释指向输出，以更好地理解 GPT-4V 的参考，或者由 GPT-4V 本身解释，以基于先前的输出进行进一步推理。如图 52 底部所示，GPT-4V 能够解释其生成的指针，并根据图 48 中的提示提供基础描述。此外，GPT-4V 本身的迭代指向生成和理解可以帮助复杂的多点分析。跳跃扎根的视觉推理任务。 GPT-4V 能够解构问题，生成不同的视觉标记，以迭代地关注每个子步骤的不同图像区域，最终整理信息以制定最终答案。 69秒。 5.2 目视提示 （1）提示：圆圈玻璃里有什么？对象 1 还是对象 2？描述什么是物体 1 和物体 2。然后检查圆圈玻璃里有什么。 GPT-4V：物体1是一个玻璃瓶水。它是透明的，上面有一个蓝色标签。物体2是一瓶麦格纳啤酒的玻璃瓶。它是绿色的，上面有一个红色和白色的标签。在圆圈玻璃中，它看起来是一种透明液体，可能是水。因此，圆圈玻璃中的内容物很可能来自对象 1，即玻璃瓶水。 8（2）提示：回答下图问题。提供中间步骤。 GPT-4V：要找到蓝色箭头边的长度，我们可以使用毕达哥拉斯定理，因为我们有一个直角三角形。该定理指出 a² + b² = c²，其中 a 和 b 是直角三角形的两条边，c 是斜边。代入我们得到的值，我们得到： 4² + 8² = c² 16 + 64 = c² 80 = c² √80 = c 8.94 ≈ c 因此，蓝色箭头边缘的长度约为 8.94。为了找到绿色箭头处的角度，我们可以使用正切函数，因为我们有角度的对边和邻边。正切函数指出 tan θ = 相反/相邻。代入我们得到的值，我们得到： tan θ = 4/8 tan θ = 1/2 θ = tan^-1(1/2) θ ≈ 26.57° 因此，绿色箭头处的角度约为 26.57°。 (3) 提示：哪条圈出的线显示了不同的比较趋势？提供中间步骤。 GPT-4V：显示不同比较趋势的圆圈线是 2022 年 USNCO 本地部分考试。 中间步骤： 1. 分析表中的数据并查找比较趋势中的任何差异。 2. 请注意，在除 2022 年 USNCO 本地部分考试之外的所有行中，GPT-4（无视力）列的分数低于 GPT-4 列。 3. 这意味着在所有其他行中，具有视觉的 GPT-4 模型比不具有视觉的 GPT-4 模型表现更好。 4. 然而，在 2022 年 USNCO 地方考试行中，GPT-4（无视力）栏的分数高于 GPT-4 栏。 5. 这是与其余行不同的比较趋势，表明在该特定检查中，没有视力的 GPT-4 模型比有视力的 GPT-4 模型表现更好。 （4）提示：回答下图中的问题。提供中间步骤。 GPT-4V：序列中的下一个图像将是中心有一个点的星星。这是因为该序列似乎遵循一种模式，其中形状在菱形和星星之间交替，并且每隔一个图像就会在形状中心添加一个点。中间步骤： - 首先，我们可以观察到序列在菱形和星形之间交替。 - 接下来，我们可以看到每隔一个图像就会在形状中心添加一个点。 - 根据这个模式，我们可以预测下一张图像将是一颗中心有一个点的星星。图50：视觉引用提示直接编辑输入图像作为输入提示，例如绘制视觉指针和场景文本。作为文本提示的补充，视觉引用提示提供了更细致、更自然的交互，例如，(1) 将指向的对象与索引相关联，(2) 指向图像进行提问，(3) 突出显示文档和表格中的行，(4 ）在图像上绘制图案，以及许多其他新颖的用例。查看第 5.2 节了解详细讨论。 70 秒5.2 视觉参考提示 提示：该图标是用来做什么的？ GPT-4V：图中圈出的图标是麦克风图标。它用于激活 Bing 上的语音搜索功能。用户可以单击此图标并对着设备的麦克风说话来提出问题或搜索内容，而无需输入内容。这对于免提搜索或可能打字有困难的用户很有帮助。提示：重点新闻讲了什么？ GPT-4V：重点新闻是谈论ChatGPT的新功能，它允许用户创建个性化指令。据说此功能可以帮助用户更好地管理他们的对话并改善他们使用聊天机器人的体验。提示：海报的这一部分突出了什么？ GPT-4V：海报的这一部分重点介绍了 ReCo 框架，这是该研究的主要贡献。它解释了该框架如何工作以及它的作用。 ReCo框架是一个区域控制的文本到图像生成模型，可以根据文本描述生成高质量的图像。它还显示了框架的不同组件以及它们如何相互交互。 ReCo 框架的设计灵活且易于扩展，与其他文本到图像生成方法相比，它已被证明可以提高图像生成质量并实现更好的语义连贯性。提示：幻灯片中这两个实验有什么区别？ GPT-4V：幻灯片中显示的两个实验之间有一些关键区别： 1. 任务：第一个实验（左侧）专注于视觉基础任务，其中模型被训练来识别和定位图像中的对象。第二个实验（右侧）专注于图像字幕任务，其中模型被训练为图像生成描述性字幕。 2. 数据集：第一个实验使用 Flickr30k Entities 数据集，其中包含带注释的对象边界框的图像。第二个实验使用 MSCOCO 和 VQA2 数据集，其中包含带有相关标题的图像。 3. 评估指标：第一个实验使用平均精度指标来评估模型在视觉基础任务上的性能。第二个实验使用 BLEU 和 CIDEr 指标来评估模型在图像字幕任务上的性能。总体而言，这两个实验旨在评估 UniTAB 模型在不同任务和数据集上的性能，并展示其使用单个模型处理多个任务的能力。图 51：视觉参考提示增强了人与计算机之间的无缝交互。这在与计算机和移动图形用户界面（GUI）的集成以及理解文档和幻灯片方面提供的支持中显而易见。查看第 5.2 节了解详细讨论。 71秒。 5.3 生成指向输出 提示：找到所涉及的对象并表示区域的位置。区域由 (x1,y1,x2,y2) 坐标表示。 x1 x2 是最左边和最右边的位置，标准化为 0 到 1，其中 0 是左边，1 是右边。 y1 y2 是最顶部和最底部的位置，标准化为 0 到 1，其中 0 是顶部，1 是底部。例如，啤酒瓶所在区域的 (x1,y1,x2,y2) 坐标为 (0.47, 0.48, 0.55, 0.87)。对于下图中，蓝色斯巴鲁 SUV 所在区域的 (x1,y1,x2,y2) 坐标是多少？ GPT-4V：蓝色 Subaru SUV 所在区域的 (x1,y1,x2,y2) 坐标为 (0.68, 0.57, 0.95, 0.95)。绘图可视化：请参阅下面的查询图像 接地描述提示：描述图像中的指示区域。 GPT-4V：红色的尖头区域是建筑物侧面较大壁画的一部分。该特定区域中的内容似乎描绘了一辆停在停车场的蓝色汽车，可能是一辆 SUV。汽车面向图像的右侧，似乎位于左侧有一条白线的停车位。提示：找到所涉及的对象并代表该区域的位置。区域由 (x1,y1,x2,y2) 坐标表示。 x1 x2 是最左边和最右边的位置，标准化为 0 到 1，其中 0 是左边，1 是右边。 y1 y2 是最顶部和最底部的位置，标准化为 0 到 1，其中 0 是顶部，1 是底部。例如，啤酒瓶所在区域的 (x1,y1,x2,y2) 坐标为 (0.47, 0.48, 0.55, 0.87)。对于下图，其中有对象的区域的 (x1,y1,x2,y2) 坐标是多少？ GPT-4V：黑色奥迪汽车所在区域的 (x1,y1,x2,y2) 坐标约为 (0.35, 0.55, 0.55, 0.85)。这是基于汽车最左和最右位置分别约为图像宽度的 35% 和 55%，最顶部和最底部位置分别约为图像高度的 55% 和 85%。绘图可视化：请参阅下面的查询图像 接地描述提示：描述图像中的指示区域。 GPT-4V：红色尖角区域的物体是一辆停在停车场的黑色汽车，具体来说是一辆轿车。它似乎是一款较新的车型，具有闪亮的外观和有色窗户。 0.48 0.87 0.47 0.55 0.48 0.87 0.47 0.55 图 52：GPT-4V 可以利用其对坐标的理解来生成视觉指向输出，从而为文本或视觉查询对象奠定基础。使用基于示例的指令可以帮助 GPT-4V 理解坐标定义，从而生成更好的指向。虽然输出空间区域并不精确，但该方法能够实现视觉指向的“理解（即基础描述）和生成”循环，从而形成一种有效的人机交互方式。查看第 5.3 节了解详细讨论。

# 6 时间和视频理解

在本节中，我们讨论时间和视频理解功能。尽管 GPT4V 主要以图像作为输入，但评估其对时间序列和视频内容的理解仍然是其整体评估的一个重要方面。这是因为现实世界的事件会随着时间的推移而展开，而人工智能系统理解这些动态过程的能力对于现实世界的应用至关重要。时间预期、时间排序、时间定位、时间推理和扎根时间理解等功能有助于衡量模型在理解事件序列、预测未来事件以及随时间的上下文分析活动方面的熟练程度，所有这些都在一系列静态图像中进行。尽管以图像为中心，GPT-4V 仍能够以类似于人类理解的方式理解视频和时间序列。为了增强 GPT-4V 等复杂人工智能模型的多功能性和适用性，这方面的测试对其开发和完善至关重要。对于本节即将进行的实验，我们将使用多个选定的视频帧作为输入来测试模型理解时间序列和视频内容的能力。 6.1 多图像排序 在本小节中，我们证明 GPT-4V 可以准确理解和分析视频帧序列。在逐帧分析中，GPT-4V 可以识别活动发生的场景，从而提供更深入的上下文理解。如图53所示，该模型不仅仅局限于识别环境；它还准确地解释了视频中个人所执行的动作。 GPT-4V 可以理解各种人体姿势的顺序和背景，并智能地将它们与正在进行的活动关联起来。通过了解识别之外的姿势变化，GPT-4V 可以从人类运动和动作的微妙之处中获取意义。由于这种详细的理解水平，GPT-4V 可以捕捉视频中发生的事情的本质，提供丰富而细致的见解，而不仅仅是识别对象和场景。 

## 6.2 视频理解时间顺序

时间排序是时间常识的关键要素，也是 GPT-4V 能力评估的重要组成部分。这包括为模型提供一系列打乱的图像，并衡量其辨别因果关系以及时间进程的能力。对此类关系的理解需要能够以逻辑连贯且时间准确的方式重新排序序列。图 54 说明了长期时间排序的示例，其中 GPT-4V 呈现有一系列描绘寿司制作事件的打乱图像帧。尽管存在混乱，GPT-4V 仍能有效识别事件并确定寿司制作过程的适当时间顺序。此外，图 55 提供了短期时间排序的示例。给定指定的动作，例如打开或关闭门，GPT-4V 展示了其理解图像内容并确定事件的正确顺序的能力。这些例子凸显了 GPT-4V 在时间常识方面的能力，增强了其准确理解长期和短期序列的能力。时间预期。我们展示了 GPT-4V 在给定一组初始帧的情况下预测未来事件的能力。长期和短期的例子用于验证这种预测未来事件的能力。图 56 的右侧以足球点球为例说明了 GPT-4V 预测短期事件的能力。由于它对比赛的固有结构和规则的理解，在给出前几帧的情况下，它可以准确地预测踢球者和守门员的典型下一步动作。此外，如图56左侧所示，寿司准备序列说明了GPT-4V的长期预期能力。通过根据视觉提示理解活动，GPT-4V 不仅可以识别寿司准备过程中的当前进度，还可以准确预测后续步骤，展示了其在较长时间内解释和预测复杂的多步骤过程的能力。这种短期和长期时间预期的结合使 GPT-4V 能够捕获和理解具有不同时间结构和复杂性的活动。时间定位和推理。图 57 说明了 GPT-4V 在时间定位和推理方面的功能。它准确地识别球员击球的精确时刻。 Fur73 动作识别部分6.1 多图像排序提示：解释图像和人正在采取的动作。 GPT-4V：图像显示一个穿着动作捕捉服的人在配有多个摄像机和传感器的工作室中。该人正在进行俯卧撑练习。在第一张图片中，人处于起始位置，双臂伸展，身体呈一条直线。在第二张图片中，该人正在将身体向地面放低。在第三张图片中，该人处于俯卧撑的底部，胸部靠近地面。在第四张图片中，该人正在将身体推回到起始位置。图 53：视频帧序列理解：解释人体姿势并从视频序列中得出相关见解。查看第 6.1 节了解详细讨论。此外，GPT-4V 通过推断守门员与球之间的关系来判断守门员是否成功挡球，展示了其对因果关系的理解。在给出的示例中，了解守门员是否可以阻挡球不仅涉及识别守门员和球的空间位置，还涉及了解它们相互作用的动态并预测这些动态的结果。这表明模型的推理能力相当复杂。 74 临时排序部分6.2 视频理解提示：分析图像并决定它们应该显示的正确顺序。 GPT-4V：图像显示的正确顺序是： 1. e - 搅拌米饭 2. c - 将米饭放在海藻上 3. b - 添加馅料 4. a - 切卷 5. d - 完成的寿司卷放在盘子上。 abcde 提示续 图 54：长期时间排序：GPT-4V 呈现有描绘寿司制作事件的打乱图像帧。虽然寿司制作过程是无序的，但 GPT-4V 能够识别事件并确定正确的时间顺序。查看第 6.2 节了解详细讨论。 75 临时排序部分6.2 视频理解提示：开门时，决定门的正确显示顺序。 GPT-4V：正确的顺序是： 1. a - 人靠近门 2. b - 人开门 3. c - 人从门进入。 abc 提示：要关闭一扇门，请确定它们应显示的正确顺序。 GPT-4V：正确顺序：1) c - 人站在门口 2) b - 人开始关门 3) a - 人完全关门 abc 图 55：短期时间顺序：给出指定的动作，例如开门或者关上门，GPT-4V 展示了其理解图像内容并确定与指定动作相对应的正确顺序的能力。查看第 6.2 节了解详细讨论。 76 时间预期部分6.2 视频理解提示：根据图像预测接下来会发生什么。 GPT-4V：从图像来看，身穿白色球衣的球员正在主罚点球。下一个可能的事件是球员将球踢向球门，试图得分。身穿黑色球衣的守门员将尝试封堵射门。提示：分析图像并决定下一步应该做什么。 GPT-4V：图像显示了寿司卷的制作过程。第一张图片显示米饭与醋在碗中混合。第二张图片显示将米饭铺在一片海藻上。第三张图显示了在卷中添加了鲑鱼和黄瓜。接下来的步骤是用竹席卷寿司，将卷切成小块，并与酱油和芥末一起食用。图 56：短期和长期时间预期：GPT-4V 捕获并理解具有不同时间结构和复杂性的活动。查看第 6.2 节了解详细讨论。 77 时间定位和推理部分6.2 视频理解提示：球员在哪一帧踢球？守门员挡住了球吗？ c 提示续 GPT-4V：球员在 c 帧处踢球。球没有被守门员阻挡，因为在 f 帧中可以看到球在网内，而守门员在地面上。图 57：时间定位和推理：GPT-4V 通过准确识别球员何时击球来展示时间定位的能力。它还通过根据守门员与球的交互确定球是否被阻挡来演示因果推理。查看第 6.2 节了解详细讨论。 78 扎根时间理解 第二节6.3 视频视觉参考提示 提示：描述并总结圈出的人在做什么？ GPT-4V：圈出的人是一名站在长凳旁边的男子，似乎正在与坐在长凳上的另一名男子交谈。在第二张图片中，圈出的人指向某物，在第三张图片中，他顽皮地假装要打另一个人。总体而言，圆圈中的男子似乎正在与另一个男子进行友好的交谈并开玩笑。提示：总结该人的活动。 GPT-4V：圈出的人坐在长凳上，然后站起来调整衬衫。图 58：扎根的时间理解：GPT-4V 可以将时间理解应用于特定的感兴趣的人（用圆圈表示）。查看第 6.3 节了解详细讨论。 6.3 用于接地时间理解的视觉参考提示 第 5 节说明了 GPT-4V 在视觉参考提示方面的功能。在本节中，我们的目标是通过测试视觉参考提示来扩展此功能以进行时间理解。这一进步增强了对视频理解任务的控制。扎根的时间理解。扎根的时间理解构成了 GPT-4V 功能的另一个重要方面，我们使用图像帧序列中的指向输入来探索这一点。图 58 通过演示 GPT-4V 如何将时间理解应用于特定的感兴趣的人（用圆圈表示）来举例说明。 GPT-4V 可以以与相应时间顺序一致的方式准确描述事件，重点关注圈出的个体的活动。除此之外，GPT-4V 展示了对事件的更精细的理解，认识到交互的本质。例如，GPT-4V 可以区分友好互动和暴力事件，这表明它不仅能够理解事件的时间流，而且能够解释所发生的互动的基调和性质。这表明 GPT-4V 有能力处理和理解给定序列中复杂的时间和社会线索，为其理解增加了一层深度。

# 7 抽象视觉推理与智商测试

对抽象视觉刺激和符号的理解和推理是人类智力的一项基本能力。本节检查 GPT-4V 是否可以从视觉信号中抽象语义，并可以执行不同类型的人类智商 (IQ) 测试。 

## 7.1 抽象视觉刺激

人类可以从抽象且常常模糊的视觉刺激中推断出语义。图 59 探索了 GPT-4V 解释七巧板的方法 [31,97,43,59]。七巧板是一种传统的几何拼图，由七个称为 tans 的扁平部件组成，这些部件组合在一起形成形状，但部件之间不会重叠。例如，GPT-4V 解释图 59 中的子图 7 最好地说明了一只飞翔的鹅，并为其他子图提供了推理描述，例如 4. 人或机器人、9. 船或帽子、以及 10. 狗或狐狸。 GPT-4V 还能够理解其他格式的抽象视觉图 [127,16,150]，例如图 59 中卡通人物的 ASCII 文本艺术和图 61-62 中的符号输入。 

## 7.2 部件和对象的发现和关联

发现和关联对象部件[139, 44]是另一个重要的抽象视觉推理能力。人类可以轻松地发现对象部分如何组成具有语义意义的对象。图 60 设计示例来探测 GPT-4V 关联对象部分的能力。在左边的例子中，我们要求 GPT-4V 根据对象部分的语义来定位它。在右侧的示例中，要求 GPT-4V 关联由 SAM [65] 分割的对象部分。 GPT-4V 可以处理所有物体部分的图形，并将它们以语义上有意义的方式关联起来，形成右下角可视化的男孩。 

## 7.3 韦克斯勒成人智力量表

第 7.1 节展示了 GPT-4V 的抽象视觉理解能力。作为进一步的挑战，GPT-4V 被要求执行来自人类智商 (IQ) 测试的不同抽象推理任务。韦克斯勒成人智力量表[133]被认为是“智商黄金标准测试”之一，旨在通过一系列子测试来全面测量个人的认知能力。图 61 显示了每个子测试类别的代表性问题和 GPT-4V 的输出。 GPT-4V 在抽象推理、仅用文本回答问题、符号视觉输入和自然图像方面展现了前景。例如，右下示例显示 GPT-4V 可以解释类比问题并找到鞋子的最佳比较。 7.4 Raven 的渐进矩阵 Raven 的渐进矩阵（RPM）[109] 是另一种众所周知的非语言智力测试，旨在测量抽象推理和解决问题的能力。该测试旨在最大限度地减少语言、文化和正规教育对测试表现的影响，使其适合测试人工智能模型[16,150,55]。每个测试样本包含三张或八张图像，排列成 2×2 或 3×3 矩阵，其中缺少一张图片。目标是通过识别提供的样本中的模式从多个候选图像中选择下一个图像。在我们的方法中，我们通过将整个问题页面作为单个图像发送来挑战 GPT-4V，而不是将其转换为交错的图像文本对，类似于人类进行 IQ 测试的方法。如图 62 所示，GPT-4V 无需经过处理的文本描述或子图即可生成合理的答案。然而，我们也注意到，将整个问题图像分解为交错的文本和子图（如图 63 所示）确实简化了任务，并使 GPT-4V 产生更可靠的答案。 80 秒7.1 抽象视觉刺激 7. 8. 9. 10. GPT-4V：最能说明飞翔的鹅的七巧板是数字 7。它具有鹅的身体和翅膀的三角形形状，顶部的较小三角形可以代表鹅的形状。头部和颈部。其他图形可以代表各种事物： 
1. 火箭或塔 
2. 蝴蝶或蝙蝠 
3. 问号或蛇 
4. 人或机器人 
5. 山脉或王冠 
6. 房屋或一座寺庙 
7. 一只飞雁（如上所述） 
8. 一只鸟或一条鱼 
9. 一艘船或一顶帽子 
10. 一只狗或一只狐狸。

提示：七巧板是一种几何拼图，由七块平板组成，形成形状。这里有十个抽象七巧板。哪一个最能说明雁翔的情况？其他人物是什么样子的？ 1. 2. 3. 4. 5. 6. 提示继续提示：这是一个抽象的图形。你能认出其中有多少个角色以及它们源自哪部动画片吗？ GPT-4V：这个抽象图形中有四个字符。它们源自动画片《南方公园》。角色是埃里克·卡特曼、凯尔·布罗夫洛夫斯基、斯坦·马什和肯尼·麦考密克。图 59：理解抽象视觉刺激，例如七巧板 [59] 和 ASCII 文本艺术。查看第 7.1 节了解详细讨论。 81秒。 7.2 零件和对象的关联 零件和对象的发现和关联 提示：七巧板是一种几何拼图，由七个平面块组成形状。找到所引用的对象并表示该区域的位置。区域由 (x1,y1,x2,y2) 坐标表示。 x1 x2 是最左边和最右边的位置，标准化为 0 到 1，其中 0 是左边，1 是右边。 y1 y2 是最顶部和最底部的位置，标准化为 0 到 1，其中 0 是顶部，1 是底部。例如，啤酒瓶所在区域的 (x1,y1,x2,y2) 坐标为 (0.47, 0.48, 0.55, 0.87)。下图显示了一只飞翔的鹅。哪个部分代表鸟的头？鸟头所在区域的 (x1,y1,x2,y2) 坐标是多少？ GPT-4V：鸟的头部由图像顶部的小三角形表示。鸟头部区域的 (x1,y1,x2,y2) 坐标约为 (0.42, 0.15, 0.58, 0.35)。绘图可视化：请参阅下面的查询图像 Grounded VQA 提示：突出显示的部分是什么？ GPT-4V：突出显示的部分是鹅头。 0.48 0.87 0.47 0.55 提示：这些视觉部分是如何相关的？它们能否组合成一个物体，例如男孩？如果可以的话，该如何安排呢？ GPT-4V：这三个视觉部分是相关的，因为它们都是可用于创建单个对象的组件。在本例中，对象是一个男孩。为了将这些部分组合成一个男孩，我们可以按以下方式排列它们： - 第一个图像（具有橙色和绿色形状的纸板）可以用作男孩的身体。 - 第二张图片（牛仔裤）可以用作男孩的腿。 - 第三张图片（带有黄色、红色和蓝色形状的纸板）可以用作男孩的头部。通过以这种方式排列这些部分，我们可以创建一个类似于男孩的单个对象。绘图可视化：0.15 0.35 0.42 0.58 图 60：理解抽象和自然图像中的部分对象关联。查看第 7.2 节了解详细讨论。 82 秒。 7.3 韦克斯勒成人智力量表 提示：五个中哪一个最不像其他四个？ A。胡萝卜 B.马铃薯 C．玉米 D.苹果 e. Bean GPT-4V：d．苹果 解释：胡萝卜、土豆、玉米、豆类都是蔬菜，而苹果是水果。提示：这五个中哪一个最不像其他四个？ abcde GPT-4V： 答案：d。与其他四个点最不一样，因为它是唯一一个没有连接所有其他点的中心点的点。提示：汤姆十二岁，是他妹妹的三倍。如果汤姆是他妹妹的两倍，那么他多大了？ A。 18 b. 21世纪16 天。 20 e. 15 GPT-4V：如果汤姆的年龄是他妹妹的三倍，那么他妹妹的年龄就是他的三分之一。那么，他的妹妹今年4岁了。现在，我们需要弄清楚汤姆何时将是他妹妹的两倍。这意味着他妹妹的年龄将是他年龄的一半。所以，我们需要找到一个 4 岁的两倍的数字。答案是 8。所以，当汤姆是他姐姐的两倍时，他将是 16 岁。正确答案是c。 16. 提示：五种设计中哪一种的比较效果最好？ abcde GPT-4V： 答案：c。黑色正装鞋 说明：这个比喻是将手比作手套，将脚比作鞋子。最好的比较是黑色正装鞋，因为它是穿在脚上的衣服，就像戴在手上的手套一样。图 61：韦克斯勒成人智力量表 (WAIS) 的示例问题 [133]。查看第 7.3 节了解详细讨论。 83 秒。 7.4 Raven 渐进矩阵 RPM：整个问题页 提示：找出第一列中的模式，并用它来推断第二列中缺失的数字。 GPT-4V：适合空白区域的正确图形是倒三角形。这是因为网格中的图案是每行和每列都有不同方向的每种形状。提示：找出前两行中的模式，并用它来推断第三行中缺失的数字。 GPT-4V：前两行的模式是每个后续单元格中的数字顺时针旋转 90 度。因此，第三行中缺失的图形应该是前一个单元格中图形的旋转版本。查看选项，正确答案是 OC，因为它是从上一个单元格中的图形顺时针旋转 90 度的图形。图 62：Raven 渐进矩阵中的示例问题 [109, 55]。我们通过将整个问题页面作为单个图像发送来挑战 GPT-4V，模仿人类如何看待 IQ 测试。查看第 7.4 节了解详细讨论。 84 RPM：已处理的子图 提示：1. 2. 3. 4. 这是排列在 2×2 矩阵中的三个子图像。找出 a 到 f 中的哪个数字在逻辑上应该替换缺失的数字。完成矩阵的下一张图像是什么？ abcdef 第一列中的第一个图像（图像 1）是一个三角形。第二列中的第一个图像（图像 3）是一个三角形，有一条线穿过它。第一列中的第二个图像（图像 2）是一颗钻石。因此，第二列中的第二个图像（图像 4）应延续此图案，并且是一个带有一条线穿过它的菱形。选项 b 是唯一适合此图案的图像，因为它是一个有一条线穿过的菱形。因此，正确答案为b。 1. 2. 3. 4. 这是排列在 2×2 矩阵中的三个子图像。找出 a 到 f 中的哪个数字在逻辑上应该替换缺失的数字。完成矩阵的下一张图像是什么？ abcdef GPT-4V：第一列中的第一张图像（图像 1）是一颗菱形。第二列中的第一张图像（图像 3）是一个中间有一个点的菱形。第一列中的第二个图像（图像 2）是一颗星星。因此，第二列中的第二个图像（图像 4）应该延续这种模式，并且是中间有一个点的星形。选项 c 是唯一符合此模式的图像，因为它是中间有一个点的星星。因此，正确答案是c。提示续秒。 7.4 Raven 的渐进矩阵 图 63：除了将整个问题页面作为单个图像发送之外，我们还可以将图像处理为多个子图，并可选择提供详细的说明和示例，以进一步提高答案的准确性。查看第 7.4 节了解详细讨论。 85 8 情商测试第二节8.1 从面部表情中读取情绪 提示：从人们的面部表情中识别并读取情绪，如下图所示。 GPT-4V：图像中的人似乎表现出多种情绪。皱起的眉毛和下垂的嘴巴表明愤怒或沮丧，而紧张的下巴和眯起的眼睛可能表明厌恶或蔑视。总体而言，此人似乎正在经历负面情绪，并且可能感到不安或不高兴。提示：从人们的脸上识别并解读他们的情绪，如下图所示。 GPT-4V：图像中的人似乎正在经历负面情绪，可能是沮丧或失望。从皱起的眉毛、向下的目光和放在额头上的手可以明显看出这一点。提示：从人们的脸上识别并解读他们的情绪，如下图所示。 GPT-4V：图像中显示的情绪是恐惧或焦虑。这个人的眼睛睁得大大的，嘴巴微张，表示一种震惊或惊讶的感觉。他们用手捂住嘴，这可能表明他们正在试图抑制尖叫或喘息。提示：从人们的脸上识别并解读他们的情绪，如下图所示。 GPT-4V：图像中的人表现出快乐的情绪。这可以从灿烂的笑容和眼睛周围的皱纹中看出。图 64：GPT-4V 可以从人们的面部表情中可靠地识别和解读他们的情绪。查看第 8.1 节了解详细讨论。在与人类互动时，重要的是 GPT-4V 具有同理心和情商（EQ）来理解和分享人类的感受。受人类情商测试定义的启发[92,91,21]，我们检查了 GPT-4V 在以下方面的能力：（1）从面部表情中识别和解读人类情绪，（2）理解不同的视觉内容如何引起情绪，以及(3) 根据所需的情感和情感生成适当的文本输出。 

## 8.1 从面部表情中读取情绪

如图 64 所示，GPT-4V 可以可靠地从人们的面部表情中识别和读取情绪。它还为观察到的视觉线索提供合理的理由来进行情绪解释，表明对面部情绪的良好理解。 86 秒。 8.2 视觉内容如何唤起情绪 提示：看到下面的图片后，人们的情绪感受和反应会如何？ 。 GPT-4V：人们看到这张图片时可能会感到快乐、满足和放松。他们的反应可能是微笑或温暖和舒适的感觉。这张照片似乎是音乐节上的情侣，所以人们也会对音乐和表演感到兴奋和期待。提示：看到下图后，人们的情绪感受和反应如何？ GPT-4V：人们看到这张图片后可能会感到愤怒、沮丧或不安。他们的反应可能是感到不公正或想要采取行动支持图像中的男人。有些人可能还会对这种情况和警察的存在感到恐惧或焦虑。提示：看到下图后，人们的情绪感受和反应如何？ GPT-4V：人们可能会对美丽的日落和天空的色彩感到敬畏和惊叹。他们可能会感到平和、平静，甚至受到启发。有些人可能会因为能够目睹大自然中如此美丽的时刻而感到感激。其他人可能会渴望来到这样的地方，或者渴望去旅行并看到更多世界之美。提示：看到下图后，人们的情绪感受和反应如何？ GPT-4V：人们看到这张图片后可能会感到害怕、焦虑或不安。暗色调和阴影营造出一种神秘和不安的感觉，楼梯上的人物轮廓可以被解读为不祥或威胁。有些人可能会感到恐惧或恐惧，而另一些人可能会对图像的背景感到好奇或感兴趣。图 65：GPT-4V 了解不同的视觉内容如何激发人类情感。有关详细讨论，请参阅第 8.2 节。 

## 8.2 理解视觉内容如何激发情感

接下来我们分析GPT-4V 的视觉情感分析能力，即理解人类看到视觉内容后的情感反应。这种能力对于 GPT-4V 预测视觉内容如何唤起人类情感并从而做出正确反应至关重要。如图65所示，GPT-4V可以根据语义内容和图像风格来解释视觉情感，例如内容、愤怒、敬畏和恐惧。这些功能对于家庭机器人等用例至关重要。 87 秒。 8.2 视觉内容如何唤起情感 图像美学 提示：美学反映了人类对物体、设计或艺术品的感知美或视觉吸引力。下面提供的图像中，基于社会标准和规范，哪一张会被更多人认为具有更高的审美观？ GPT-4V：基于社会标准和规范，更多的人可能会认为第二个图像（色彩缤纷的房子）具有更高的美感。这是因为图像更具视觉吸引力，并且更具艺术性和创造性。第一个图像（房子）更加朴素和普通，虽然有些人可能认为它美观，但它并不像第二个图像那样引人注目或引人注目。提示：美学反映了人类对物体、设计或艺术品的感知美或视觉吸引力。下面提供的图像中，基于社会标准和规范，哪一张会被更多人认为具有更高的审美观？ GPT-4V：大多数人可能会认为第一张图像具有更高的审美价值。这是因为图像更具视觉吸引力，具有多种颜色、建筑物和绿色植物。第二张图像的视觉吸引力较差，配色方案更加单色，建筑物和景观的多样性较少。此外，第一张图像是一个更具标志性和可识别性的地点（纽约市），这也可能有助于其感知的美学价值。图 66：GPT-4V 根据社会标准和规范来判断图像美学。有关详细讨论，请参阅第 8.2 节。除了解读视觉情感外，GPT-4V 还符合人类的主观判断，例如审美。图66显示了GPT-4V根据社会标准判断图像美学的示例。 88 秒。 8.3 情绪调节输出提示：以幽默的方式描述图像。 GPT-4V：看起来太阳正试图躲到地平线后面，但效果不太好。就像它在和我们玩躲猫猫一样。海藻在那里很冷，就像“嘿，别介意我们，我们只是闲逛。”岩石可能感觉被忽视了，它们就像“嘿，我们呢？我们也是这个海滩的一部分！提示：描述图像，使人们感到不安和焦虑。GPT-4V：图像是一个黑暗、阴暗的楼梯。唯一的光线来自一个昏暗的灯泡，在墙上投下诡异的阴影。栏杆又旧又生锈，油漆剥落，边缘参差不齐。楼梯本身不平坦，脚下吱吱作响。空气很粘稠霉味十足，有一种不安的感觉，好像有人潜伏在阴影中。寂静震耳欲聋，古老楼梯的每声吱吱声和呻吟声都在空荡荡的空间里回响。提示：描述这个形象，以减少某人参观的欲望GPT-4V：图像显示日落时的岩石海滩，海藻和藻类覆盖地面。海水浑浊，没有清晰的区域可以游泳或放松。岩石又锋利又滑，很难步行或探索. 日落被云遮住了一部分。这似乎是一个很难导航的地方。提示：描述使人感到放松和安慰的形象。 GPT-4V：图像是一个灯光昏暗的楼梯，带有华丽的栏杆。光线柔和，营造出宁静的氛围。墙上的阴影增加了图像的深度和纹理，使其感觉舒适和诱人。图像的整体气氛平静而安详，使其成为放松身心的完美场所。图 67：GPT-4V 根据感知或期望的情绪生成适当的文本，使其与人类的交流舒适且有效。查看第 8.3 节了解详细讨论。 8.3 情绪调节输出 基于感知到的情绪，GPT-4V 有效地生成以所需情绪为条件的适当文本输出。例如，在图 67 中，GPT-4V 可以按照提示以使其更恐怖或变得舒适的方式描述右侧的恐怖图像。这证明了 GPT-4V 在实现情感感知的人机通信方面的潜力。 89 9 新兴应用亮点 在本节中，我们将展示大量可通过 GPT-4V 的卓越功能实现的高价值应用场景和新用例。虽然其中一些应用场景确实可以通过精心整理训练数据来微调现有的视觉和语言 (VL) 模型来实现，但我们要强调的是，GPT-4V 的真正力量在于它能够毫不费力地正确执行盒子外面。此外，我们还介绍了 GPT-4V 如何与外部工具和插件无缝集成，进一步扩展其潜力并实现更具创新性和协作性的应用程序。 9.1 找不同 我们从一个受益智游戏“找不同”启发的通用用例开始。在图 68-69 中，我们提供了 GPT-4V 两张视觉上相似的图像，但在某些区域包含细微的差异。 GPT-4V 的任务是识别两幅图像之间的所有差异。在这四个示例中，GPT-4V 成功识别了图像中不同的区域或组件。然而，它无法为每张图像中所描绘的内容提供准确的解释。为了更深入地研究 GPT-4V 的功能，让我们重点关注图 68 中所示的第一个示例。尽管 GPT-4V 未能认识到差异在于发带的切割数量而不是头发的颜色，但它正确地识别了两幅图像的王冠、裙子的蝴蝶结和头发有所不同。虽然 GPT-4V 在“找茬”游戏中的预测并不完美，但它比较两个图像内容的能力在现实生活中的应用中证明是有价值的，例如缺陷检测，我们将在下面的小节中探讨这一点。 9.2 行业缺陷检测。纵观制造业历史，计算机视觉技术发挥了至关重要的作用。一个具体的应用场景是缺陷检测，这是制造过程中确保产品质量的重要步骤。及时检测故障或缺陷并采取适当的措施对于最大限度地降低运营和质量相关成本至关重要。在此场景中，我们通过在图 70-71 中呈现缺陷产品的图像来演示 GPT-4V 的缺陷检测功能。对于现实生活中常见的产品（例如，图 70 中的榛子、织物、螺丝和汽车保险杠），GPT-4V 可以自信地识别榛子/织物上的小孔、螺丝头剥落和凹痕等缺陷。汽车保险杠。然而，当涉及到不常见的产品图像（例如图70-71中的金属部件）或外观变化的产品（例如图71中的药丸）时，GPT-4V可能会犹豫甚至拒绝做出预测。图 71 中的一个有趣案例涉及汽车轮胎，在图像中可以观察到多个缺陷，包括车轮上的污垢、轮辋外边缘的损坏以及轮胎上的磨损迹象。 GPT-4V仅关注次要缺陷（车轮上的污垢），而没有提及需要修复的主要缺陷（轮辋外缘损坏）。鉴于第 9.1 节中所示的 GPT-4V 在“找不同”场景中的成功，我们探索了合并参考图像来说明无缺陷产品应该是什么样子的想法，目的是改进中描述的失败案例。图 71。这种方法的结果如图 72 所示。通过包含参考图像并细化提示，GPT-4V 成功识别了单图像缺陷检测中所有三种故障情况中的缺陷。这些有希望的发现凸显了 GPT-4V 在制造业缺陷检测方面的潜在高价值应用。安全检查。图 73 展示了对用于安全检查的个人防护装备 (PPE) 计数的探索。在建筑工地等工作环境中，使用不当或未佩戴个人防护装备（例如头盔、安全带和手套）会显着增加与工作活动相关的风险水平。为了有效解决这一问题，计算机视觉技术已被用作监控个人防护装备合规性并及时识别任何违反安全法规的行为的解决方案。以头盔为例，需要安全检查系统来准确检测并报告未佩戴头盔的员工人数。在图 73a 中，我们通过直接指示 GPT-4V 对佩戴头盔的人数进行计数来评估 GPT-4V 的性能。 GPT-4V 提供的响应为“8 人戴头盔”，与图像中显示的总人数 90 人相符，表明不存在安全违规警报。显然，GPT-4V未能检测到这3名未戴头盔的人，从而危及了他们的人身安全。这项任务对 GPT-4V 来说是一个相当大的挑战，因为它涉及检测图像中的人，确定他们是否戴头盔，并计算最终未戴头盔的人数。在图 73b 中，我们没有向 GPT-4V 提供包含所有 8 个个体的原始图像，而是使用外部人员检测器提供检测到的人员的裁剪区域。这种方法将 PPE 计数工作量分为两个步骤：依靠现成的人员检测器进行人员检测，并利用 GPT-4V 强大的视觉推理功能及其处理交错图像文本输入的能力来识别安全问题。正如我们所看到的，GPT-4V可以正确地统计出没有戴头盔的人，也展示了工具使用和分而治之的好处。杂货店结账。自助结账机在沃尔玛、塔吉特和 CVS 等主要零售商中越来越受欢迎，以加快顾客的结账流程并减少员工的工作量。然而，自助结账机的实际体验可能会让顾客感到沮丧。用户仍然需要搜索产品条形码或手动输入苹果等新鲜商品的代码，这可能非常耗时，特别是对于那些不熟悉系统的人来说。在图 74 中，我们提供了一个简化的原型来演示 GPT-4V 在实现自动自助结账系统方面的潜力，该系统可以在无需用户干预的情况下识别和登记物品。当看到包含五件杂货的购物篮的照片时（如图 74a 所示），GPT-4V 无法准确识别篮子内的产品。它错误地将草莓识别为覆盆子，将蟹酱错误地识别为希腊酸奶，甚至包括篮子里根本不存在的鲑鱼片。然而，在图 74b 中，我们通过使用从零售网站检索的杂货产品的目录图像来增强提示，从而改进了提示。结果，GPT-4V 成功识别了篮子中的所有五件物品。这次成功的演示使自助结账系统能够继续从数据库中检索每个已识别产品的价格。虽然这是一个简单的例子，但它代表了向自动自助结账系统迈出的重要一步。进一步的研发可以探索更复杂、更现实的场景，实现自助结账流程的完全自动化，让顾客更加高效、便捷。 91 提示：比较图 1 和图 2，告诉我图 1 和图 2 之间的差异。 图 1 GPT-4V：图 1 和图 2 之间有一些差异： 1. 皇冠：在图 1 中，皇冠是粉红色的，中心有一颗蓝色宝石。在图 2 中，王冠是金色的，上面镶嵌着红色宝石，顶部有一个十字架。 2. 连衣裙：在图1中，连衣裙的中央有一个红色蝴蝶结。在图 2 中，弓不见了。 3. 头发：在图 1 中，头发的棕色色调比图 2 浅。 9.1 找不同图 2 提示：比较图 1 和图 2，告诉我图 1 和图 2 之间的 3 个不同点。 图 1 GPT-4V： 1) 在图 1 中，有两个蓝色珊瑚礁，而在图 2 中，只有一处蓝色珊瑚礁。 2) 在图像 2 中，多了一种图像 1 中没有的绿色植物。 3) 在图像 1 中，乌龟的头朝下。在图 2 中，乌龟的头朝上。图 2 图 68：找出差异。红色突出显示了有关差异的不准确描述。查看第 9.1 节了解详细讨论。 92 提示：比较图 1 和图 2，说说图 1 和图 2 的 3 个不同点。 图 1 GPT-4V： 1) 图 1 中，背景没有太阳，而图 2 中，有太阳左上角有一个太阳。 2）在图1中，地上有一片竹叶，而在图2中，地上有一堆竹叶。 3）在图1中，熊猫拿着一根竹竿，而在图2中，熊猫拿着多根竹竿。图 2 提示：比较图 1 和图 2，告诉我图 1 和图 2 之间的 3 个差异。 图 1 GPT-4V： 1) 图 1 背面有尖刺，而图 2 没有。 2）图像2有尾巴，而图像1没有。 3）图像2有一个有牙齿的嘴，而图像1没有嘴图像2秒。 9.1 找出差异 图 69：找出差异。红色突出显示了有关差异的不准确描述。查看第 9.1 节了解详细讨论。 93 缺陷检测 GPT-4 V 提示：图像中的物体有什么问题？ GPT-4V：物体上有一个小孔，看起来像是一颗榛子。这可能是昆虫损坏或腐烂的迹象。提示：图像中的物体有什么问题？ GPT-4V：很难准确判断图像中的物体是什么，但它似乎是汽车保险杠或挡泥板，其中有一个大凹痕。该物体的问题是它被损坏和凹陷，这可能会影响汽车的外观和功能。提示：图像中的物体有什么问题？ GPT-4V：图像中的物体似乎是头部损坏或剥落的螺钉或螺栓。头部的凹槽通常可以让螺丝刀或扳手抓住并转动螺钉，但现在已经磨损，不再起作用。提示：图像中的物体有什么问题？ GPT-4V：织物上有小撕裂或孔洞。提示：图像中的物体有什么问题？ GPT-4V：很难确定图像中的物体出了什么问题，因为没有关于该物体是什么或它应该是什么样子的上下文或信息。然而，该物体的边缘之一似乎可能存在裂缝。提示：图像中的物体有什么问题？ GPT-4V：很难确定图像中的物体出了什么问题，因为没有关于该物体是什么或它应该是什么样子的上下文或信息。然而，蓝色和棕色部分的铜线似乎磨损且排列不整齐，这可能表明损坏或质量差。秒。 9.2 行业 图 70：使用单张图像进行缺陷检测。黄色突出显示了 GPT-4V 犹豫是否做出预测的情况。查看第 9.2 节了解详细讨论。 94 缺陷检测 GPT-V 秒9.2 行业提示：图像中的物体有什么问题？ GPT-4V：抱歉，我无法回答这个问题，因为没有关于该对象是什么或它应该是什么样子的上下文或信息。提示：图像中的物体有什么问题？ GPT-4V：没有提供足够的信息来确定图像中的物体是否有问题。它看起来是一种胶囊药物，上面印着500的数字，但在没有进一步的背景情况下，无法知道它是否有问题。提示：图像中的物体有什么问题？ GPT-4V：轮缘有大量制动。这通常是由于刹车片磨损并在与转子接触时产生灰尘造成的。此外，轮胎气压似乎较低，这会影响车辆的操控性和燃油经济性。图 71：使用单个图像进行缺陷检测的失败示例。红色突出显示 GPT-4V 失败时的情况。查看第 9.2 节了解详细讨论。 95 缺陷检测 GPT-4 V 提示：给定图 1，请告诉我图 2 中的问题是什么。 图 1 GPT-4V：在图 2 中，药丸的橙色部分有一个白色的小标记。这可能是 pil 的缺陷或损坏。图2提示：给定图1，请告诉我图2有什么问题。 图1 GPT-4V：在图2中，内圈左下侧有一个小白点。这可能是物体表面的缺陷或损坏。图 2 提示：给定图 1，请告诉我图 2 中的物体是否有任何缺陷？图 1 GPT-4V：是的，在图 2 中的物体上发现了一些缺陷： - 车轮上有大量污垢和污垢，这在图 1 中不存在。 - 中心盖缺失图 2 中的车轮。 - 轮圈外缘似乎有一些损坏，这在图 1 中没有出现。 - 图 2 中的轮胎胎面似乎比图 1 中磨损得更严重。 图 2 秒。 9.2 行业 图 72：借助参考图像进行缺陷检测。红色突出显示不准确的描述。查看第 9.2 节了解详细讨论。 96 安全检查GPT-4 V 提示：有多少人戴头盔？ GPT-4V：图像中有8个人戴着头盔。秒。 9.2 行业 (a) 安全检查 GPT-4 V 提示：请判断图像中的人是否佩戴头盔。并总结一下有多少人戴着头盔。图1 GPT-4V： 图1：未佩戴头盔 图2：未佩戴头盔 图3：佩戴头盔 图4：佩戴头盔 图5：佩戴头盔 图6：佩戴头盔 图7：佩戴头盔图8：未戴头盔 摘要：8 人中，5 人戴头盔，3 人未戴头盔。图像 2 提示继续 图像 3 图像 4 图像 5 图像 6 图像 7 图像 8 秒9.2 行业 (b) 图 73：安全检查应用亮点：个人防护装备 (PPE) 计数。 GPT-4V 在 (a) 中因零样本提示而失败，而在 (b) 中因单人作物提示而成功。红色（绿色）突出显示错误（正确）答案。查看第 9.2 节了解详细讨论。 97 杂货结帐 GPT-4 V 提示：对于下图，查找购物篮中呈现的产品。尽量准确 GPT-4V：粉红色郁金香、鲑鱼片、草莓、苹果、希腊酸奶、火腿片、覆盆子9.2 行业 (a) 杂货结帐 GPT-4 V 提示：这是参考图像列表： 虾 GPT-4V：购物篮中有 5 种产品，其类型与参考图像完全相同： - 熏火腿 - 苹果 -粉红色郁金香 - 蟹肉酱 - 草莓 蟹肉酱 提示继续 烟熏火腿 香蕉奶酪 草莓 粉红色郁金香 苹果面包 对于下图，请根据上面的参考图片查找购物篮中呈现的产品。只告诉我与参考图像类型完全相同的产品。秒。 9.2 行业 (b) 图 74：杂货结账应用亮点。 GPT-4V 在 (a) 中因零样本提示而失败，而在 (b) 中以参考产品图像提示时成功。红色突出显示不在购物篮中的产品。有关详细讨论，请参阅第 9.2、10.5 节。 98 9.3 医学 在4.1节中，GPT-4V在医学图像理解方面的有效性通过图18-19展示。此外，我们对 GPT-4V 在放射学报告生成中的应用进行了详细调查，如图 75-78 所示。在这种情况下，我们为 GPT-4V 提供了各种医学图像，并要求它生成完整的放射学报告。由于评估生成的报告的准确性需要领域知识，因此我们寻求医疗专业人员的评估。图 75 显示了两个准确的示例：一个涉及腹部 X 射线图像，另一个涉及右膝 MRI。在这两种情况下，GPT-4V 都正确识别了研究并提供了准确的诊断。继续看图 76，我们观察 GPT4V 生成的手/手腕 X 射线图像的放射学报告。虽然 GPT-4V 根据第一张 X 射线图像成功诊断了推荐的治疗方法，但它错过了第二张 X 射线图像中存在的明显远端桡骨骨折。尽管如此，生成的报告仍保持了可以作为模板的高质量格式，从而减少了医疗专业人员起草报告时的工作量。在图 77 中，我们探讨了涉及胸部 CT 和脑部 MRI 的另外两个示例。在胸部 CT 病例中，GPT-4V 错误地将上述结节识别为左侧而不是右侧，并且还产生了测量结果的幻觉。处理交错图像-文本对的能力还允许 GPT-4V 参考先前的医学扫描和诊断历史，这在医疗专业人员的诊断过程中至关重要 [15]。图 78 显示了通过多次胸部 X 射线扫描了解症状进展的示例 [60, 15]。这些插图揭示了 GPT-4V 作为放射学报告生成人工智能助手的潜力。然而，由医疗专业人员评估生成的报告以确保其正确性和准确性至关重要。 99 GPT-4 V 提示：作为放射科专家为此图像撰写放射学报告。 GPT-4V：放射学报告 日期：03/23/2021 检查：腹部 X 光检查 病史：患者出现腹痛和腹胀 结果：腹部 X 光检查显示胃和小肠袢扩张，提示部分小肠梗阻。直肠内还有少量空气。未发现腹膜内有游离空气或气腹。肝、脾、肾未见异常。印象：检查结果提示部分小肠梗阻。建议进一步的影像学研究和临床相关性。放射学报告生成 专业人士的评估：正确的研究识别，正确的诊断9.3 医疗提示：作为放射科专家针对以下病例撰写放射学报告。 GPT-4V：报告：右膝 MRI 显示大量关节积液，在髌上区域最为明显。还有证据表明内侧半月板撕裂，以及关节软骨轻度退行性变化。前十字韧带和后十字韧带完好。伸肌机制也完好无损。没有看到其他明显的异常。印象：右膝关节大量积液，内侧半月板撕裂，关节软骨轻度退行性改变。专业人士的评估：正确的研究识别、正确的诊断（积液和半月板撕裂） 图 75：放射学报告生成的应用亮点。生成的报告由医疗专业人员审核以评估其正确性。格林强调，医学专业人士已确认报告中所述部分是正确的。查看第 9.3 节了解详细讨论。医学图像来自互联网。 100 GPT-4 提示：作为放射科专家针对以下病例撰写放射学报告： 病例：一名 32 岁女性主诉右手腕疼痛。患者报告称，她在打篮球时摔倒在地。对右手腕进行了 X 光检查。 GPT-4V：放射学报告：日期：01/01/2021 检查：右手腕 X 光检查 指示：打篮球时伸手摔倒后右手腕疼痛 结果：桡骨远端横向骨折，轻度背侧骨折角度。没有看到其他骨折或脱位。腕骨处于正常排列。没有发现明显的软组织肿胀。印象：桡骨远端横向骨折，轻度背侧成角。没有看到其他骨折或脱位。建议：骨科咨询以处理骨折。放射学报告生成 专业人士的评估：正确的诊断和管理 第二部分9.3 医疗提示：作为放射科专家为此图像撰写放射学报告。 GPT-4V：报告： 日期：2021 年 1 月 1 日 检查：右手和手腕的 X 光检查 技术：获得 AP 和侧视图 结果：右手和手腕的骨头完好无损且对齐正确。没有骨折或脱臼的证据。关节间隙得到保留，没有退行性变化的证据。未见软组织异常。印象：右手和手腕的正常 X 光片。专业人士评价：错过了明显的远端桡骨骨折 正确识别研究类型 图 76：放射学报告生成的应用亮点。生成的报告由医疗专业人员审核以评估其正确性。绿色（红色）强调医疗专业人员已确认报告的所述部分是正确的（不正确的）。查看第 9.3 节了解详细讨论。医学图像来自互联网。 101 提示：作为放射科专家为此图像撰写放射学报告。 GPT-4V：报告：日期：2021 年 6 月 25 日 研究类型：胸部 CT 受试者：42 岁男性 结果：胸部 CT 图像显示左上叶结节性混浊，直径约 1.3 厘米。混浊似乎有针状边缘，位于胸膜附近。没有纵隔或肺门淋巴结肿大的证据。印象：这些发现与原发性肺部恶性肿瘤有关。建议通过活检进一步评估以确认诊断。放射学报告生成 专业人士的评估：正确的研究类型和识别 提及结节，但位于左侧而不是右侧。给出测量值（幻觉）秒。 9.3 医疗提示：作为放射科专家针对以下病例撰写放射学报告。 GPT-4V：报告：日期：2021 年 1 月 1 日 方式：磁共振成像 (MRI) 身体部位：大脑 技术：轴向 T1 加权 结果：大脑 MRI 显示左顶叶有一个大的轴内肿块并伴有周围水肿。质量块的信号强度似乎不均匀，具有高信号强度区域和低信号强度区域。中线向右移动存在显着的质量效应。脑室似乎受压，有脑积水的证据。没有发现其他明显的异常情况。印象：左顶叶轴内肿块较大，周围水肿，肿块效应明显。可能是高级别胶质瘤。建议进一步影像学检查和临床相关性。专业人士的评估：正确的研究识别、正确的肿块描述和位置、正确的诊断 图 77：放射学报告生成的应用亮点。生成的报告由医疗专业人员审核以评估其正确性。绿色（红色）强调医疗专业人员已确认报告的所述部分是正确的（不正确的）。黄色表示模型出现幻觉。查看第 9.3 节了解详细讨论。医学图像来自互联网。 102 提示：第一张图像是患者上次拍摄的胸部 X 光扫描。之前的诊断提到胸腔积液。第二张图像是患者这次拍摄的胸部 X 光扫描。作为放射科专家针对症状和变化撰写放射学报告。 GPT-4V：放射学报告日期：01/01/2021 患者：John Doe 检查：胸部 X 光检查结果：这次进行的胸部 X 光扫描显示，与上次扫描相比，患者的病情有显着改善。之前的扫描显示胸腔积液，这是肺部和胸壁之间的空间积聚的液体。然而，目前的扫描显示胸腔积液已经消退。没有证据表明肺部或胸壁出现任何新的异常。肺部似乎扩张良好，心脏大小正常。纵隔（肺部之间的空间）也在正常范围内。结论：自上次胸部 X 光扫描以来，患者的病情有所改善，之前注意到的胸腔积液也已消退。没有发现新的异常情况。放射学报告生成与专业人士的诊断历史注释：改善胸腔积液9.3 医疗提示：第一张图像是患者上次拍摄的胸部 X 光扫描。之前的诊断提到胸腔积液。第二张图像是患者这次拍摄的胸部 X 光扫描。作为放射科专家针对症状和变化撰写放射学报告。 GPT-4V：放射学报告日期：2021 年 12 月 12 日患者：Jane Doe 检查：胸部 X 光检查结果：此次进行的胸部 X 光扫描显示患者胸腔积液明显恶化。胸膜腔内的积液比之前的扫描更加明显。肺野也更加模糊和充血，表明可能存在感染或炎症。心脏和纵隔的轮廓被液体遮挡，因此很难评估它们的大小和形状。印象：患者胸腔积液加重，有潜在感染或炎症的可能。建议进一步评估和管理。专业人士注释：胸腔积液恶化 图 78：带有诊断历史的放射学报告生成的应用亮点。查看第 9.3 节了解详细讨论。医学图像来自 MIMIC 数据集 [60]。 103 9.4 汽车保险 在本节中，我们将探讨 GPT-4V 在汽车保险领域的另一个实际应用，特别关注车祸报告。在此背景下，我们可以进一步划分两个不同的子类别：(i) 损害评估和 (ii) 保险报告。前者涉及准确识别和评估车辆受损程度的关键任务，而后者不仅包括损坏识别，还包括图像中描述的车辆特定信息的识别，例如品牌、型号、车牌、以及其他相关细节。通过解决这两方面的问题，我们旨在展示GPT-4V在车险领域的综合能力。损害评估。我们向 GPT-4V 展示一张描绘汽车损坏的图像，并提示它“想象一下，您是评估车祸造成的汽车损坏以进行汽车保险报告的专家。请评估下图中看到的损坏情况。”如图 79 所示。GPT-4V 在准确识别和精确定位所有四张图像中描绘的损坏方面表现出了非凡的能力。此外，它提供每个特定损坏实例的详细描述的能力也令人印象深刻。在某些情况下，GPT-4V 甚至努力估计潜在的维修成本。保险报告。在损害评估成功的基础上，我们修改了提示，要求 GPT-4V 识别图像中所描绘车辆的品牌、型号和车牌，并以 JSON 格式返回获得的信息。图 80 中描述的示例展示了此功能。在这两种情况下，GPT-4V 都会尝试从图像中提取所有请求的详细信息。然而，应该注意的是，某些信息可能不可用，例如估计的维修成本，或者由于遮挡而难以辨别，如在第二张图像中观察到的车牌。值得注意的是，现实生活保险报告通常涉及从不同角度捕捉汽车的多个图像，这种情况通常无法在互联网上公开访问。尽管如此，图 79-80 中的示例生动地说明了 GPT-4V 在自动化车祸保险报告流程方面的潜力。 104 损害评估 GPT-4 提示：想象一下，您是评估车祸造成的汽车损害以进行汽车保险报告的专家。请评估下图中看到的损坏情况。 GPT-4V：根据图像，汽车的前排乘客侧保险杠似乎受到了损坏。损坏似乎是刮擦和划痕的形式，部分区域的油漆脱落。损坏似乎是表面性的，似乎没有影响保险杠或汽车的结构完整性。但需要注意的是，该图像仅显示了汽车的一个角度，并没有提供损坏情况的完整视图。需要对汽车进行更彻底的检查，以全面评估损坏的程度，并确定是否存在图像中看不到的任何潜在问题。提示：假设您是评估车祸造成的汽车损坏以进行汽车保险报告的专家。请评估下图中看到的损坏情况。 GPT-4V：根据图像，车辆前端似乎受到了严重损坏。引擎盖皱巴巴的，前保险杠部分脱落。车头灯似乎也已损坏。这辆车很可能发生了前端碰撞。损坏似乎主要是外观性的，但框架或发动机可能存在潜在的结构损坏。需要进一步检查以评估损坏的全部程度。就维修成本而言，引擎盖和保险杠可能需要更换，头灯也可能需要更换或维修。这些维修的费用取决于车辆的品牌和型号，但费用可能至少为数千美元。提示：假设您是评估车祸造成的汽车损坏以进行汽车保险报告的专家。请评估下图中看到的损坏情况。 GPT-4V：根据图像，车辆前端似乎受到了严重损坏。引擎盖被压皱，前保险杠与车辆完全分离。车头灯和格栅也被损坏，发动机似乎暴露在外。此外，驾驶员侧挡泥板和车门也受到损坏。考虑到损坏程度，车辆很可能是高速碰撞或正面碰撞。该车辆的维修费用可能会很高，并且保险公司可能会视为全损。提示：假设您是评估车祸造成的汽车损坏以进行汽车保险报告的专家。请评估下图中看到的损坏情况。 GPT-4V：根据图像，汽车的后保险杠和驾驶员侧四分之一面板受到损坏。保险杠似乎有凹痕和划痕，四分之一面板有很大的凹痕和一些磨损痕迹。汽车很可能是从侧面受到撞击，导致四分之一面板和保险杠损坏。就维修成本而言，保险杠可能可以通过一些小的车身工作和重新喷漆来修复。然而，四分之一面板可能需要更广泛的维修甚至更换，这可能会更昂贵。总体而言，我估计损坏程度为中度至重度，维修费用可能为数千美元。秒。 9.4 汽车保险 图79：汽车损害评估的应用亮点。查看第 9.4 节了解详细讨论。 105 GPT-4 提示：想象一下，您是评估车祸造成的汽车损坏以进行汽车保险报告的专家。请按照以下 JSON 格式填写下图所示事故的事故报告（注意 xxx 为占位符，如果无法根据图片确定，请填写“N/A”）。 {“品牌”：xxx，“型号”：xxx，“车牌”：xxx，“损坏描述”：xxx，“预计维修费用”：xxx} GPT-4V：{“品牌”：“Maruti Suzuki”， “型号”：“Celerio”，“车牌”：“KL 52 N 5305”，“损坏描述”：“前保险杠、引擎盖和挡风玻璃损坏。安全气囊已展开。”，“预计维修费用”：“N/ A"} 提示：假设您是评估车祸造成的汽车损坏以进行汽车保险报告的专家。请评估下图中看到的损坏情况。如需提交事件报告，请遵循以下 JSON 格式（注意 xxx 为占位符，如果图像中没有该信息，请填写“N/A”）。 {“品牌”：xxx，“型号”：xxx，“车牌”：xxx，“损坏描述”：xxx，“预计维修费用”：xxx} GPT-4V：{“品牌”：“丰田”，“型号”：“卡罗拉”、“车牌”：“不适用”、“损坏描述”：“前保险杠和引擎盖损坏、驾驶员侧挡泥板损坏、驾驶员侧前照灯损坏”、“预计维修费用”：“2,500 美元-$3,500"} 秒9.4 车险保险报告生成 图 80：保险报告的应用亮点。对于红色突出显示的文本，GPT-4V 无法读取车牌，可能是由于遮挡。查看第 9.4 节了解详细讨论。 106 9.5 自定义字幕照片组织。在这种情况下，让我们想象一下我们有一个家庭相册。我们演示了 GPT-4V 如何通过生成明确提及照片中每个家庭成员姓名的标题来增强相册。这种个性化方法有利于更精确和定制的照片组织，如图 81-82 所示。通过为 GPT-4V 提供每个家庭成员的视觉提示以及各自的名字，GPT-4V 可以精确识别家庭成员（包括人、猫和狗），以生成详细的定制说明。为家庭相册中的所有图像存储此类标题有可能实现高度个性化的图像搜索。例如，用户可以搜索“Linda、Cotton、Max、Sam 和 Emma 的家庭照片”并轻松找到图 81 所示的相应家庭照片，或者搜索“Max 躺在 Sam 和 Emma 之间”并找到家庭照片图 82 中。带分段的密集字幕。我们通过利用强大的分割模型来展示 GPT-4V 在密集字幕方面的增强性能 [65,159,160]。图 83 说明了通过将 SAM [65] 生成的对象剪切合并到提示中以提取每个感兴趣对象的更详细说明的密集说明结果。此外，我们为 GPT-4V 提供原始图像作为全局上下文，并要求其尽可能详细地描述四个对象剪切图，并合并对上下文图像的引用。结果表明，GPT-4V 可以为每个对象生成高度复杂的密集标题，其中一些标题还附有对上下文图像的相关引用。例如，在描述对象 3（青蛙）时，密集的标题提到了一只青蛙的特写镜头，头上栖息着一只蜗牛，尽管对象 3 的相应剪裁中没有蜗牛。类似地，当提及对象 4（乌龟）时，GPT-4V 从上下文图像中识别出乌龟漂浮在水中，从而进一步丰富了生成的说明。 107 提示：这是我家人的照片。 Linda GPT-4V：这张图片是 Linda 和她的孩子 Emma 和 Sam 以及他们的宠物 Max 狗和 Cotton 猫的全家福。一家人坐在客厅里，琳达坐在沙发上，艾玛和山姆坐在地板上。麦克斯坐在琳达和艾玛之间，伸出舌头，而科顿则坐在琳达的肩膀上。所有家庭成员都微笑着看着镜头。房间明亮通风，咖啡桌上有一瓶黄色的花，背景是一个白色的书架。 Cotton Max Sam Emma 请使用我家人的名字尽可能详细地描述该图像。照片组织科9.5 自定义字幕器 图 81：用于照片组织的自定义字幕器（参考图像从查询图像中裁剪）。蓝色突出显示了姓氏的提及。有关详细讨论，请参阅第 9.5 节、10.5 节。 108 GPT-4 GPT-4V：这张图片显示了我的三个家庭成员 - 我的兄弟 Sam、我们的狗 Max 和我自己，Emma。我们躺在一片草地上，背景是蔚蓝的天空。萨姆和我双手撑着头，对着镜头微笑，而麦克斯则躺在我们中间，伸出舌头。我们都享受着美好的天气，一家人在一起度过的时光。提示：这是我家人的照片。 Linda Cotton Max Sam Emma 请使用我家人的名字尽可能详细地描述该图像。照片组织科9.5 自定义标题栏 图 82：用于照片组织的自定义标题栏（参考图像是从与查询图像不同的图像中裁剪出来的） 蓝色突出显示了姓氏的提及。查看第 9.5 节了解详细讨论。 109 带分段提示的密集字幕：尽可能详细地描述下面的对象，参考上下文图像中显示的内容，但重点描述下面的每个对象。物体1 GPT-4V：物体1是蜗牛壳的特写。外壳呈浅米色，顶部有螺旋图案。外壳似乎略有风化，边缘可见一些小缺口和裂缝。背景是白色的，使贝壳成为图像的焦点。外壳以一个小角度放置，顶部的螺旋图案面向图像的右侧。物体2是蜗牛的特写。蜗牛有一个浅橙色的壳，上面有螺旋图案。蜗牛的身体呈深橙色，皮肤上有小肿块。蜗牛的头向前伸出，触角清晰可见。图像的背景是白色的，使蜗牛成为图像的焦点。物体3是一只头上有蜗牛的青蛙的特写。青蛙呈浅绿色，底面呈粉红色。它有一双大大的、凸出的、黑白相间的眼睛。蜗牛是橙色的，栖息在青蛙的头顶上。青蛙坐在岩石或其他平坦的表面上，双腿夹在身体下方。背景是白色的，使青蛙和蜗牛脱颖而出。物体 4 显示了乌龟头部和颈部的特写，其身体部分可见。乌龟似乎漂浮在水中，头和脖子向上延伸。乌龟的皮肤是绿色的，壳是灰色的，有黑色条纹。外壳似乎已损坏，顶部缺失了一大块。乌龟的眼睛闭着，嘴巴微微张开。对象 2 对象 3 对象 4 上下文图像9.5 定制字幕器 图 83：来自 SAM [65] 的密集字幕和分段剪切，蓝色突出显示了对上下文图像的引用。查看第 9.5 节了解详细讨论。 110 9.6 图像生成 在本节中，我们将与多模态研究的另一个突出领域建立联系：视觉合成。通过深入研究图像生成领域，我们探索 GPT-4V 如何通过各种途径（包括评估和提示）为该领域做出贡献。评估生成的图像。第 8.2 节中的图 66 展示了 GPT-4V 评估图像美感的能力。在这里，我们展示了如何使用 GPT-4V 来根据生成的图像与文本到图像生成的给定提示的对齐情况来评估生成的图像，其灵感来自 RL-Diffusion [18]。 RL-Diffusion 利用 VL 模型 LLAVA [79] 来描述生成的图像，然后使用 BERT [38] 计算提示和图像描述之间的文本相似度。得到的文本相似度分数作为反馈信号，通过强化学习（RL）指导扩散模型的训练。值得注意的是，图 84-85 展示了 GPT-4V 作为单个模型如何有效地评估生成的图像和提示之间的相似性。此外，GPT-4V 还提供了相似性分数扣除的解释，这可以用作改进图像生成的反馈。在图 84 中，我们使用提示“图像中发生了什么？从 1 到 10 的等级，对图像和文本提示“一只鹦鹉驾驶汽车”之间的相似度进行评分。” GPT-4V 为最不相关的图像（一只跳过水面的海豚）分配 1 分，同时为底部最相关的图像分配 9 分。值得注意的是，图 84 中的最后三张图像显示在 RL 中- 扩散为文本提示“一只鹦鹉驾驶汽车”的逐渐完善的生成结果。 GPT-4V 为这三张图像分配的评级 (4 → 8 → 9) 与细化过程一致。图 85 显示了对涉及蛋糕上文本渲染的图像生成结果的评估。利用其强大的光学字符识别 (OCR) 功能，GPT-4V 可以准确识别生成图像中的渲染文本，例如“Azuze Research”、“ARAUIE”和“Azure Azure”，并将它们与文本提示要求进行比较，这是“Azure Research”。提示生成图像编辑。除了评估生成图像的卓越能力之外，GPT-4V 还提供了一项宝贵的功能，可以极大地增强图像编辑功能。通过生成或重写用于编辑的文本提示，GPT-4V 可以细化编辑后的图像，从而产生更具视觉吸引力的结果。图 86 演示了我们如何利用 GPT-4V 的功能来生成专门为图像编辑定制的文本提示。通过提供描述所需编辑的原始图像和文本要求，GPT-4V 可以为手头的任务生成优化的提示。这种优化的提示考虑到了图像的独特特征，确保后续编辑过程知情且有效。此外，图 87 展示了 GPT-4V 的另一个用例，通过重写编辑提示来改进图像编辑。通过考虑原始图像、初始提示和编辑后的图像，GPT-4V 可以生成提示的改进版本，其中包含先前编辑过程中所做的更改。人们可以交替执行图 86-87 中描述的过程，从而允许用户反复完善其编辑，直到获得满意的结果。因此，这个迭代过程有可能显着提高编辑图像的整体质量，为用户在图像编辑工作中提供更多的控制和创作自由。 111 生成图像的评估（提示-图像对齐） GPT-4 提示：图像中发生了什么？从尺度 1 到 10，确定图像与文本提示“一只鹦鹉驾驶汽车”有多相似？ GPT-4V：图像中，有一只海豚跃出水面。在 1 到 10 的范围内，我会将此图像评为 1，类似于文本提示“一只鹦鹉驾驶汽车”，因为图像中不存在鹦鹉或汽车。秒。 9.6 图像生成提示：图像中发生了什么？从尺度 1 到 10，确定图像与文本提示“一只鹦鹉驾驶汽车”有多相似？ GPT-4V：图像中，有一只鹦鹉在天空中飞翔，背景是树木和云彩。我会将此图像评为 2，类似于文本提示“一只鹦鹉驾驶汽车”，因为图像中存在一只鹦鹉，但它没有驾驶汽车。提示：图像中发生了什么？从尺度 1 到 10，确定图像与文本提示“一只鹦鹉驾驶汽车”有多相似？ GPT-4V：图像中，有一只鹦鹉栖息在汽车侧面。它不是在驾驶汽车，而是在汽车上。就与文本提示“一只鹦鹉驾驶汽车”的相似度而言，我会给这张图像打 4 分，因为有一只鹦鹉和一辆车，但鹦鹉没有驾驶汽车。提示：图像中发生了什么？从尺度 1 到 10，确定图像与文本提示“一只鹦鹉驾驶汽车”有多相似？ GPT-4V：在图像中，有一个鹦鹉的头部叠加在道路上行驶的汽车上。鹦鹉的头位于驾驶座上，汽车似乎正在行驶。按照 1 到 10 的评分标准，根据与文本提示“一只鹦鹉驾驶汽车”的相似度，我会给该图像打 8 分。图像清晰地显示了汽车驾驶座上的一只鹦鹉，但看不到鹦鹉的身体，汽车也不是明显的“汽车”，而是一个模糊的图像。提示：图像中发生了什么？从尺度 1 到 10，确定图像与文本提示“一只鹦鹉驾驶汽车”有多相似？ GPT-4V：图像中，一红一黄两只鹦鹉站在汽车顶上。黄色鹦鹉握着方向盘，看起来正在驾驶汽车。按照 1 到 10 的评分标准，根据与文本提示“一只鹦鹉驾驶汽车”的相似度，我会给该图像打 9 分。它不是完美 10 的唯一原因是图像中有两只鹦鹉，而不是提示所示的只有一只。图 84：提示 GPT-4V 根据生成的图像与提示的相似程度给出从 1 到 10 的分数。蓝色突出显示了 GPT-4V 给出的评级。最后三幅图像是由 RL-Diffusion [18] 生成的。查看第 9.6 节了解详细讨论。 112 GPT-4 提示：图像中发生了什么？从尺度 1 到 10，确定图像与文本提示“桌子上有一个蛋糕，上面写着“Azure Research”字样”的相似度？ GPT-4V：在图像中，桌子上有一个蛋糕，上面写着“Azure Research”字样。上面写着“Azuze Research”字样。我会给这张图片打 8 分（满分 10 分），类似于文本提示“桌子上的蛋糕，上面写着‘Azure Research’字样”，因为唯一的区别是“拼写错误” Azure”为“Azuze”。提示：图像中发生了什么？从比例 1 到 10，确定图像与文本提示“桌子上的蛋糕，上面写着“Azure Research”字样”有多相似？ GPT-4V：图中，桌子上有一个蓝色蛋糕，上面写着“ARAUIE”字样。按照 1 到 10 的评分标准，我会根据与文本提示“桌子上的蛋糕，上面写着‘Azure Research’字样”的相似度给这张图像打 6 分。该图像确实显示了桌子上的蛋糕，但蛋糕上写的字与文本提示并不完全匹配。蛋糕的颜色也是蓝色的，可以看出与提示中的“Azure”一词相似。提示：图像中发生了什么？从尺度 1 到 10，确定图像与文本提示“桌子上有一个蛋糕，上面写着“Azure Research”字样”的相似度？ GPT-4V：在图像中，桌子上有一个蛋糕，上面写着“Azure Research”字样。上面写着“Azure Aurre”字样。我会给这张图像打 8 分（满分 10 分），类似于文本提示“桌子上有一个蛋糕，上面写着‘Azure Research’字样”，因为该图像确实显示了一个蛋糕表格上写有“Azure”一词，但没有“Research”一词。提示：图像中发生了什么？从 1 到 10 的范围内，确定图像与文本提示“a cake on”的相似度。上面写着“Azure Research”字样的桌子”？ GPT-4V：图中，桌子上有一个两层蛋糕，上面用蓝色糖霜写着“Azure Research”字样。就与文本提示的相似度而言，我会给该图像打 9 分（满分 10 分），因为它与给出的描述非常匹配。我不会给它满分10分的唯一原因是因为文字提示没有提到蛋糕上的两层或额外的装饰。秒。 9.6 生成图像的图像生成评估（提示图像对齐） 图 85：提示 GPT-4V 对生成图像与提示的相似程度给出从 1 到 10 的分数。蓝色突出显示了 GPT-4V 给出的评级。红色（绿色）表示错误（正确）渲染的文本。生成的图像来自 DeepFloyd IF [2]、Midjourney V5.1 [4]、SDXL [110] 和 ReCo [143]。查看第 9.6 节了解详细讨论。 113 图像编辑的提示生成 GPT-4 提示：这是原始图像：我想让该图像看起来像图画小说的封面。提示应为少于 15 个单词的单个句子，并带有描述性词语。例如：“让它看起来像一本图画小说”。根据上面的提示示例和原始图像，帮助我为图像编辑模型编写更好的提示。 GPT-4V：怎么样：“将这个雕像图像转变成一个戏剧性的暗色调图画小说封面。”指导 Pix2Pix：以原始图像和提示“将此雕像图像转换为具有暗色调的戏剧性图画小说封面”作为输入秒。 9.6 图像生成 图86：考虑到原始图像和文本要求，改进图像编辑的文本提示。蓝色突出显示 GPT-4V 建议的编辑提示。原始图像/示例编辑提示来自 Instruct Pix2Pix [22]。查看第 9.6 节了解详细讨论。 114 GPT-4 提示：这是原始图像：我用来编辑此图像的提示是“让它看起来像一本图画小说”。我得到的编辑后的图像是：GPT-4V：您可以尝试使用更具体的提示来引导人工智能朝着您希望图像前进的方向，而不是使用提示“让它看起来像图画小说”。例如，您可以使用诸如“使图像看起来像黑白漫画书插图”或“向图像添加粗线和高对比度，使其看起来像图画小说封面”等提示。这可以帮助人工智能更好地理解你想要的美感，并生成更精致的编辑图像。指导 Pix2Pix：使用原始图像和提示“使图像看起来像黑白漫画书插图”作为输入告诉我应该如何更改提示以使编辑后的图像更好。使用原始图像和提示“为图像添加粗线和高对比度，使其看起来像图画小说封面”作为图像编辑秒的输入提示生成。 9.6 图像生成 图 87：改进编辑提示，给出原始图像、编辑提示和编辑后的图像。蓝色突出显示 GPT-4V 建议的编辑提示。原始图像/编辑提示/编辑后的图像来自 Instruct Pix2Pix [22]。查看第 9.6 节了解详细讨论。 115 9.7 体现智能体 在本节中，我们深入研究 GPT-4V 对体现人工智能的令人兴奋的应用和影响，探索它如何准备弥合静态输入的多模态理解与动态环境的物理交互之间的差距。为了提供具体说明，让我们考虑一下 GPT-4V 扮演家庭机器人角色的场景。在此背景下，我们见证了它如何读取菜单来操作家用电器（例如咖啡机），并在房屋中执行面向任务的导航。操作机器。想象一下，您刚刚购买了一台全新的咖啡机，令您高兴的是，您值得信赖的家庭机器人 GPT-4V 会代表您学习如何操作它。在我们的实验中，我们为 GPT-4V 提供了单个图像（图 88），其中包含带有插图和文本的操作菜单。我们对 GPT-4V 的任务是识别与咖啡机操作面板中的“8 OZ 咖啡”选项相对应的按钮。令人惊讶的是，GPT-4V不仅准确定位了“8 OZ咖啡”按钮，还成功识别了“10 OZ咖啡”按钮。然而，它错误地将电源按钮识别为“6 OZ 咖啡”按钮，这可能是由于“6 OZ 咖啡”选项在菜单和咖啡机本身上的位置造成的视觉混乱。为了解决这种特定的故障情况，我们设计了一种解决方案，隔离每个按钮的操作菜单，并在单个提示中将它们全部呈现给 GPT-4V（图 89）。通过这种改进的方法，GPT-4V 现在可以识别“6 OZ 咖啡”按钮的精确位置。导航。为了探索导航功能，我们利用 Redfin 虚拟房屋游览作为为实体代理复制交互式环境的手段。目的是评估 GPT-4V 在面向任务的场景中的性能。为了说明这一点，我们提供了图 90-91 中所示的示例。最初，我们为 GPT-4V 提供了虚拟房屋参观的入口图像，提供了从一个角落到客厅的视图。分配给 GPT-4V 的任务是“去厨房并从冰箱中取出物品”。我们的目标是促使 GPT-4V 预测后续行动。在第一步中，如图 90 的上半部分所示，GPT-4V 通过建议“右转并向前走向走廊”来预测最初的行动。该预测基于 GPT-4V 的假设，即厨房可能位于该方向。然后，我们使用视觉房屋游览门户手动执行此操作，捕获执行操作后生成的视图。然后，该视图用于提示 GPT-4V 进行下一步操作，如图 90 的后半部分所示。值得注意的是，在整个过程中，我们维护了前一个回合的记录，为 GPT-4V 的操作提供上下文后续行动。随着导航过程的展开，我们在第三圈内成功到达冰箱，如图 91 后半部分的查询图像所示。GPT-4V 预测的最终动作是“按照顺序向前并稍微向左移动”。将自己与冰箱门对齐。然后，用我的机械臂打开冰箱门并取出所需的物品。”这一果断的行动标志着GPT-4V在这种面向任务的导航场景中取得了成就。 116 操作机器GPT-4 提示：首先，阅读下面的操作菜单以了解咖啡机按钮。菜单：秒。 9.7 Embodied Agent 现在，让我们看看下图中咖啡机的操作面板，对于 8 OZ 的咖啡，我应该使用哪个按钮：左、右、上、下按钮？ GPT-4V：您应该使用底部按钮来冲泡 8 盎司咖啡。根据菜单，底部按钮对应8盎司咖啡，顶部按钮对应6盎司咖啡，右侧按钮对应10盎司咖啡。图 88：GPT-4V 读取咖啡机按钮的完整菜单，识别为 8 盎司咖啡选择哪个按钮。绿色（红色）突出显示正确（错误）答案。查看第 9.7 节了解详细讨论。 117 操作机器GPT-4 提示：首先，阅读以下咖啡机按钮的操作菜单。菜单 1：现在，让我们看看下图中咖啡机的操作面板，对于 6 盎司的咖啡，我应该使用哪个按钮：左、右、顶部或底部按钮？ GPT-4V：您应该使用左侧按钮来冲泡 6 盎司咖啡。菜单 2：菜单 3：秒。 9.7 体现代理 图 89：将咖啡机按钮的完整菜单转换为交错的图像文本指令，GPT-4V 可以识别为 6 OZ 咖啡选择哪个按钮，而 GPT-4V 在完整菜单指令下无法做到这一点。绿色突出显示正确答案。查看第 9.7 节了解详细讨论。 118 提示：想象一下，你是一个家庭机器人，被要求去厨房从冰箱里拿东西。下图显示了您当前的位置。请计划您的下一步行动。 GPT-4V：我的下一个动作是右转并向走廊前进，因为我可以看到厨房可能位于那个方向。然后我会继续穿过走廊，直到到达厨房并找到冰箱。提示：想象一下，您是一个家庭机器人，被要求去厨房从冰箱里拿东西。在上一个转弯时，您位于下图所示的位置： GPT-4V：从当前位置，我可以看到右侧的厨房，我的下一个动作是向右转并向厨房前进。注意：与上一回合相同的图像，调整大小以节省空间上一回合采取的动作是：右转并向前朝走廊移动。现在你在走廊，这就是你从那里可以看到的。从这里你能看到厨房吗？您的下一步行动是什么？导航科9.7 实体代理 图 90：充当实体代理，在房屋中导航并从冰箱中取东西（第 1 圈和第 2 圈）。蓝色突出显示了预测的操作。查看第 9.7 节了解详细讨论。 119 导航 GPT-4 提示：想象一下，您是一个家庭机器人，被要求去厨房从冰箱里拿东西。在上一回合中，您位于下图所示的位置： GPT-4V：从这个位置，我可以看到厨房右侧的冰箱。我的下一步行动是向前移动并稍微向右转以接近冰箱。注意：与上一回合相同的图像，调整大小以节省空间上一回合采取的动作是：右转并向厨房前进。现在你在厨房，这是你从那里可以看到的。从这里你能看到冰箱吗？您的下一步行动是什么？提示：想象一下，您是一个家庭机器人，被要求去厨房从冰箱里拿东西。在上一回合，您位于下图所示的位置： GPT-4V：我的下一步动作是向前并稍微向左移动，使自己与冰箱门对齐。然后，我会用机械臂打开冰箱门并取出所需的物品。注意：与上一回合相同的图像，调整大小以节省空间上一回合采取的动作是：向前移动并稍微向右转向以接近冰箱。现在你可以从那里看到这个。您的下一步行动是什么？秒。 9.7 实体代理 图 91：充当实体代理，在房屋中导航并从冰箱中取东西（第 3 和第 4 回合）。蓝色突出显示了预测的操作。查看第 9.7 节了解详细讨论。 120 9.8 GUI 导航 除了在物理世界中导航之外，本节还展示了 GPT-4V 与计算机或智能手机的图形用户界面 (GUI) 进行交互和导航的能力。我们探索 GPT-4V 完成复杂任务的潜力，例如网页浏览、在线购物等。 网页浏览。我们在面向任务的设置下评估 GPT-4V 在计算机 GUI 导航上的性能。该模型提供了当前计算机屏幕的屏幕截图、导航的最终目标（例如，查找烹饪食谱或阅读今天的新闻）、可能的操作列表（例如，移动鼠标、用鼠标单击图标、或用键盘输入一些文本）。然后指示模型预测后续操作（有关完整的提示示例，请参阅图 92）。根据模型的预测，我们手动执行预测的动作并捕获屏幕截图，作为下一回合 GPT-4V 的输入。当预测的动作是移动鼠标时，GPT-4V 会被专门指示详细说明鼠标的位置。因此，预测的动作是有根据的，显示出在没有人参与的情况下自动化整个过程的潜力。在图 92-96 中，GPT-4V 预测操作计算机 GUI 的合理动作，最终实现找到麻婆豆腐食谱的最终目标，并打印出图 95 中的食谱副本。然后我们为 GPT-4V 提供一个打印的食谱的屏幕截图，并要求其尽可能详细地描述打印输出。如图 96 所示，GPT-4V 能够识别打印输出中呈现的详细信息，包括烹饪时间、配料列表、菜谱作者、原始菜谱链接等。图 97-102 呈现GPT-4V 如何通过 GUI 浏览网页来“阅读今日新闻”。尽管图 100 中在尝试返回上一个搜索结果页面以继续浏览更多新闻文章时出现了一些小错误，但 GPT-4V 仍可以相当好地执行导航并阅读两篇新闻文章。网上购物。图 103-111 说明了 GPT-4V 如何导航智能手机 GUI 进行在线购物。同样，我们向 GPT-4V 提供当前手机屏幕的屏幕截图、可能的操作列表（例如，将手指移动到图标、用手指单击图标、向下滚动屏幕或使用键盘输入一些文本） ）并要求它预测购买预算在 50 美元到 100 美元之间的人体工学键盘的后续操作。 GPT-4V预测打开亚马逊应用程序（图103），搜索人体工学键盘（图104），打开过滤器选项（图105），将价格范围过滤器设置在50美元到100美元之间（图106），显示过滤结果（图106） （图107），选择顶部搜索结果（图108），查看产品详细信息（图109），将产品添加到购物车（图110），最后进行结帐（图111）。通知理解。通知是现代人机交互不可或缺的一部分。 GPT-4V 已展示其解释通知内容并做出相应响应的能力。如图 112 所示，该模型可以读取并响应通知，例如建议打开地图应用程序以响应西雅图的会议提案。它还可以有效地处理计算机屏幕上的呼叫（图 113）和消息（图 114）通知。看视频。除了网页浏览之外，视频也是在线信息的重要来源。 GPT-4V 已经展示了其基于流行短视频的一系列屏幕截图来描述视频内容的能力。无论视频是否有字幕叠加（图 115 和 116）（图 117、118、119），GPT-4V 都可以生成有关视频内容的深刻描述，展示了其在自动生成用户生成视频内容的脚本方面的潜力。 121提示：想象一下你是一个操作计算机的机器人。就像人类操作计算机一样，您可以移动鼠标，用鼠标单击图标，或者用键盘输入一些文本。要求你找到麻婆豆腐的详细食谱。以下是您在计算机屏幕上看到的内容，预测您的下一步行动。如果操作涉及移动鼠标，请尽可能详细地描述位置。 GPT-4V：下一步：我将鼠标移动到位于屏幕左侧的 Google Chrome 图标，大约从顶部向下 1/3 的位置。然后我会单击该图标打开网络浏览器。提示：想象一下你是一个操作计算机的机器人。就像人类操作计算机一样，您可以移动鼠标，用鼠标单击图标，或者用键盘输入一些文本。要求你找到麻婆豆腐的详细食谱。上一操作：“我将鼠标移动到位于屏幕左侧的 Google Chrome 图标，大约从顶部向下 1/3 处。然后单击该图标以打开 Web 浏览器。”现在已打开网络浏览器。以下是您在计算机屏幕上看到的内容。接下来你会做什么？如果操作涉及移动鼠标，请尽可能详细地描述位置。 GPT-4V：接下来，我将鼠标移动到位于屏幕中央的搜索栏，大约从顶部向下 1/2 处。然后我会点击搜索栏并使用键盘输入“麻婆豆腐食谱”。输入搜索查询后，我会按键盘上的“Enter”键启动搜索。网页浏览（麻婆豆腐食谱）二段9.8 GUI 导航 图 92：GPT-4V 通过 GUI 导航，浏览网页搜索麻婆豆腐的菜谱。蓝色突出显示了预测的操作。查看第 9.8 节了解详细讨论。 122 提示：想象一下你是一个操作计算机的机器人。就像人类操作计算机一样，您可以移动鼠标，用鼠标单击图标，或者用键盘输入一些文本。要求你找到麻婆豆腐的详细食谱。上一操作：“我将鼠标移动到位于屏幕中央的搜索栏，大约从顶部向下 1/2。然后，我将单击搜索栏并使用以下命令输入“麻婆豆腐食谱”键盘。输入搜索查询后，我会按键盘上的“Enter”键启动搜索。”您现在已经完成了上述之前的操作。以下是您在计算机屏幕上看到的内容。接下来你会做什么？如果操作涉及移动鼠标，请尽可能详细地描述位置。 GPT-4V：下一步操作：“我将鼠标移动到“食谱”部分下的第一个搜索结果，标题为“麻婆豆腐食谱 - 生活的锅”。然后我会单击链接打开网页并查看详细食谱。”网页浏览（麻婆豆腐食谱）二段9.8 GUI 导航 图 93：GPT-4V 通过 GUI 导航，浏览网页搜索麻婆豆腐的菜谱。蓝色突出显示了预测的操作。查看第 9.8 节了解详细讨论。 123 提示：想象一下你是一个操作计算机的机器人。就像人类操作计算机一样，您可以移动鼠标，用鼠标单击图标，或者用键盘输入一些文本。要求你找到麻婆豆腐的详细食谱。上一操作：“我将鼠标移动到“食谱”部分下的第一个搜索结果，标题为“麻婆豆腐食谱 - 生活的锅”。然后我会点击链接打开网页并查看详细的食谱。” 您现在已经完成了上述操作。下面是您在计算机屏幕上看到的内容。根据下图，您下一步要做什么? 如果操作涉及移动鼠标，请尽可能详细地描述位置。GPT-4V：下一步操作：“我会将鼠标移动到位于网页右上角的“跳转到菜谱”按钮。然后我会点击按钮跳转到页面的详细菜谱部分。” 网页浏览（麻婆豆腐菜谱）第 9.8 节 GUI 导航 图 94：GPT-4V 通过 GUI 导航来浏览网页以搜索菜谱麻婆豆腐。蓝色突出显示了预测的动作。详细讨论请参见第 9.8 节。 124 提示：假设你是一个操作计算机的机器人。就像人类操作计算机一样，你可以移动鼠标，用鼠标单击图标，或者用键盘输入一些文字。系统会要求您查找麻婆豆腐的详细食谱。上一步操作：“我将鼠标移动到位于网页右上角的“跳转到食谱”按钮。然后单击点击按钮跳转到页面的详细食谱部分。”您现在已经完成了上述之前的操作。以下是您在计算机屏幕上看到的内容。根据下图，你接下来要做什么？如果操作涉及移动鼠标，请尽可能详细地描述位置。 GPT-4V：下一步操作：“我将鼠标移动到位于菜谱部分右上角的“打印菜谱”按钮，位于“评价此菜谱”按钮旁边。然后单击该按钮进行打印出一份麻婆豆腐的详细食谱。”网页浏览（麻婆豆腐食谱）第 9.8 节 GUI 导航 图 95：GPT-4V 通过 GUI 浏览网页搜索麻婆豆腐食谱。蓝色突出显示预测的操作。详细讨论请参阅第 9.8 节。 125 提示：尽可能详细地描述下面的图片。GPT-4V：该图片是麻婆豆腐的菜谱，一道中国菜。菜谱以结构化格式呈现，包括标题、描述、准备时间、烹饪时间、总时间、课程菜谱、菜品、份量、评分。菜谱的标题是“麻婆豆腐”，用黑体字写着。标题下面有菜品的介绍，说是正宗的正宗正品- 麻辣麻辣的米饭，绝对不能少的麻婆豆腐，准备时间10分钟，煮时间25分钟，总时间35分钟课程被列为“主菜”，菜肴为“中式”。菜谱可供 6 人食用，评分为 4.69 星（满分 5 星）。在该信息的下方，列出了该菜品所需的食材列表，包括豆腐、猪肉末、花椒、大蒜、生姜、酱油和玉米淀粉。成分以要点格式列出。图像底部有该菜肴的营养信息，包括卡路里、碳水化合物、蛋白质、脂肪、饱和脂肪、胆固醇、钠和钙。营养信息以表格形式呈现。该图像还包含菜谱作者 Kaitlin 的署名，以及“The Woks of Life”网站上原始菜谱的链接。网页浏览（麻婆豆腐食谱）二段9.8 GUI 导航 图 96：GPT-4V 通过 GUI 导航，浏览网页搜索麻婆豆腐的菜谱。由于 GPT-4V 预测会打印出上一轮的菜谱，因此我们提示它读取打印菜谱的屏幕截图并进行总结。红色突出显示有关图像的不准确描述。查看第 9.8 节了解详细讨论。 126 提示：想象一下你是一个操作计算机的机器人。就像人类操作计算机一样，您可以移动鼠标，用鼠标单击图标，或者用键盘输入一些文本。要求您查找今天的新闻内容。以下是您在计算机屏幕上看到的内容，预测您的下一步行动。如果操作涉及移动鼠标，请尽可能详细地描述位置。 GPT-4V：我的下一步是将鼠标移动到位于屏幕左侧的 Google Chrome 图标，大约从顶部向下 1/3 的位置。然后，我会单击该图标打开网络浏览器并搜索新闻网站以了解今天的新闻内容。提示：想象一下你是一个操作计算机的机器人。就像人类操作计算机一样，您可以移动鼠标，用鼠标单击图标，或者用键盘输入一些文本。要求您查找今天的新闻内容。上一个操作：“我的下一步是将鼠标移动到位于屏幕左侧的 Google Chrome 图标，大约从顶部向下 1/3。然后我将单击该图标以打开网页浏览器并搜索新闻网站以了解今天的新闻。”您现在已打开网络浏览器。以下是您在计算机屏幕上看到的内容，您下一步要做什么？如果操作涉及移动鼠标，请尽可能详细地描述位置。 GPT-4V：我的下一步是将鼠标移动到位于屏幕中心的搜索栏，大约从顶部向下的 1/2。然后，我会单击搜索栏并输入“新闻”，然后按键盘上的回车键来搜索新闻网站。网络浏览（今日新闻）秒。 9.8 GUI 导航 图 97：GPT-4V 通过 GUI 导航来浏览网页以阅读今日新闻。蓝色突出显示了预测的操作。查看第 9.8 节了解详细讨论。 127 提示：想象一下你是一个操作计算机的机器人。就像人类操作计算机一样，您可以移动鼠标，用鼠标单击图标，或者用键盘输入一些文本。要求您查找今天的新闻内容。上一操作：“我的下一步是将鼠标移动到位于屏幕中心的搜索栏，大约从顶部向下 1/2。然后我会单击搜索栏并输入“ news”并按键盘上的回车键搜索新闻网站。”您现在已经完成了前面的操作。以下是您在计算机屏幕上看到的内容。根据下图，您下一步要做什么？如果操作涉及移动鼠标，请尽可能详细地描述位置。 GPT-4V：我的下一步是将鼠标移至第一个搜索结果，即“国务院加倍关注泽伦斯基猛烈攻击”，位于屏幕顶部向下大约 1/4 和 1/8 处从屏幕左侧开始。然后，我会单击链接打开新闻文章并阅读今天的新闻内容。网络浏览（今日新闻）秒。 9.8 GUI 导航 图 98：GPT-4V 通过 GUI 导航来浏览网页以阅读今日新闻。蓝色突出显示了预测的操作。查看第 9.8 节了解详细讨论。 128 提示：阅读下图所示的文章并总结。 GPT-4V：摘要：本文讨论了乌克兰总统弗拉基米尔·泽伦斯基周二发表的声明，他在声明中表达了乌克兰加入北约的愿望。泽连斯基表示，乌克兰无法承担与俄罗斯开战的代价，加入北约将提供必要的安全和保护。不过，北约发言人马修·米勒表示，虽然该联盟准备向乌克兰发出邀请，但需要满足某些条件。这些条件包括民主和安全部门改革。米勒还强调，乌克兰加入北约并不是保证，最终决定权在于联盟成员。文章还提到，泽连斯基在周二的新闻发布会上重申了加强乌克兰民主的承诺，这是加入北约的必要条件。网络浏览（今日新闻）秒。 9.8 GUI 导航 图 99：GPT-4V 通过 GUI 导航来浏览网页以阅读今日新闻。我们提示 GPT-4V 阅读第一篇新闻文章的屏幕截图并进行总结。查看第 9.8 节了解详细讨论。 129 提示：想象一下你是一个操作计算机的机器人。就像人类操作计算机一样，您可以移动鼠标，用鼠标单击图标，或者用键盘输入一些文本。要求您查找今天的新闻内容。上一操作：“我的下一步是将鼠标移至第一个搜索结果，即“国务院对泽连斯基猛烈抨击加倍”，位于屏幕顶部向下大约 1/4 处和 1/8 处从屏幕左侧的方式。然后我会点击链接打开新闻文章并阅读今天的新闻内容。”您现在已经读完“国务院加大力度抨击泽连斯基”。您下一步的下一步计划是什么？如果操作涉及移动鼠标，请尽可能详细地描述位置。 GPT-4V：我的下一步是将鼠标移动到屏幕的右上角，在那里我可以看到“X”图标来关闭当前选项卡。然后，我会单击“X”图标关闭选项卡并返回上一页以继续浏览更多新闻文章。网络浏览（今日新闻）秒。 9.8 GUI 导航 图 100：GPT-4V 通过 GUI 导航来浏览网页以阅读今日新闻。阅读完第一篇新闻文章后，GPT-4V 预测关闭选项卡并返回上一页以继续浏览更多新闻文章（以蓝色突出显示）。红色突出显示了不准确的动作预测。查看第 9.8 节了解详细讨论。 130提示：想象一下你是一个操作计算机的机器人。就像人类操作计算机一样，您可以移动鼠标，用鼠标单击图标，或者用键盘输入一些文本。要求您查找今天的新闻内容。上一操作：“我的下一步是将鼠标移动到屏幕的右上角，在那里我可以看到“X”图标来关闭当前选项卡。然后我会单击“X”图标来关闭标签并返回上一页继续浏览更多新闻文章。”在阅读第一篇文章“国务院加大对泽连斯基的猛烈抨击”后，您现在已返回上一页。以下是您在计算机屏幕上看到的内容。根据下图，您下一步要做什么？如果操作涉及移动鼠标，请尽可能详细地描述位置。GPT-4V：我的下一步是将鼠标移动到页面上的第二篇文章，“由于强烈的风暴迫使疏散，灾难性的洪水淹没了佛罗里达州的狭长地带”。我会将鼠标移动到文章标题的左侧，大约是页面下方的 1/3，然后单击文章标题将其打开并阅读新闻。浏览网页（今日新闻）秒。 9.8 GUI 导航 图 101：GPT-4V 通过 GUI 导航来浏览网页以阅读今日新闻。蓝色突出显示了预测的操作。查看第 9.8 节了解详细讨论。 131 提示：阅读下图文章并总结。 GPT-4V：文章讨论了 2023 年 7 月 11 日星期二在佛蒙特州首府蒙彼利埃发生的灾难性洪水。洪水是由淹没东北部的强暴雨引起的，导致该地区疏散和关闭。官员们将这次洪水描述为“史无前例”和“历史性”，一些地区的降雨量破了纪录。国家气象局发布旅行警告，警告居民避免不必要的旅行。佛蒙特州州长菲尔·斯科特宣布进入紧急状态，新罕布什尔州派出救援人员和黑鹰直升机协助应对。佛蒙特州消防局和其他紧急服务部门也被派往受影响地区。洪水对房屋和企业造成了广泛破坏，一些居民被迫撤离。蒙彼利埃发布了烧水通知，官员们周三开始清理道路上的碎片。在俄克拉荷马城，两名被洪水冲走的儿童从水库中获救。这两个孩子分别为 10 岁和 11 岁，他们是在该地区钓鱼的四人小组中的一员。在纽约，飓风艾琳在 24 小时内造成了 8 英寸的降雨，导致基础设施严重受损。长湖镇镇长克莱·阿瑟诺宣布进入紧急状态，并敦促居民撤离。文章最后引用了佛蒙特州切斯特居民丹·汉考克的一句话，他亲眼目睹洪水进入他的地下室。他表达了他的沮丧和无助，他说：“一旦水退下去，我们就回去，清理干净，然后继续前进。我们能做什么？” 9.8 GUI 导航 图 102：GPT-4V 通过 GUI 导航来浏览网页以阅读今日新闻。我们提示GPT-4V阅读第二篇新闻文章的截图并进行总结。查看第 9.8 节了解详细讨论。 132 提示：想象一下你是一个操作电话的机器人。就像人类操作手机的方式一样，您可以将手指移动到图标上，用手指单击图标，向下滚动屏幕或使用键盘输入一些文本。您被要求购买符合人体工学的键盘，您的预算在 50 美元到 100 美元之间。以下是您在手机屏幕上看到的内容，预测您的下一步行动。如果操作涉及将手指移至图标，请尽可能详细地描述该图标的位置。 GPT-4V：我的下一步是将手指移至位于屏幕第三行第三列的亚马逊图标。然后，我会点击图标打开应用程序，并在我的预算范围内搜索 50 到 100 美元之间的人体工学键盘。网上购物（人体工学键盘）第二节9.8 GUI 导航 图 103：GPT-4V 通过 GUI 导航以在线购买人体工学键盘。蓝色突出显示了预测的操作。红色突出显示亚马逊图标的不准确位置。查看第 9.8 节了解详细讨论。 133 提示：想象一下你是一个操作电话的机器人。就像人类操作手机的方式一样，您可以将手指移动到图标上，用手指单击图标，向下滚动屏幕或使用键盘输入一些文本。您被要求购买符合人体工学的键盘，您的预算在 50 美元到 100 美元之间。上一个操作：“我的下一步是将手指移至位于屏幕第三行第三列的亚马逊图标。然后我会单击该图标打开应用程序并在其中搜索符合人体工学的键盘我的预算是 50 美元。”您现在已经打开了亚马逊应用程序。以下是您在手机屏幕上看到的内容。接下来你会做什么？如果操作涉及将手指移至图标，请尽可能详细地描述该图标的位置。 GPT-4V：我的下一步是将手指移至位于屏幕顶部的搜索栏。然后，我会单击搜索栏并使用键盘输入“人体工学键盘”。输入搜索词后，我会单击键盘右下角的“搜索”按钮来启动搜索。网上购物（人体工学键盘）第二节9.8 GUI 导航 图 104：GPT-4V 通过 GUI 导航以在线购买人体工学键盘。蓝色突出显示了预测的操作。查看第 9.8 节了解详细讨论。 134 提示：想象一下你是一个操作电话的机器人。就像人类操作手机的方式一样，您可以将手指移动到图标上，用手指单击图标，向下滚动屏幕或使用键盘输入一些文本。您被要求购买符合人体工学的键盘，您的预算在 50 美元到 100 美元之间。上一操作：“我的下一步是将手指移至位于屏幕顶部的搜索栏。然后，我将单击搜索栏并使用键盘输入“人体工学键盘”。输入后搜索词，我会单击位于键盘右下角的“搜索”按钮来启动搜索。“您现在已经完成了上述操作。以下是您在手机屏幕上看到的内容。请预测您的下一步行动。如果操作涉及将手指移至图标，请尽可能详细地描述该图标的位置。 GPT-4V：我的下一步行动是将手指移至“过滤器”按钮，该按钮位于屏幕右上角，“Windows”按钮旁边。然后，我会单击“过滤器”按钮打开过滤器选项，并缩小搜索结果范围，仅显示我的预算范围（50 美元到 100 美元）内的人体工学键盘。网上购物（人体工学键盘）第二节9.8 GUI 导航 图 105：GPT-4V 通过 GUI 导航以在线购买人体工学键盘。蓝色突出显示了预测的操作。查看第 9.8 节了解详细讨论。 135 提示：想象一下你是一个操作电话的机器人。就像人类操作手机的方式一样，您可以将手指移动到图标上，用手指单击图标，向下滚动屏幕或使用键盘输入一些文本。您被要求购买符合人体工学的键盘，您的预算在 50 美元到 100 美元之间。上一操作：“我的下一步行动是将手指移至“过滤器”按钮，该按钮位于屏幕右上角，“Windows”按钮旁边。然后我将单击“过滤器”按钮打开过滤器选项并缩小搜索结果范围，仅显示我的预算范围为 50 美元到 100 美元的人体工学键盘。” 您现在已经完成了上述操作。以下是您在手机屏幕上看到的内容。请预测您的下一步行动。如果操作涉及将手指移至图标，请尽可能详细地描述该图标的位置。 GPT-4V：我的下一步行动是将手指移至“价格和交易”过滤器选项，该选项位于“颜色”过滤器选项下方和“排序方式”过滤器选项上方。然后，我会单击“价格和优惠”筛选器选项以打开价格范围筛选器，并将最低价格设置为 50 美元，最高价格设置为 100 美元。这将进一步缩小我的搜索结果，仅显示我预算范围内的人体工学键盘。网上购物（人体工学键盘）第二节9.8 GUI 导航 图 106：GPT-4V 通过 GUI 导航以在线购买人体工学键盘。蓝色突出显示了预测的操作。查看第 9.8 节了解详细讨论。 136 提示：想象一下你是一个操作电话的机器人。就像人类操作手机的方式一样，您可以将手指移动到图标上，用手指单击图标，向下滚动屏幕或使用键盘输入一些文本。您被要求购买符合人体工学的键盘，您的预算在 50 美元到 100 美元之间。上一操作：“我的下一步行动是将手指移至“价格和优惠”过滤器选项，该选项位于“颜色”过滤器选项下方、“排序方式”过滤器选项上方。然后，我将单击“价格和优惠”筛选选项可打开价格范围筛选器，并将最低价格设置为 50 美元，最高价格设置为 100 美元。这将进一步缩小我的搜索结果范围，仅显示我的预算范围内的人体工学键盘。“您现在已完成如上所述的先前操作。以下是您在手机屏幕上看到的内容。接下来你会做什么？如果操作涉及将手指移至图标，请尽可能详细地描述该图标的位置。 GPT-4V：我的下一步是将手指移至“显示 1,987 个结果”按钮，该按钮位于屏幕底部、“清除过滤器”按钮下方、导航栏上方。然后，我会单击“显示 1,987 个结果”按钮，查看我的预算范围内的人体工学键盘的搜索结果。网上购物（人体工学键盘）第二节9.8 GUI 导航 图 107：GPT-4V 通过 GUI 导航以在线购买人体工学键盘。蓝色突出显示了预测的操作。查看第 9.8 节了解详细讨论。 137 提示：想象一下你是一个操作电话的机器人。就像人类操作手机的方式一样，您可以将手指移动到图标上，用手指单击图标，向下滚动屏幕或使用键盘输入一些文本。您被要求购买符合人体工学的键盘，您的预算在 50 美元到 100 美元之间。上一操作：“我的下一步是将手指移至“显示 1,987 个结果”按钮，该按钮位于屏幕底部、“清除过滤器”按钮下方和导航栏上方。然后我会单击“显示 1,987 个结果”按钮可查看我的预算范围内的人体工学键盘的搜索结果。“您现在已经完成了上述操作。以下是您在手机屏幕上看到的内容。接下来你会做什么？如果操作涉及将手指移至图标，请尽可能详细地描述该图标的位置。 GPT-4V：我的下一步是向下滚动屏幕，查看在我的预算范围内符合人体工学键盘的不同选项。然后，我将手指移至“Kensington Pro Fit 人体工学无线键盘 - 黑色”选项，该选项位于“探索相关品牌”部分下方和“VIVO”选项上方。然后，我会单击“Kensington Pro Fit 人体工学无线键盘 - 黑色”选项，查看有关该产品的更多详细信息并可能进行购买。网上购物（人体工学键盘）第二节9.8 GUI 导航 图 108：GPT-4V 通过 GUI 导航以在线购买人体工学键盘。蓝色突出显示了预测的操作。红色突出显示要选择的产品选项的不准确位置。查看第 9.8 节了解详细讨论。 138 提示：想象一下你是一个操作电话的机器人。就像人类操作手机的方式一样，您可以将手指移动到图标上，用手指单击图标，向下滚动屏幕或使用键盘输入一些文本。您被要求购买符合人体工学的键盘，您的预算在 50 美元到 100 美元之间。上一操作：“我的下一步是向下滚动屏幕，查看我的预算范围内人体工学键盘的不同选项。然后，我将手指移至“Kensington Pro Fit 人体工学无线键盘 - 黑色”选项，该选项位于在“探索相关品牌”部分下方和“VIVO”选项上方。然后，我会单击“Kensington Pro Fit 人体工学无线键盘 - 黑色”选项以查看有关该产品的更多详细信息并可能进行购买。“您现在已经如上所述完成先前的操作。以下是您在手机屏幕上看到的内容。接下来你会做什么？如果操作涉及将手指移至图标，请尽可能详细地描述该图标的位置。 GPT-4V：我的下一步是向下滚动屏幕以查看有关“Kensington Pro Fit 人体工学无线键盘 - 黑色”产品的更多详细信息。然后，我会将手指移至“购买新产品”按钮，该按钮位于产品图片下方、“当您向礼品卡余额充值 100 美元或以上时，可获得 8 美元奖金”部分上方。然后我会单击“购买新产品”按钮继续购买。网上购物（人体工学键盘）第二节9.8 GUI 导航 图 109：GPT-4V 通过 GUI 导航以在线购买人体工学键盘。蓝色突出显示了预测的操作。红色突出显示不准确的动作预测（“购买新的”不是可点击的按钮）。查看第 9.8 节了解详细讨论。 139 提示：想象一下你是一个操作电话的机器人。就像人类操作手机的方式一样，您可以将手指移动到图标上，用手指单击图标，向下滚动屏幕或使用键盘输入一些文本。您被要求购买符合人体工学的键盘，您的预算在 50 美元到 100 美元之间。上一操作：“我的下一步是向下滚动屏幕以查看有关“Kensington Pro Fit 人体工学无线键盘 - 黑色”产品的更多详细信息。然后我会将手指移至位于下方的“购买新产品”按钮产品图片以及“当您向礼品卡余额充值 100 美元或更多时获得 8 美元奖金”部分上方。然后我将单击“购买新产品”按钮继续购买。“您现在已完成之前的操作如上所述。以下是您在手机屏幕上看到的内容。接下来你会做什么？如果操作涉及将手指移至图标，请尽可能详细地描述该图标的位置。 GPT-4V：我的下一步是将手指移至“添加到购物车”按钮，该按钮位于“购买新品”按钮下方和“亚马逊发货”部分上方。然后，我会单击“添加到购物车”按钮将商品添加到我的购物车。网上购物（人体工学键盘）第二节9.8 GUI 导航 图 110：GPT-4V 通过 GUI 导航以在线购买人体工学键盘。蓝色突出显示了预测的操作。查看第 9.8 节了解详细讨论。 140提示：想象一下你是一个操作电话的机器人。就像人类操作手机的方式一样，您可以将手指移动到图标上，用手指单击图标，向下滚动屏幕或使用键盘输入一些文本。您被要求购买符合人体工学的键盘，您的预算在 50 美元到 100 美元之间。上一操作：“我的下一步是将手指移至“添加到购物车”按钮，该按钮位于“购买新品”按钮下方和“亚马逊发货”部分上方。然后，我将单击“添加”到购物车”按钮将商品添加到我的购物车。”您现在已经完成了上述操作。以下是您在手机屏幕上看到的内容。接下来你会做什么？如果操作涉及将手指移至图标，请尽可能详细地描述该图标的位置。 GPT-4V：我的下一步是将手指移至“继续结帐”按钮，该按钮位于“与类似商品比较”部分下方和“30 天退货”部分上方。然后，我会单击“继续结账”按钮以继续购买。网上购物（人体工学键盘）第二节9.8 GUI 导航 图 111：GPT-4V 通过 GUI 导航以在线购买人体工学键盘。蓝色突出显示了预测的操作。红色突出显示“继续结帐”按钮的位置不准确。查看第 9.8 节了解详细讨论。 141提示：想象一下你是一个操作电话的机器人。就像人类操作手机的方式一样，您可以将手指移动到图标上，用手指单击图标，向下滚动屏幕或使用键盘输入一些文本。以下是您在手机屏幕上看到的内容。描述图像并预测你的下一步行动。如果操作涉及将手指移至图标，请尽可能详细地描述该图标的位置。 GPT-4V：手机屏幕上的图像是iPhone的主屏幕。多个应用程序图标呈网格状排列，包括日历、设置、Twitter、亚马逊、Instagram 等。屏幕顶部有一条来自名为“yykhahah”的用户的通知，上面写着“我看到你了”我们在西雅图，我们见面吧。”屏幕底部有一个搜索栏。根据通知，我的下一步是将手指移至地图应用程序图标，该图标位于应用程序网格的第二行第一列。这将使我能够搜索西雅图的位置并计划与用户会面。通知理解秒。 9.8 GUI 导航 图 112：提示 GPT-4V 预测收到通知后的操作。 GPT-4V可以准确识别通知和相应的内容（以绿色突出显示）。蓝色突出显示了预测的操作。红色突出显示地图应用程序图标的不准确位置。查看第 9.8 节了解详细讨论。 142 提示：想象一下你是一个操作计算机的机器人。就像人类操作计算机一样，您可以移动鼠标，用鼠标单击图标，或者用键盘输入一些文本。以下是您在计算机屏幕上看到的内容。描述图像并预测你的下一步行动。如果操作涉及移动鼠标，请尽可能详细地描述位置和图标。 GPT-4V：计算机屏幕上的图像是水面上一座桥的桌面背景。桌面上有多个图标，包括 YouTube 图标、回收站图标和终端图标。屏幕底部有一个任务栏，其中包含多个应用程序图标，例如 Microsoft Edge 和文件资源管理器。屏幕右下角有一条通知，显示“林凯文正在给你打电话。”根据通知，我的下一步是将鼠标移动到屏幕右下角，然后单击通知。这将打开通话应用程序并允许我接听 Kevin Lin 的电话。通知理解秒。 9.8 GUI 导航 图 113：提示 GPT-4V 预测收到通知后的操作。 GPT-4V可以准确识别通知和相应的内容（以绿色突出显示）。蓝色突出显示了预测的操作。红色突出显示地图应用程序图标的不准确位置。查看第 9.8 节了解详细讨论。 143 提示：想象一下你是一个操作计算机的机器人。就像人类操作计算机一样，您可以移动鼠标，用鼠标单击图标，或者用键盘输入一些文本。以下是您在计算机屏幕上看到的内容。描述图像并预测你的下一步行动。如果操作涉及移动鼠标，请尽可能详细地描述位置。 GPT-4V：计算机屏幕上的图像是海洋上一座桥梁的美丽鸟瞰图的桌面背景。屏幕左侧有几个图标，包括回收站、终端和其他一些图标。在右下角，有一条来自消息应用程序的通知，来自一位名叫 Kevin Lin 的用户，询问我今天下午是否有空聊天。我的下一步是将鼠标移动到屏幕右下角，然后单击 Kevin Lin 的通知，打开消息应用程序并回复他的消息。我会将鼠标移动到通知的确切位置，距离屏幕右边缘大约 2 英寸，距离屏幕下边缘大约 1 英寸。通知理解秒。 9.8 GUI 导航 图 114：提示 GPT-4V 预测收到通知后的操作。 GPT-4V可以准确识别通知和相应的内容（以绿色突出显示）。蓝色突出显示了预测的操作。查看第 9.8 节了解详细讨论。 144 提示：解释下图中的故事。 GPT-4V：这些图像显示了 Instagram 上的一个卷轴，用户正在分享一个幽默的帖子，讲述他们在狗身上花了多少钱。第一张图片显示一名男子抱着他的狗，标题是“当有人问我在我的狗身上花了多少钱”。接下来的三张图片显示了乔·拜登的一段片段，他说“7000亿”，然后是“7000亿和1万亿3亿”和“7000亿和1万亿3亿美元”。该用户使用乔·拜登说一大笔钱的片段开玩笑地夸大了他们在狗身上花费的金额。提示：根据下面的帧，告诉我有关视频内容的信息。 GPT-4V：视频内容是亚洲人无缘无故做的事情的汇编。该视频由用户 laparasian 发布在 TikTok 上，拥有 130 万次观看和 1.31 万人点赞。该视频由sophrelabelous 设置为原始音频，并带有#asian 和#relatable 标签。该视频分为 5 个不同的场景： 1. 第一个场景显示一个女孩从超市货架后面抓取产品。 2. 第二个场景展示了一个女孩在使用之前冲洗干净的杯子。 3. 第三个场景是两个女孩问“你吃饭了吗？”作为一种打招呼的方式。 4. 第四个场景是两个女孩在餐馆里为结账而激烈争斗。 5. 第五个场景是一个女孩把裤子绕在脖子上看是否合身。总的来说，该视频以幽默的方式呈现了亚洲社区中常见的一些怪癖和习惯。观看视频第二节9.8 GUI 导航 图 115：提示 GPT-4V 观看网络视频。我们按照原始视频中的时间顺序呈现 GPT-4V 视频帧的屏幕截图。为了节省空间，我们将帧排成一行，其中最左边的帧是第一帧。查看第 9.8 节了解详细讨论。红色突出显示有关视频的不准确描述。 145 提示：转录视频内容，给定以下帧。 GPT-4V：大家好，这里是 natyexplora，今天我将分享华盛顿州您需要参观的 7 个地方。首先，我们有北喀斯喀特国家公园。这个公园充满了美丽的山景和远足小径。这是任何自然爱好者的必游之地。接下来是奥林匹克半岛。该地区是著名的 Hoh 雨林和美丽的海滩的所在地。这是放松身心并享受华盛顿自然美景的好地方。名单上的第三位是贝克山荒野。该地区以其迷人的山景和远足小径而闻名。这是逃离城市、享受户外活动的好地方。接下来，我们要去雷尼尔山国家公园。该公园是华盛顿最高山峰的所在地，是徒步旅行和观光的好地方。排名第五的是高山湖泊荒野。该地区遍布美丽的高山湖泊和远足小径。这是花一天时间探索和享受华盛顿自然美景的好地方。接下来，我们有皮尔查克山州立公园。这个公园以其美丽的景色和远足小径而闻名。这是花一天时间探索和享受华盛顿自然美景的好地方。最后但并非最不重要的一点是，我们有吉福德·平肖国家森林。这片森林拥有美丽的山景和远足小径。这是逃离城市、享受户外活动的好地方。这就是我在华盛顿州需要参观的 7 个地方的清单。我希望您喜欢它，并受到启发去探索更多这个美丽的州。提示：根据下面的帧，告诉我有关视频内容的信息。 GPT-4V：视频内容是关于一只名叫Tofu的柯基犬在家工作的故事。第一帧显示 Tofu 睡在床上，标题为“WFH 员工：上午 8:59”。第二帧显示 Tofu 坐在一台有多个屏幕的电脑前，标题为“WFH 员工：上午 9:00”。该视频可能是对在家工作体验的幽默呈现，强调了豆腐就像其他员工一样，早上很难起床，但一旦在电脑前就准备好工作。观看视频第二节9.8 GUI 导航 图 116：观看网络视频。我们按照原始视频中的时间顺序呈现 GPT-4V 视频帧的屏幕截图。为了节省空间，我们将帧排成一行，其中最左边的帧是第一帧。查看第 9.8 节了解详细讨论。 146 提示：请告诉我视频内容，给出下面的帧。请提供尽可能多的详细信息。 GPT-4V：视频内容是有关如何制作覆盆子极乐球的教程，覆盆子极乐球是幼儿和大孩子的健康早餐选择。该视频由 Instagram 帐户“mealtime with mummy”发布，并获得了超过 13,000 个赞。视频以一碗新鲜覆盆子和一把叉子开始，然后将其捣碎成果泥。下一帧显示了一个更大的搅拌碗，其中将燕麦、奇亚籽和花生酱添加到覆盆子泥中。然后将混合物一起搅拌直至充分混合。下面的框架显示了一个盘子，上面有椰丝，覆盆子混合物被卷成小球并涂上椰子。最后的帧显示了成品覆盆子极乐球被放入碗中并准备食用。在整个视频中，都有带有说明和提示的文字叠加，使观看者可以轻松地跟随并自己制作食谱。观看视频第二节9.8 GUI 导航 图 117：观看网络视频。我们按照原始视频中的时间顺序呈现 GPT-4V 视频帧的屏幕截图。为了节省空间，我们将帧 1-5 放在第一行中，将帧 6-9 放在第二行中。查看第 9.8 节了解详细讨论。 147 提示：请告诉我视频内容，给出下面的帧。请提供尽可能多的详细信息。 GPT-4V：视频内容是苹果香蕉煎饼的食谱教程。该视频由用户“mealtime with mummy”发布在 Instagram Reels 上，观看次数达 13,200 次。在第一帧中，我们看到一个玻璃碗，里面有香蕉泥和苹果。第二帧显示香蕉和苹果混合在一起。第三帧显示将鸡蛋添加到混合物中。第四帧显示用叉子搅拌混合物。第五帧显示一碗燕麦被添加到混合物中。第六帧显示用勺子混合燕麦。第七帧显示混合物被舀入煎锅中。第八帧显示煎饼正在煎锅中烹饪。最后一帧显示了放在盘子上的成品煎饼，配上切片苹果、香蕉和酸奶。视频上的标题写着“SAVE for easy breakfast inspo”，视频背景为 Bee Gees 的歌曲“Stayin' Alive”。观看视频第二节9.8 GUI 导航 图 118：观看网络视频。我们按照原始视频中的时间顺序呈现 GPT-4V 视频帧的屏幕截图。为了节省空间，我们将帧 1-5 放在第一行中，将帧 6-9 放在第二行中。查看第 9.8 节了解详细讨论。 148 提示：请告诉我视频内容，给出下面的 9 帧。请提供尽可能多的详细信息。 GPT-4V：视频内容是草莓酿法式吐司的食谱教程。该视频由用户“mealtime with mummy”发布在 Instagram Reels 上。该视频有 13.2K 点赞和 190 条评论。在第一帧中，我们看到一个白色的盘子，上面有一块红酱和一块白色奶油。第二帧显示了红酱和白奶油混合在一起的盘子。第三帧显示了一片面包，用刀将混合物涂在上面。第四帧显示了一个盘子，上面有一块圆形面包。第五帧显示一只手用刀将粉红色混合物涂在面包上。第六帧显示了带有粉红色混合物的面包，上面覆盖着另一片面包，制成了三明治。第七帧显示一只手将三明治浸入一碗打好的鸡蛋中。第八帧显示三明治正在平底锅中煎炸。最后一帧显示了放在盘子里的成品草莓法式吐司。该视频以 Bee Gees 乐队的歌曲“Stayin' Alive”为背景。标题写着“节省一下，享受简单的早餐 inspo ”。观看视频第二节9.8 GUI 导航 图 119：观看网络视频。我们按照原始视频中的时间顺序呈现 GPT-4V 视频帧的屏幕截图。为了节省空间，我们将帧 1-5 放在第一行中，将帧 6-9 放在第二行中。红色突出显示有关视频的不准确描述。查看第 9.8 节了解详细讨论。 149 10 LMM 支持的代理 在本节中，我们讨论可能进一步增强 GPT-4V 功能的未来研究方向。讨论重点是 LLM 中有趣的用法如何扩展到多模式场景及其启用的新功能，例如多模式插件、多模式链、自我反思、自我一致性和检索增强的 LMM 等。 -部分，我们使用人类生成的示例来说明增强基于 GPT-4V 的系统的潜在方法。 GPT-4V：抱歉，我无法准确回答这个问题，因为照片没有提供上下文或信息。然而，从破坏情况和紧急救援人员的存在来看，它似乎是在饱受战争蹂躏或受灾的地区拍摄的。秒。 10.1 多模态插件 提示：这张照片是在哪里拍的？提示：这张照片是在哪里拍的？ GPT-4V： - 我没有该信息。 - 启用 Bing 图像搜索插件。注意：与上图所示相同的查询图像，调整大小以节省空间 调用 Bing 图像搜索... - 该图像拍摄于土耳其伊兹密尔 - 该图像与地震事件相关 - 总而言之，该图像拍摄于土耳其伊兹密尔，土耳其爱琴海地区发生里氏6.6级地震。该场景展示了灾难的后果，人们站在一堆瓦砾中，一台起重机吊起一辆卡车，还有一辆前面黑色的红色卡车。图 120：使用 Bing 图像搜索 [94] 插件启用具有时间敏感知识的 GPT-4V 的图示（底部，以绿色突出显示）。请注意，地震发生在 2023 年 2 月 6 日，这是在 GPT-4V 训练之后，因此 GPT-4V 在没有插件的情况下无法识别确切位置（上）。有关详细讨论，请参阅第 10.1 节。 150 个想法 1 秒10.2 多式联运链 提示：请判断图像中的每个人是否佩戴头盔。并总结一下有多少人戴着头盔。这道题需要检测图像中的人。动作 1 助手，检测此图像中显示的人 <ImagePath> 观察 1 人 [4, 126, 72, 175] 人 [63, 121, 88, 181] 人 [30, 107, 56, 88] 人 [223, 123, 43, 78] 人 [178, 122, 52, 180] 人 [322, 118, 41, 68] 人 [268, 109, 55, 178] 人 [357, 127, 88, 173] 想法 2 行动 2观察 2 此图像中检测到 8 个人。助手，裁剪该图像中由边界框 <ImagePath> 指定的区域 Image 1 Image 2 Image 3 Image 4 Image 5 Image 6 Image 7 Image 8 GPT-4V： Image 1：未佩戴头盔 Image 2：未佩戴头盔图 3：佩戴头盔 图 4：佩戴头盔 图 5：佩戴头盔 图 6：佩戴头盔 图 7：佩戴头盔 图 8：未佩戴头盔 摘要：8 人中，5 人佩戴头盔，3 人佩戴头盔没有戴头盔。图 121：使用 ReAct [145, 142] 将 GPT-4V 扩展到多式联运链，以实现 PPE 计数场景。有关详细讨论，请参阅第 10.2 节。 151 10.1 多模式插件 在法学硕士的背景下，插件[98,56,6,112,87,103]在协助法学硕士完成各种任务（例如访问最新信息、执行计算或利用第三方服务）方面发挥着至关重要的作用。这些插件主要设计用于处理自然语言的输入或可以解释为语言的输入，例如代码和数学方程。为了说明多模态插件（例如 Bing 图像搜索 [94]）的重要性，特别是在 LMM 的背景下，我们展示了图 120。通过合并 Bing 图像搜索插件，我们使 GPT-4V 能够获取与输入相关的时间敏感知识图像。在图的上半部分，我们演示了没有 Bing 图像搜索插件的 GPT-4V 的局限性。它无法准确回答“这张照片是在哪里拍摄的？”这个问题，因为这张照片捕捉了 2023 年 2 月 6 日在土耳其和叙利亚边境发生的大地震的后果，这种情况导致了GPT-4V 训练后的位置。由于使用当前信息不断重新训练模型可能需要大量计算且成本高昂，因此搜索引擎等插件被证明是模型访问最新信息的宝贵资源。在图 120 的下半部分，我们展示了配备 Bing 图像搜索插件时 GPT-4V 的功能。它有效地利用从插件检索的信息，从而能够准确识别位置：土耳其伊兹密尔。 10.2 多模式链 与法学硕士的链接在最近的研究中得到了广泛的探索[145,47,124,107]。这种方法超越了使用单个插件，而是建立了一个将 LLM 与插件池集成的系统范例，从而实现更高级的推理和交互。通过用视觉/多模态专家（例如图像字幕器、对象检测器或用于文本到图像生成和音频到文本转换的训练有素的模型）替换仅限语言的插件，可以使用法学硕士构建强大的多模态链[137、142、121、114、75、86]。然而，法学硕士和插件之间的这些链中的交互通常以文本格式进行。尽管插件可以接受多模式输入，但它们会以文本形式返回结果，以增强法学硕士的知识。在图像合成/编辑 [137] 的情况下有一个值得注意的例外，其中插件可以生成图像，但这些图像不会反馈到 LLM 中以进行进一步分析或知识增强，因为 LLM 只能处理基于语言的输入。在图 121 中，我们展示了如何使用 ReAct [145, 142] 扩展 GPT-4V 以支持多模式链。该扩展使链上的插件能够提供多模态信息，然后由 GPT-4V 进行集中处理，以实现 PPE 计数等场景的高级推理。图 121 所示的整个链接过程分为两轮思考、行动和观察，每一轮都涉及特定插件的激活。在第一轮中，GPT-4V 推断需要进行人员检测来统计佩戴头盔的人数（想法 1）。因此，它调用人员检测器工具（操作 1）并接收图像中每个检测到的人员的边界框坐标（观察 1）。进入第二轮，根据获得的边界框信息，GPT-4V 推断图像中共有 8 个人（想法 2）。然后，它利用图像裁剪工具根据每个人相应的边界框坐标裁剪出每个人的单独图像（操作 2）。结果输出（观察 2）由 8 个标记图像组成，从图像 1 到图像 8 进行编号。GPT-4V 随后确定这些图像中的每个人是否佩戴头盔，并总结佩戴头盔的总人数。总体而言，LMM 与多模式插件池的集成为增强推理和交互开辟了新的可能性，充分利用了语言和视觉功能的优势。多模式链的灵活性允许对多模式数据进行更全面的理解和分析，并有可能提高各种应用的性能。 10.3 自反射 图 122 演示了应用自反射 [116,88,63] 来改进图 47 中所示的结果。正如我们所看到的，自反射结果与参考图像更好地对齐。例如，在左侧，数据点的数量从 4 更正为 3，而在右侧，百分比则添加回条形上方。虽然结果仍然不完全相同，但很明显，自反射可以方便手动抛光。图 123 显示了改进文本到图像模型提示生成的另一个自我反思示例 [106]。 152 秒10.3 自我反思提示：生成python代码，绘制相似的曲线。 GPT-4V：提示：您能否仔细检查代码并将其与参考图像更好地对齐？注意：为了节省空间，省略了上述 GPT-4V 响应中的代码 GPT-4V： 提示：编写 python 代码来生成类似的数字。 GPT-4V：提示：您能否仔细检查代码并将其与参考图像更好地对齐？注意：为了节省空间，省略了上述 GPT-4V 响应中的代码 GPT-4V：自反射改进编码 图 122：使用自反射改进图形绘制代码的图示。左：反射后，曲线中的点数与参考图像对齐。右：添加百分比以与参考图像对齐。有关详细讨论，请参阅第 10.3 节。 153 秒10.3 自我反思提示： 说明：给定用户想象的场景 IDEA，将 IDEA 转换为独立的句子提示，用于生成图像。想法：一只狗的照片看起来就像给定图像中在海滩上奔跑的那只狗。根据以上信息，我写了一篇详细的提示，准确地讲述了IDEA遵循的规则。 GPT-4V：一只蓝色的狗在海滩上奔跑，脸上带着快乐的表情。 SDXL：提示：我通过查看 AI 艺术生成模型生成的图像来迭代改进句子提示，并找出与给定 IDEA 的不同之处。这个想法是：一只狗的照片……海滩。本轮生成的句子提示是：一只蓝色的狗在沙滩上奔跑，脸上带着幸福的表情。 AI艺术生成模型生成的对应图像：自我反思以改进文本到图像的生成生成的图像并不完美。写出如何进一步改进图像以更好地遵循用户想象的场景 IDEA 的关键原因。 GPT-4V：生成图像中的狗看起来与给定图像中的狗不同。给定图像中的狗是哈巴狗，而生成图像中的狗是不同的品种。为了解决这个问题，我们可以修改提示，特别提到狗应该是哈巴狗。提示： 说明：给定用户想象的场景 IDEA，将 IDEA 转换为用于生成图像的句子提示。我通过查看 AI 艺术生成模型生成的图像来迭代改进句子提示，并找出与给定 IDEA 的不同之处。这个想法是：一只狗的照片……海滩。本轮生成的句子提示是：蓝色……它的脸。 AI艺术生成模型生成的对应图像： 图像可以改进，因为： 狗……应该是哈巴狗。基于以上信息，为了完善形象，我写了一篇详细的提示，准确的说明了IDEA遵循的规则。 GPT-4V：一只蓝色哈巴狗在海滩上奔跑，脸上带着快乐的表情，背景是日落和棕榈树。 SDXL：提示续 图 123：使用自反射改进文本到图像模型 SDXL [106] 生成的文本提示的图示。 GPT-4V反映了最初提示中没有提及狗的品种的错误，并进行了正确的修改。有关详细讨论，请参阅第 10.3 节。 154秒。 10.4 自洽示例1 提示：数一下图像中船只的数量。 GPT-4V：图像中有6艘船。计数样本 3 的自洽性 提示：计算图像中船只的数量。描述它们各自的位置。 GPT-4V：图像中有 4 艘船。 1）第一艘船在图片左侧，停靠在码头。这是一艘较大的船，顶部有一座塔。 2）第二艘船位于图像中央，也停靠在码头。这是一艘较小的船，顶部有一个白色的天篷。 3）第三艘船在图片右侧，停靠在码头。这是一艘较小的船，顶部有一个白色的天篷，与第二艘船类似。 4) 第四艘船位于背景中，位于图像的最右侧。它被第三艘船部分遮挡，但看起来是一艘更大的船，顶部有一座塔。示例2 提示：计算图像中船只的数量。描述它们各自的位置。 GPT-4V：图中共有4艘船。 1）第一艘船在图片左侧，停靠在码头。这是一艘较大的船，顶部有一座塔。 2）第二艘船位于图像中央，也停靠在码头。这是一艘较小的船，顶部有一个白色的天篷。 3）第三艘船在图片右侧，停靠在码头。这是一艘较小的船，顶部有一个白色的天篷，与第二艘船类似。 4) 第四艘船位于背景中，位于图像的最右侧。那是一艘帆船，看上去正在水面上航行。示例4 提示：数一下图像中船只的数量。描述它们各自的位置。 GPT-4V：图像中有6艘船。 - 1 艘船位于图像左侧，停靠在码头，顶部有一座塔 - 2 艘船位于图像中央，并排停靠在码头 - 1 艘船位于图像右侧，停靠在码头，顶部有盖子 - 图像右侧的背景中有 2 艘船，停靠在不同的码头。自洽性： 样本 2：图像中共有 4 艘船。 1）第一艘船在图像的左侧……示例3：图像中有4艘船。 1）第一艘船在图像的左侧，停靠…… 示例4：图像中有6艘船。 - 1 艘船位于图像左侧，停靠在码头…… [边缘化推理路径以汇总最终答案，例如多数投票] => 图像中有 4 艘船。注意：与示例 1 中所示相同的查询图像，调整大小以节省空间 注意：与示例 1 中所示相同的查询图像，调整大小以节省空间 注意：与示例 1 中所示相同的查询图像，调整大小以节省空间 图 124：改进具有自我一致性的计数可靠性[130]，它聚合了在同一图像上重复的多个计数结果。有关详细讨论，请参阅第 10.4 节。 10.4 自一致性 自一致性[130]是一种解码策略，它聚合多个采样输出以产生最终答案，例如通过多数投票。从边缘化延伸到聚合最终答案，思想树[144]表明，自洽思想可以应用于中间思想，以提高法学硕士的推理性能。图 124 说明了在 GPT-4V 上使用自一致性来解决计数问题。我们通过要求 GPT-4V 对同一图像多次计数 155 来采样多个计数结果，要么进行多次运行（样本 2-4），要么改写输入文本指令（样本 1,2）。然后，该示例使用简单多数投票来汇总“4 艘船”的最终答案。我们将自洽 LMM 的全面探索留给未来的工作。 10.5 检索增强的 LMM 检索增强的 LMM [93,68,50,19,115,104]通过检索相关信息并将其集成到提示中来增强文本生成。当需要专门的任务相关信息时，例如高度专业化的专家领域的专家知识、可能与法学硕士记忆不同的最新信息以及因用户而异的可定制信息，该技术特别有效。我们认为检索增强将继续在 LMM 中发挥重要作用。图 74 显示了帮助杂货结账的检索增强 LMM 的示例。由于每个商店中产品的图像-文本-价格三元组都不同，因此从商店的数据库中检索它们并生成正确的结帐信息将是有益的。类似地，在图 81 的定制字幕场景中，我们想象系统可以自动从相册中检索家庭成员的照片并实现自定义字幕。

11 结论

11.1 摘要和结论 在本报告中，我们的主要重点是在各种应用场景中探索 GPT-4V。研究结果揭示了其卓越的功能，其中一些功能尚未在现有方法中进行研究或证明。虽然我们努力揭示尽可能多的这些功能，但我们承认我们的介绍可能并不详尽。尽管如此，这份报告可以作为未来研究的参考，旨在探索 GPT-4V 的其他用途，加深对 LMM 的理解，并构建更强大的 LMM。 11.2 面向未来的 LMM GPT 模型的弱点和局限性已在相关报告中进行了广泛讨论[99,100,24]。在本节中，我们将简要介绍我们对未来研究方向的看法。 GPT-1、GPT-2 和 GPT-3 等模型主要用作文本输入文本输出系统，仅能够处理自然语言。 GPT-4（无视觉）在文本理解和生成方面表现出无与伦比的能力，而 GPT-4V 也表现出强大的图像领域理解能力。作为一个自然的进展，LMM 应该能够生成交错的图像文本内容，例如生成包含文本和图像的生动教程，以实现全面的多模式内容理解和生成。此外，结合其他模式（例如视频、音频和其他传感器数据）来扩展 LMM 的功能将是有益的。关于学习过程，当前的方法主要依赖于组织良好的数据，例如图像标签或图像文本数据集。然而，更通用的模型可能能够从各种来源学习，包括在线网络内容甚至现实世界的物理环境，以促进持续的自我进化。致谢我们对 OpenAI 的所有贡献者在 GPT-4V 项目 [99-101, 1] 上所做的技术努力表示感谢，并且非常感谢 OpenAI 允许我们尽早使用他们出色的工具。我们衷心感谢 Misha Bilenko 的宝贵指导和支持。我们还衷心感谢 Microsoft 同事的见解，特别感谢 John Montgomery、Marco Casalaina、Gregory Buehrer、Nguyen Bach、Gopi Kumar、Luis Vargas、Kun Wu、Meenaz Merchant、Jianfeng Gang、Matt Lungren、Sheela Agarwal、 Yumao Lu、Thomas Soemo、Fisayo Okikiolu、Ce Liu、Michael Zeng、Faisal Ahmed、Ehsan Azarnasab 和 Lin Liang 提供的建设性反馈。我们还感谢 Yingkai Yu 帮助创建 GUI 导航屏幕截图。