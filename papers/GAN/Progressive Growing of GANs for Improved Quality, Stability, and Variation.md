---
Url: https://arxiv.org/pdf/1710.10196.pdf
Publish: ICLR2018
Year: "2017"
创新点: 由低分辨率到高分辨率逐步训练，生成1024分辨率图像
---
## 摘要

我们描述了一种新的生成对抗网络训练方法。其关键思想是逐步增加生成器和鉴别器的层次：从低分辨率开始，随着训练的进行，我们添加新的层次来模拟越来越精细的细节。这既加快了训练速度，也极大地稳定了训练过程，使我们能够生成质量前所未有的图像，例如 10242 分辨率的 CELEBA 图像。我们还提出了一种简单的方法来增加生成图像的变化，并在无监督的 CIFAR10 数据集上实现了 8.80 的记录 Inception 分数。此外，我们描述了几个对阻止生成器和鉴别器之间的不健康竞争至关重要的实现细节。最后，我们提出了一个评估 GAN 结果的新指标，包括图像质量和变化程度。作为额外的贡献，我们构建了一个更高质量的 CELEBA 数据集版本。

## 1 引言

生成方法用于从高维数据分布中产生新样本，例如图像，在许多领域得到了广泛应用，例如语音合成（van den Oord等，2016a）、图像到图像的翻译（Zhu等，2017；Liu等，2017；Wang等，2017）以及图像修复（Iizuka等，2017）。目前最突出的方法包括自回归模型（van den Oord等，2016b；c）、变分自编码器（VAE）（Kingma＆Welling，2014）和生成对抗网络（GAN）（Goodfellow等，2014）。目前它们都具有显著的优势和劣势。

自回归模型（如PixelCNN）生成清晰的图像，但评估速度较慢，并且由于直接对像素的条件分布进行建模而没有潜在表示，其适用性可能受到限制。

VAE易于训练，但由于模型限制而倾向于产生模糊的结果，尽管最近的工作正在改进这一点（Kingma等，2016）。

GAN生成清晰的图像，尽管仅在相当小的分辨率下，并且具有相对有限的变化，尽管最近取得了进展，但训练仍然不稳定（Salimans等，2016；Gulrajani等，2017；Berthelot等，2017；Kodali等，2017）。

混合方法结合了三种方法的各种优点，但在图像质量方面远远落后于GAN（Makhzani＆Frey，2017；Ulyanov等，2017；Dumoulin等，2016）。

通常，GAN由两个网络组成：生成器和鉴别器（也称为评论者）。生成器从 latent code 生成样本，例如图像，这些图像的分布理想情况下应与训练分布不可区分。由于一般不可能设计一个能够判断是否达到这种情况的函数，因此训练一个鉴别器网络来进行评估，而且由于网络是可微分的，我们还会得到一个梯度，可以用来引导两个网络朝着正确的方向。通常，生成器是主要关注的对象——一旦生成器训练完成，鉴别器就是一个自适应损失函数，会被丢弃。

这种表述存在多个潜在问题。当我们测量训练分布和生成分布之间的距离时，如果这些分布没有重叠的部分，即很容易区分它们，那么梯度可能会指向更多或更少随机的方向（Arjovsky＆Bottou，2017）。最初，Jensen-Shannon 散度被用作距离度量（Goodfellow等，2014），最近该表述已得到改进（Hjelm等，2017），并提出了许多更稳定的替代方法，包括最小二乘（Mao等，2016）、带边界的绝对偏差（Zhao等，2017）和 Wasserstein 距离（Arjovsky等，2017；Gulrajani等，2017）。我们的贡献在很大程度上与这一持续讨论无关，我们主要使用改进后的 Wasserstein 损失，但也尝试了最小二乘损失。

生成高分辨率图像很困难，因为更高的分辨率使得生成的图像与训练图像更容易区分开来（Odena等，2017），从而严重放大了梯度问题。较大的分辨率还需要使用较小的小批量，因为受内存约束，进一步损害了训练的稳定性。我们的关键洞察力是我们可以逐步增加生成器和鉴别器，从容易的低分辨率图像开始，并随着训练的进行添加新层，引入更高分辨率的细节。这大大加快了训练速度，并提高了高分辨率下的稳定性，我们将在第 2 节中讨论。

GAN的表述并不明确要求生成模型来表示整个训练数据分布。传统观点认为图像质量和变化之间存在权衡，但这一观点最近受到了挑战（Odena等，2017）。目前，保留的变化程度正在受到关注，已经提出了各种方法来衡量它，包括 Inception 分数（Salimans等，2016）、多尺度结构相似性（MS-SSIM）（Odena等，2017；Wang等，2003）、生日悖论（Arora＆Zhang，2017）以及显式测试发现的离散模式数量（Metz等，2016）。我们将在第 3 节中描述我们鼓励变化的方法，并在第 5 节中提出一个评估质量和变化的新指标。

第 4.1 节讨论了网络初始化的微妙修改，导致不同层的学习速度更加平衡。此外，我们观察到传统上困扰GAN的模式崩溃往往会非常快地发生，在几十个小批次的过程中。通常，当鉴别器超调时，模式崩溃开始，导致梯度夸张，然后出现了不健康的竞争，两个网络中的信号幅度升级。我们提出了一个机制来阻止生成器参与这种升级，从而克服了这个问题（第 4.2 节）。

我们使用 CELEBA、LSUN、CIFAR10 数据集评估我们的贡献。我们改进了 CIFAR10 的最佳发表 Inception 分数。由于通常用于基准测试生成方法的数据集分辨率较低，我们还创建了一个更高质量的 CELEBA 数据集版本，允许在分辨率高达 1024 × 1024 像素的情况下进行实验。该数据集和我们的完整实现可在 https://github.com/tkarras/progressive_growing_of_gans 找到，训练过的网络可以在 https://drive.google.com/open?id=0B4qLcYyJmiz0NHFULTdYc05lX0U 找到，其中包括结果图像，另外还有一个补充视频，展示了数据集、额外结果和潜在空间插值，链接为 https://youtu.be/G06dEcZ-QTg。

## 2 逐步增长的 GAN

我们的主要贡献是一种 GAN 的训练方法，我们从低分辨率图像开始，然后通过向网络添加层次逐步增加分辨率，如图 1 所示。这种增量式方法使得训练首先可以发现图像分布的大尺度结构，然后逐渐将注意力转移到越来越细微的尺度细节上，而不是必须同时学习所有尺度。

我们使用生成器和鉴别器网络，它们彼此是镜像的，并且始终同步增长。在整个训练过程中，两个网络中的所有现有层都保持可训练状态。当向网络添加新层时，我们平滑地将它们淡入，如图 2 所示。这避免了对已经训练良好的较小分辨率层造成突然的冲击。附录 A 详细描述了生成器和鉴别器的结构，以及其他训练参数。

我们观察到逐步训练有几个好处。早期，生成较小图像的过程更加稳定，因为其中的类信息较少，模式也较少（Odena等，2017）。通过逐步增加分辨率，我们不断地提出了一个与从潜在向量到例如 10242 图像的最终目标相比要简单得多的问题。这种方法在概念上类似于陈&科尔顿（2017）的最近工作。在实践中，它足够稳定训练，使我们能够可靠地使用 WGAN-GP 损失（Gulrajani等，2017）甚至 LSGAN 损失（Mao等，2016b）合成百万像素级别的图像。

另一个好处是减少了训练时间。通过逐步增长的 GAN，大部分迭代过程都在较低分辨率下进行，通常可以在更短的时间内获得可比较的结果质量，取决于最终的输出分辨率。

逐步增长 GAN 的想法与王等（2017）的工作相关，他们使用在不同空间分辨率上操作的多个鉴别器。该工作受到 Durugkar 等（2016）的启发，后者同时使用一个生成器和多个鉴别器，以及 Ghosh 等（2017），他们采用多个生成器和一个鉴别器相反的方法。分层 GAN（Denton等，2015；Huang等，2016；Zhang等，2017）为图像金字塔的每个级别定义了一个生成器和鉴别器。这些方法建立在我们工作的相同观察基础之上——即从潜在到高分辨率图像的复杂映射可以分步学习——但关键的区别是我们只有一个 GAN，而不是一系列 GAN。与早期关于自适应增长网络的工作相反，例如，自适应增长神经气（Fritzke，1995）和增强拓扑的神经进化（Stanley＆Miikkulainen，2002）会贪婪地增长网络，我们只是推迟了预配置层的引入。从这个意义上讲，我们的方法类似于自动编码器的逐层训练（Bengio等，2007）。

## 3 使用小批量标准差增加变化的翻译

GANs往往只能捕捉到训练数据中的一个子集的变化，Salimans等人（2016）提出“小批量判别”作为解决方案。他们不仅从单个图像中计算特征统计信息，还从小批量中计算特征统计信息，从而鼓励生成图像和训练图像的小批量显示类似的统计信息。这是通过在鉴别器的末尾添加一个小批量层来实现的，该层学习将输入激活投影到一系列统计信息的大张量。每个小批量中的每个示例都会产生一组单独的统计信息，并将其连接到该层的输出，以便鉴别器可以在内部使用这些统计信息。我们大大简化了这一方法，同时也提高了变化。

我们的简化解决方案既没有可学习的参数，也没有新的超参数。我们首先计算整个小批量中每个特征在每个空间位置上的标准差。然后，我们将这些估计值在所有特征和空间位置上进行平均，得到一个单一的值。我们复制这个值，并将其连接到所有的空间位置和整个小批量，产生一个额外的（常数）特征映射。这一层可以插入到鉴别器的任何地方，但我们发现最好将其插入到最后（详见附录A.1）。我们尝试了更丰富的统计信息集，但未能进一步提高变化。在并行工作中，Lin等人（2017）提供了关于向鉴别器展示多个图像的好处的理论见解。

增加变化的替代方法包括将鉴别器展开（Metz等人，2016）以规范其更新，以及“排斥正则化器”（Zhao等人，2017）将新的损失项添加到生成器中，试图鼓励其使小批量中的特征向量正交化。Ghosh等人（2017）的多个生成器也达到了类似的目标。我们承认这些解决方案可能会比我们的解决方案进一步增加变化，甚至可能与之正交，但将详细比较留待日后。

## 4 标准化在生成器和鉴别器中

GANs容易因为两个网络之间的不健康竞争而导致信号幅度的逐渐增加。大多数，如果不是全部，较早的解决方案通过在生成器中使用批量归一化的变体（Ioffe＆Szegedy，2015；Salimans＆Kingma，2016；Ba等，2016），而且通常也在鉴别器中使用，来抑制这一现象。这些标准化方法最初是为了消除协变量转移而引入的。然而，我们并没有观察到这在GANs中是一个问题，因此我们认为GANs实际上需要的是限制信号幅度和竞争。我们采用了一种不同的方法，由两个成分组成，都不包括可学习参数。

### 4.1 统一的学习率

我们偏离了当前精心权重初始化的趋势，而是使用了一个平凡的N（0，1）初始化，然后在运行时明确地缩放权重。准确地说，我们设置ŵ_i= w_i/c，其中w_i是权重，c是来自He初始化器（He等，2015）的每层标准化常数。这样做的好处在某种程度上是微妙的，与常用的自适应随机梯度下降方法（如RMSProp（Tieleman＆Hinton，2012）和Adam（Kingma＆Ba，2015））中的标准差估计相关。这些方法通过其估计的标准差对梯度更新进行归一化，从而使更新与参数的尺度无关。因此，如果一些参数的动态范围大于其他参数，它们将需要更长的时间来调整。这正是现代初始化器引起的情况，因此可能会出现学习速率同时太大和太小的情况。我们的方法确保了所有权重的动态范围以及学习速度都相同。Van Laarhoven（2017）也独立使用了类似的推理。

### 4.2 生成器中的逐像素特征向量归一化

为了防止生成器和鉴别器中的幅度在竞争中失控的情况，我们在每个卷积层后将每个像素中的特征向量归一化为单位长度。我们使用的是“局部响应归一化”的变体（Krizhevsky等人，2012），配置为bx,y=ax,y/√(1/N ∑_(j=0)^(N-1) (a_jx,y)^2 + )，其中 = 10^(-8)，N是特征映射的数量，ax,y和bx,y分别是像素(x，y)中的原始和归一化特征向量。令人惊讶的是，这种严格的约束似乎并没有以任何方式损害生成器，在大多数数据集中，它并没有对结果产生太大影响，但在需要时有效地防止了信号幅度的逐步增加。

## 5 多尺度统计相似性用于评估GAN结果

为了比较一个GAN的结果与另一个的结果，需要调查大量的图像，这可能是繁琐、困难和主观的。因此，依赖于自动化方法，从大量图像集合中计算出一些指示性指标是可取的。我们注意到，现有的方法（如MS-SSIM（Odena等人，2017））可靠地发现大规模模式崩溃，但无法对颜色或纹理变化的丢失等较小效果做出反应，并且它们也不直接评估图像质量，即与训练集的相似性。

我们建立在这样一种直觉上，即成功的生成器会产生样本，其局部图像结构在所有尺度上都与训练集相似。我们建议通过考虑从拉普拉斯金字塔（Burt＆Adelson，1987）表示的生成和目标图像中提取的局部图像块的分布之间的多尺度统计相似性来研究这一点，从16×16像素的低通分辨率开始。按照标准做法，金字塔逐渐加倍，直到达到完整分辨率，每个后续级别都编码到前一级别的上采样版本的差异。

单个拉普拉斯金字塔级别对应于特定的空间频率带。我们随机抽样16384张图像，并从拉普拉斯金字塔的每个级别中提取128个描述符，给出每个级别的2^21（2.1M）描述符。每个描述符都是一个具有3个颜色通道的7×7像素邻域，用x ∈ R^(7×7×3)表示。我们将训练集和生成集的级别l的图像块分别表示为{x^l_i}_(i=1)^(2^21)和{y^l_i}_(i=1)^(2^21)。我们首先相对于每个颜色通道的均值和标准差对{x^l_i}和{y^l_i}进行归一化，然后通过计算它们的切片Wasserstein距离SWD({x^l_i}, {y^l_i})来估计它们的统计相似性，这是一种有效计算的对地距离的随机近似，使用512个投影（Rabin等人，2011）。

直观地，较小的Wasserstein距离表明图像块的分布相似，这意味着训练图像和生成器样本在外观和变化上在这个空间分辨率上看起来相似。特别是，从最低分辨率16×16图像提取的图像块集之间的距离表明大尺度图像结构的相似性，而最细级别的图像块则编码了关于像素级属性（如边缘的清晰度和噪声）的信息。

## 6 实验

在本节中，我们讨论了一系列实验，用以评估我们结果的质量。请参阅附录 A，了解我们网络结构和训练配置的详细描述。我们还邀请读者查阅附带视频 (https://youtu.be/G06dEcZ-QTg)，以获取额外的结果图像和潜在空间插值。在本节中，我们将区分网络结构（例如，卷积层，调整大小）、训练配置（各种归一化层，小批量相关操作）和训练损失（WGAN-GP，LSGAN）。

### 6.1 按统计相似性评估个别贡献的重要性

我们首先使用切片 Wasserstein 距离（SWD）和多尺度结构相似性（MSSSIM）（Odena 等人，2017）来评估个别贡献的重要性，并且在感知上验证这些指标本身。我们将在先前的最先进损失函数（WGAN-GP）和训练配置（Gulrajani 等人，2017）的基础上构建，在 CELEBA（Liu 等人，2015）和 LSUN BEDROOM（Yu 等人，2015）数据集上进行无监督设置的训练，分辨率为 128x128。CELEBA 尤其适用于这种比较，因为训练图像包含明显的伪影（混叠、压缩、模糊），这对生成器来说很难忠实地再现。在这个测试中，我们通过选择一个相对低容量的网络结构（附录 A.2）并在判别器展示了总共 1000 万张真实图像后终止训练，放大了训练配置之间的差异。因此，结果并未完全收敛。表 1 列出了几种训练配置的 SWD 和 MSSSIM 的数值，我们逐步在基线（Gulrajani 等人，2017）的基础上启用我们的个别贡献。MSSSIM 数值是从 10000 对生成图像中平均得出的，SWD 的计算方法如第 5 节所述。这些配置生成的 CELEBA 图像显示在图 3 中。由于空间限制，该图仅显示了表中每行的少量示例，但在附录 H 中提供了一组更广泛的示例。直观上，一个好的评估指标应该奖励展现出丰富的颜色、纹理和视角变化的合理图像。然而，这并没有被 MSSSIM 捕获：我们可以立即看到配置（h）生成的图像明显比配置（a）更好，但 MSSSIM 保持几乎不变，因为它仅度量输出之间的变化，而不是与训练集的相似性。另一方面，SWD 明显显示出改进。

第一个训练配置（a）对应于 Gulrajani 等人（2017），其中生成器使用批归一化，判别器使用层归一化，小批量大小为 64。 (b) 启用网络的渐进增长，结果是输出图像更清晰、更可信。SWD 正确地发现生成图像的分布更类似于训练集。

我们的主要目标是实现高分辨率的输出，这需要减小小批量的大小以保持在可用内存预算内。我们在 (c) 中说明了随之而来的挑战，我们将小批量大小从 64 减小到 16。生成的图像是不自然的，这在两个指标中都清晰可见。在 (d) 中，我们通过调整超参数以及去除批归一化和层归一化（附录 A.2）来稳定训练过程。作为一个中间测试（e∗），我们启用小批量区分（Salimans 等人，2016），令人惊讶的是，它未能改善任何指标，包括度量输出变化的 MSSSIM。相反，我们的小批量标准差（e）提高了平均 SWD 分数和图像质量。

## A 网络结构和训练配置

### A.1 用于 CELEBA-HQ 的 1024 × 1024 网络

表 2 显示了我们在 CELEBA-HQ 数据集中使用的全分辨率生成器和判别器的网络架构。这两个网络主要由我们在训练过程中逐步引入的复制的 3 层块组成。生成器的最后一个 Conv 1 × 1 层对应于图 2 中的 toRGB 块，而判别器的第一个 Conv 1 × 1 层类似地对应于 fromRGB。我们从 4 × 4 分辨率开始训练网络，直到总共向判别器展示了 800k 个真实图像。然后我们在两个阶段之间交替：在接下来的 800k 图像中淡入第一个 3 层块，稳定网络 800k 图像，然后在接下来的 800k 图像中淡入下一个 3 层块，依此类推。我们的潜在向量对应于 512 维超球面上的随机点，我们将训练和生成的图像表示为 [-1,1]。在这两个网络的所有层中，我们使用泄漏系数为 0.2 的泄漏 ReLU，除了最后一层使用线性激活。我们不在任何网络中使用批归一化、层归一化或权重归一化，但我们在生成器的每个 Conv 3×3 层后执行特征向量的像素级归一化，如第 4.2 节所述。我们将所有偏置参数初始化为零，所有权重根据单位方差的正态分布进行初始化。然而，在运行时，我们根据第 4.1 节的描述，使用特定于层的常数缩放权重。我们向判别器的末端注入跨小批量标准差作为额外的特征图，分辨率为 4 × 4，如第 3 节所述。表 2 中的上采样和下采样操作分别对应于 2 × 2 元素复制和平均池化。我们使用 Adam（Kingma & Ba，2015）进行网络训练，其中 α = 0.001，β1 = 0，β2 = 0.99，和  = 10−8。我们不使用任何学习率衰减或降低，但是为了在训练的任何给定时刻可视化生成器输出，我们使用指数加权移动平均来衰减生成器权重，衰减率为 0.999。对于分辨率为 4 2–1282，我们使用小批量大小 16 进行训练，然后逐渐减小大小，按照 2562 → 14，5122 → 6，和 10242 → 3，以避免超出可用内存预算。我们使用 WGAN-GP 损失，但与 Gulrajani 等人（2017）不同，我们在每个小批量基础上交替优化生成器和判别器，即我们设置 ncritic = 1。此外，我们向判别器损失引入第四个项，具有极小的权重，以防止判别器输出偏离零太远。确切地说，我们设置 L 0 = L + driftEx∈Pr [D(x) 2 ]，其中 drift = 0.001。

### A.2 其他网络

每当我们需要操作低于 1024 × 1024 的空间分辨率时，我们在两个网络中适当地省略复制的 3 层块的数量。此外，第 6.1 节使用稍低容量的版本，其中我们在 16 × 16 分辨率的 Conv 3 × 3 层中减半特征图的数量，并在后续分辨率中除以 4。这使得最后一个 Conv 3 × 3 层留下 32 个特征图。在表 1 和图 4 中，我们将每个分辨率的训练总数减少为 600k 张图像，而不是 800k，并且还在持续 600k 张图像的时间内淡入新层。对于表 1 中的“Gulrajani et al.（2017）”情况，我们尽可能地遵循他们的训练配置。特别地，我们设置 α = 0.0001，β2 = 0.9，ncritic = 5，drift = 0，以及小批量大小 64。我们禁用了渐进式分辨率、小批量标准差以及运行时的权重缩放，并使用 He 的初始化器（He et al.，2015）初始化所有权重。此外，在生成器中，我们将 LReLU 替换为 ReLU，在最后一层使用 tanh 线性激活，并将像素级归一化替换为批归一化。在判别器中，我们对所有 Conv 3 × 3 和 Conv 4 × 4 层添加了层归一化。对于潜在向量，我们使用独立从正态分布中采样的 128 个分量。




