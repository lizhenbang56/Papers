---
Publish: ICLR2016
Url: https://arxiv.org/pdf/1511.06434.pdf
Year: "2015"
Month: "11"
---
## 摘要

近年来，使用卷积神经网络（CNNs）进行监督学习在计算机视觉应用中得到了广泛应用。相比之下，使用CNN进行无监督学习的研究相对较少。在这项工作中，我们希望填补CNN在监督学习和无监督学习成功之间的差距。我们引入了一类称为深度卷积生成对抗网络（DCGANs）的CNN，具有一定的架构约束，并证明它们是无监督学习的一个强有力的选择。通过在各种图像数据集上进行训练，我们展示了令人信服的证据，表明我们的深度卷积对抗网络在生成器和鉴别器中学习到了从物体部件到场景的一系列表示。此外，我们利用学习到的特征进行了新颖任务的展示，证明了它们作为通用图像表示的适用性。

## 1. 引言

从大规模未标记数据集中学习可重用特征表示已经成为了一个活跃研究领域。在计算机视觉领域，人们可以利用几乎无限数量的未标记图像和视频来学习良好的中间表示，然后将其应用于各种监督学习任务，如图像分类。我们提出，构建良好的图像表示的一种方法是通过训练生成对抗网络（GANs）（Goodfellow等人，2014），然后重用生成器和鉴别器网络的部分作为监督任务的特征提取器。GANs为最大似然技术提供了一种有吸引力的替代方案。人们还可以认为它们的学习过程和缺乏启发式成本函数（如像素独立均方误差）对表示学习是有吸引力的。已经知道GANs在训练过程中不稳定，经常导致生成器产生荒谬的输出。对于理解和可视化GANs学习的内容以及多层GANs的中间表示，已经发表的研究非常有限。

在本文中，我们做出以下贡献：

- 我们提出并评估了一组对卷积GANs架构拓扑的约束条件，使它们在大多数情况下稳定训练。我们将这类架构命名为深度卷积GANs（DCGAN）。
- 我们使用训练好的鉴别器进行图像分类任务，展示了与其他无监督算法相竞争的性能。
- 我们可视化了GANs学习到的滤波器，并经验性地展示了特定滤波器已经学会绘制特定对象。
- 我们展示生成器具有有趣的向量算术属性，允许轻松操纵生成样本的许多语义特质。

## 2. 相关工作

### 2.1 从未标记数据学习表示

未监督表示学习是一个广泛研究的问题，在一般的计算机视觉研究中以及在图像的背景下都有所涉及。未监督表示学习的经典方法之一是对数据进行聚类（例如使用K-means），并利用这些聚类来提高分类得分。在图像的背景下，人们可以对图像块进行分层聚类，以学习强大的图像表示。另一种流行的方法是训练自动编码器（卷积的、堆叠的（Vincent等人，2010）、分离了代码的什么和哪里组件（Zhao等人，2015）、阶梯结构（Rasmus等人，2015）），将图像编码为紧凑的代码，然后尽可能准确地解码代码以重建图像。这些方法还被证明可以从图像像素中学习到良好的特征表示。深度信念网络（Lee等人，2009）也被证明在学习分层表示方面表现良好。

### 2.2 生成自然图像

生成图像模型已经得到了广泛的研究，分为两类：参数化和非参数化。非参数化模型通常是对现有图像数据库进行匹配，通常匹配图像的块，并已用于纹理合成（Efros等人，1999）、超分辨率（Freeman等人，2002）和修复（Hays＆Efros，2007）。用于生成图像的参数化模型已经被广泛探讨（例如在MNIST数字上或用于纹理合成（Portilla＆Simoncelli，2000））。然而，生成现实世界自然图像直到最近才取得了一些进展。用于生成图像的变分采样方法（Kingma＆Welling，2013）取得了一些成功，但样本通常模糊不清。另一种方法是使用迭代的前向扩散过程生成图像（Sohl-Dickstein等人，2015）。生成对抗网络（Goodfellow等人，2014）生成的图像有噪声且难以理解。这种方法的拉普拉斯金字塔扩展（Denton等人，2015）显示出更高质量的图像，但由于在链接多个模型时引入的噪声，对象看起来仍然不稳定。最近，递归网络方法（Gregor等人，2015）和反卷积网络方法（Dosovitskiy等人，2014）也取得了一些生成自然图像的成功。然而，它们并没有利用生成器进行监督任务。

### 2.3 可视化CNN的内部

使用神经网络的一个常见批评是它们是黑盒方法，几乎不了解网络以一种简单的人类可消化的算法形式做什么。在CNN的背景下，Zeiler等人（Zeiler＆Fergus，2014）表明，通过使用反卷积和过滤最大激活，可以找到网络中每个卷积滤波器的近似目的。类似地，使用输入上的梯度下降让我们检查激活某些滤波器子集的理想图像（Mordvintsev等人）。

## 3 方法和模型架构

尝试使用CNN来扩展GANs以建模图像的历史尝试都没有成功。这促使LAPGAN的作者（Denton等人，2015）开发了一种替代方法，即迭代地增加低分辨率生成的图像，这样可以更可靠地建模。我们也遇到了尝试使用在监督文献中常用的CNN架构扩展GANs的困难。然而，在进行了大量模型探索之后，我们确定了一系列架构，使其在各种数据集上稳定训练，并允许训练更高分辨率和更深层次的生成模型。我们方法的核心是采用和修改三个最近证明的对CNN架构的改变。

第一个是全卷积网络（Springenberg等人，2014），它用步进卷积替换了确定性空间池化函数（如最大池化），使网络能够学习自己的空间下采样。我们在生成器和鉴别器中使用这种方法，允许其学习自己的空间上采样。

第二个是消除完全连接层的趋势，这是全球平均池化的最强示例，已经在最先进的图像分类模型中使用（Mordvintsev等人）。我们发现全局平均池化提高了模型的稳定性，但降低了收敛速度。直接将最高卷积特征与生成器和鉴别器的输入和输出连接起来的中间地带工作得很好。GAN的第一层，将均匀噪声分布Z作为输入，可以称为完全连接，因为它只是一个矩阵乘法，但结果被重塑为一个4维张量，并用作卷积堆栈的起始点。对于鉴别器，最后一个卷积层被展平，然后馈入一个单一的sigmoid输出。

第三个是批量归一化（Ioffe＆Szegedy，2015），它通过将每个单元的输入归一化为零均值和单位方差来稳定学习。这有助于解决由于较差的初始化而导致的训练问题，并帮助更深层次模型的梯度流动。这对于使深度生成器开始学习至关重要，防止生成器将所有样本坍缩到单个点，这是GANs中常见的失败模式。然而，将批量归一化直接应用于所有层会导致样本振荡和模型不稳定。这可以通过不将批量归一化应用于生成器输出层和鉴别器输入层来避免。

ReLU激活（Nair＆Hinton，2010）在生成器中使用，除了输出层使用Tanh函数。我们观察到使用有界激活可以使模型更快地学习饱和和覆盖训练分布的颜色空间。在鉴别器中，我们发现LeakyReLU激活（Maas等人，2013）（Xu等人，2015）很有效，特别是对于更高分辨率的建模。这与原始GAN论文中使用的maxout激活（Goodfellow等人，2013）相反。

稳定深度卷积GAN的架构指南：

- 用步进卷积（鉴别器）和分数步进卷积（生成器）替换任何池化层。
- 在生成器和鉴别器中使用批量归一化。
- 对于更深层次的架构，删除全连接的隐藏层。
- 对于所有层，在生成器中使用ReLU激活，除了输出层使用Tanh。
- 对于所有层，在鉴别器中使用LeakyReLU激活。

## 4 对抗训练的细节

我们在三个数据集上训练了DCGANs，分别是大规模场景理解（LSUN）（Yu等人，2015）、Imagenet-1k和一个新收集的人脸数据集。下面介绍了对这些数据集的使用细节。在训练图像之前，除了将其缩放到tanh激活函数范围[-1,1]之外，没有应用任何预处理。所有模型都使用小批量随机梯度下降（SGD）进行训练，小批量大小为128。所有权重都从标准差为0.02的零中心正态分布初始化。在LeakyReLU中，所有模型中的泄漏斜率都设置为0.2。尽管先前的GAN工作使用动量来加速训练，但我们使用了Adam优化器（Kingma＆Ba，2014）并调整了超参数。我们发现建议的学习率0.001太高，改为使用0.0002。此外，我们发现将动量项β1保持在建议值0.9会导致训练振荡和不稳定，将其减少到0.5有助于稳定训练。

### 4.1 LSUN

随着生成图像模型样本质量的提高，对过度拟合和记忆训练样本的担忧也在增加。为了展示我们的模型如何随着更多数据和更高分辨率的生成而扩展，我们在包含略多于300万个训练样本的LSUN卧室数据集上训练了一个模型。最近的分析表明，模型学习的速度与其泛化性能之间存在直接联系。我们展示了一次训练的样本（图2），模仿在线学习，以及收敛后的样本（图3），作为展示我们的模型不是通过简单地过度拟合/记忆训练样本来生成高质量样本的机会。图像没有应用任何数据增强。

#### 4.1.1 去重

为了进一步减少生成器记忆输入示例（图2）的可能性，我们执行了一个简单的图像去重过程。我们对训练示例的32x32下采样中心裁剪拟合了一个3072-128-3072去噪dropout正则化的RELU自动编码器。然后，通过对ReLU激活进行阈值化对结果代码层激活进行二值化，这已被证明是一种有效的信息保持技术，并提供了一种方便的语义哈希形式，允许线性时间去重。哈希冲突的视觉检查显示了高精度，估计的假阳率小于100中的1个。此外，该技术检测并删除了大约275,000个近似重复项，表明高召回率。

### 4.2 人脸

我们从随机网络图像查询的图像中收集了包含人脸的图像。人名是从dbpedia获取的，标准是他们出生于现代时代。这个数据集有来自1万个人的3M张图片。我们在这些图像上运行了OpenCV人脸检测器，保留了足够高分辨率的检测结果，这给了我们大约350,000个人脸框。我们使用这些人脸框进行训练。图像没有应用任何数据增强。

### 4.3 Imagenet-1k

我们使用Imagenet-1k（Deng等人，2009）作为无监督训练的自然图像来源。我们对32×32的最小调整大小中心裁剪进行训练。图像没有应用任何数据增强。