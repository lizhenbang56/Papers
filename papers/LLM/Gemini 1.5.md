---
Url: https://arxiv.org/pdf/2403.05530
---
## Gemini 1.5: 解锁数百万个上下文标记的多模态理解

**Gemini 团队，Google**

本报告介绍了 Gemini 系列的最新模型 Gemini 1.5 Pro，这是一个高效能的多模态混合专家模型，能够从数百万个上下文标记中检索和推理细粒度信息，包括多个长文档、数小时的视频和音频。Gemini 1.5 Pro 在跨模态的长上下文检索任务中实现了近乎完美的召回率，改进了长文档问答、长视频问答和长上下文语音识别的最新技术水平，并在广泛的基准测试中达到或超过了 Gemini 1.0 Ultra 的最新性能。通过研究 Gemini 1.5 Pro 长上下文能力的极限，我们发现其在下一个标记预测和近乎完美的检索（>99%）方面持续改进，至少达到了 1000 万个标记，比现有模型（如 Claude 2.1（20 万）和 GPT-4 Turbo（12.8 万））取得了代际飞跃。最后，我们重点介绍了大型语言模型在最前沿的令人惊讶的新功能；当给定 Kalamang 语法手册时，该模型可以将英语翻译成 Kalamang，其水平与从相同内容中学习的人类似，而 Kalamang 是一种全球只有不到 200 人使用的语言。

**1. 引言**

我们推出了 Gemini 系列的最新多模态模型：Gemini 1.5 Pro。这是我们 Gemini 1.5 的第一个版本，这是一个全新的高性能多模态模型系列，它采用了新颖的混合专家架构，并在训练和服务基础设施方面取得了重大进展，使其能够突破效率、推理和长上下文性能的界限。Gemini 1.5 Pro 专为处理极长的上下文而构建；它能够从多达至少 1000 万个标记中检索和推理细粒度信息。这种规模在当代大型语言模型 (LLM) 中是前所未有的，它能够处理长形式的混合模态输入，包括整个文档集合、多个小时的视频和将近五天的音频。Gemini 1.5 Pro 超过了 Gemini 1.0 Pro，并在各种基准测试中表现出与 1.0 Ultra 相似的水平，同时训练所需的计算量显着减少。

建模越来越长上下文数据的能力追踪了更通用、功能更强大的语言模型的发展轨迹，从 Shannon (1948) 提出的现在看来很简单的 2-gram 语言模型，到 20 世纪 90 年代和 21 世纪初的现代 n-gram 模型（通常限制在 5 个上下文标记）(Brants et al., 2007; Chen and Goodman, 1999; Jelinek, 1998; Kneser and Ney, 1995)，再到 2010 年代的循环神经网络语言模型（可以有效地处理数百个标记）(Jozefowicz et al., 2016; Mikolov et al., 2010)，以及现代 Transformer (Vaswani et al., 2017)（可以处理数十万个标记）(Anthropic, 2023a)。Gemini 1.5 Pro 延续了这一趋势，将语言模型上下文长度扩展了一个数量级以上。通过扩展到数百万个标记，我们发现预测性能持续改进（第 4.2.1.1 节），在合成检索任务中实现了近乎完美的召回率（>99%）（图 1 和第 4.2.1.2 节），并具有许多令人惊讶的新功能，例如从整个长文档中进行上下文学习（第 4.2.2 节）。

**2. 模型架构**

Gemini 1.5 Pro 是一个基于稀疏混合专家 (MoE) Transformer 的模型，它基于 Gemini 1.0 (Gemini-Team et al., 2023) 的研究进展和多模态功能。Gemini 1.5 Pro 还建立在 Google 更长时间的 MoE 研究历史之上 (Clark et al., 2022; Du et al., 2022; Fedus et al., 2021; Lepikhin et al., 2020; Riquelme et al., 2021; Shazeer et al., 2017; Zoph et al., 2022) 和更广泛的文献中的语言模型研究 (Anil et al., 2023; Anthropic, 2023a; Brown et al., 2020; Chowdhery et al., 2023; Homann et al., 2022; Jiang et al., 2024; Kim et al., 2021; OpenAI, 2023; Rae et al., 2021; Rael et al., 2020; Roller et al., 2021; Thoppilan et al., 2022; Touvron et al., 2023a,b; Vaswani et al., 2017)。MoE 模型使用学习的路由函数将输入定向到模型参数的一个子集进行处理。这种形式的条件计算 (Bengio et al., 2013; Davis and Arel, 2014; Jacobs et al., 1991) 允许模型增加其总参数数量，同时保持为任何给定输入激活的参数数量不变。

通过对几乎整个模型栈（架构、数据、优化和系统）进行的一系列改进，Gemini 1.5 Pro 能够实现与 Gemini 1.0 Ultra 相当的质量（参见第 5 节），同时使用的训练计算量显着减少，并且服务效率也显着提高。Gemini 1.5 Pro 还包含一系列重要的架构变化，这些变化使其能够理解多达 1000 万个标记的长上下文输入，而不会降低性能。换算成现实世界的数据，这个上下文长度使 Gemini 1.5 Pro 模型能够轻松处理近五天的音频录音（即 107 小时），超过 1440 页的书籍（或 587,287 个单词）“战争与和平”的十倍，整个 Flax (Heek et al., 2023) 代码库（41,070 行代码）或 10.5 小时的以每秒 1 帧的速度播放的视频。此外，由于该模型是天生多模态的，并支持来自不同模态数据的交错，因此它可以在同一个输入序列中支持音频、视觉、文本和代码输入的混合。在第 4.1 节中，我们重点介绍了这些进展所带来的一些新功能，包括对长达 1000 万的上下文长度进行评估并得出积极结果。我们注意到，了解这些功能的局限性并研究其令人兴奋的功能和应用仍然是一个持续的研究探索领域。

**3. 训练基础设施和数据集**

与 Gemini 1.0 Ultra 和 1.0 Pro 一样，Gemini 1.5 Pro 使用多个 4096 芯片的 Google TPUv4 加速器进行训练，这些加速器分布在多个数据中心，并在各种多模态和多语言数据上进行训练。我们的预训练数据集包括来自许多不同领域的数据，包括网络文档和代码，并包含图像、音频和视频内容。对于指令调优阶段，我们在多模态数据（包含成对的指令和适当的响应）上对 Gemini 1.5 Pro 进行了微调，并根据人类偏好数据进行了进一步的调优。我们建议读者参考 Gemini 1.0 技术报告 (Gemini-Team et al., 2023) 以获取更多信息。

**4. 长上下文评估**

现有的评估方法越来越难以满足新型和快速发展的大型多模态模型的能力。它们通常侧重于单个模态和/或局限于上下文长度较短的任务。因此，越来越需要能够体现现实世界中长混合模态用例细微需求的基准测试。其中，我们将跨长混合模态序列的推理能力的定量评估作为一项关键挑战。

考虑到评估功能越来越强大的模型所面临的挑战，我们对 Gemini 1.5 Pro 的评估首先侧重于理解和评估其新功能。随后，我们探索了核心基准测试，涵盖了 Gemini 1.0 技术报告 (Gemini-Team et al., 2023) 中研究的功能。具体来说，我们从三个主要类别评估 Gemini 1.5 Pro：

1. **定性长上下文多模态评估**：手动探测和压力测试模型的长上下文能力，特别是对于不存在定量基准的新功能。
    
2. **定量长上下文多模态评估**：在具有明确定义的指标的合成和真实世界任务上衡量模型的长上下文能力。
    
3. **定量核心评估**：确定核心功能（例如编码、数学、科学、多语言和指令遵循）的进展和退步。
    

**4.1. 多模态长上下文能力的定性示例**

处理数百万个标记的能力解锁了以前无法实现的实际应用。在本节中，我们将展示我们在代码、文本和视频方面与 Gemini 1.5 Pro 进行交互时观察到的一些令人惊讶的互动。

**4.2. 长上下文评估**

在过去的几年中，LLM 研究的重点是扩大模型可以从中整合信息的上下文窗口 (Anthropic, 2023a; OpenAI, 2023)。这种重视源于人们认识到更宽的上下文窗口允许模型在推理时整合更多在训练数据中找不到的新的、特定于任务的信息，从而提高各种自然语言或多模态任务的性能。最近改进模型长上下文能力的方法分为几类，包括新颖的架构方法 (Ainslie et al., 2023; Gu and Dao, 2023; Guo et al., 2021; Orvieto et al., 2023; Zaheer et al., 2020)、训练后修改 (Bertsch et al., 2023; Chen et al., 2023; Press et al., 2021; Xiong et al., 2023)、检索增强模型 (Guu et al., 2020; Izacard et al., 2022; Jiang et al., 2022; Karpukhin et al., 2020; Santhanam et al., 2021)、记忆增强模型 (Bulatov et al., 2022, 2023; Martins et al., 2022; Mu et al., 2023; Wu et al., 2022a,b; Zhong et al., 2022) 以及构建更一致的长上下文数据集的技术 (Shi et al., 2023b; Staniszewski et al., 2023)。这些活动导致 LLM 在过去几个月中在长上下文能力方面取得了可衡量的改进，最近的 Liu et al. (2024) 的并发工作探索了长达 100 万个多模态标记的 7B 模型的上下文窗口。值得注意的是，在最先进的 LLM 中，Anthropic 已成功将其仅文本的 Claude 2 模型的上下文扩展到 10 万个标记，而 OpenAI 最近发布的 GPT-4 Turbo 则达到了 12.8 万个标记。最后，该系列的最新成员是上下文窗口为 20 万个标记的 Claude 2.1。

Gemini 1.5 Pro 将此上下文长度边界显着扩展到数百万个标记，几乎没有性能下降，从而可以处理更大的输入。与上下文窗口为 20 万个标记的 Claude 2.1 相比，Gemini 1.5 Pro 在 20 万个标记时实现了 100% 的召回率，超过了 Claude 2.1 的 98%。这种 100% 的召回率一直保持到 53 万个标记，而在 100 万个标记时的召回率为 99.7%。当从 100 万个标记增加到 1000 万个标记时，该模型保持了 99.2% 的召回率。此外，Gemini 1.5 Pro 的原生多模态功能使其能够摄取数小时的音频和视频记录，以及与文本并行或交错的数据。图 1 总结了此类召回功能。下面我们将报告跨所有三种模态（即文本、视觉和音频）的长上下文评估结果。

我们用于衡量 Gemini 1.5 Pro 长上下文能力的评估方法包括针对长上下文能力的诊断性探测（例如，长序列的困惑度、“大海捞针”检索研究）和专为多模态长上下文任务设计的现实评估（例如，长文档问答、长上下文自动语音识别、仅从一本书中学习翻译新语言以及长上下文视频问答）。为了提供参考点，在本节中，我们将 Gemini 1.5 Pro 与每个任务的外部领先模型进行比较。借助我们为 Gemini 1.5 Pro 开发的评估工具，我们能够可靠地量化长上下文理解能力的质量，一直到 1000 万个标记。

**4.2.1. 诊断性长上下文评估**

**4.2.1.1 长序列的困惑度**

我们首先报告文本模态的结果。为了评估模型利用非常长的上下文来改进下一个标记预测的能力（这是用于训练语言模型的目标函数），我们记录了来自保留文本（即未使用于训练）中不同位置的标记的负对数似然 (NLL)。在这里，较低的值意味着更好的预测。通常，我们预计序列开头的标记具有较高的 NLL，因为模型几乎没有上下文可以用来预测它们，而序列后面的标记的 NLL 较低，因为模型可用的信息更多。结果曲线的形状表明了模型推理长上下文的能力。下降趋势表示模型利用长上下文来减少模型的不确定性。另一方面，上升趋势表示模型无法有效地利用来自先前上下文的信息，并且预测质量可能正在下降，这突出了其长上下文理解能力的局限性。

我们在两个数据源上执行此分析：(a) 一个包含多达 100 万个标记的长文档数据集，以及 (b) 一个通过首先随机打乱所有文件然后将它们连接在一起构建的代码存储库数据集。代码数据集包含长度超过 100 万个标记的序列，这些序列具有一定的自然形式的语义关联（例如，整个存储库），允许对多达 1000 万个标记的序列进行进一步评估。图 6 显示了直到特定标记索引的累积 NLL。

我们在图 6 中发现 NLL 随着序列长度单调递减，因此预测准确性一直提高到测试的序列长度（长文档为 100 万，代码为 1000 万），这表明我们的模型即使在非常长的上下文长度下也可以利用整个输入。这表明该模型能够通过找到标记中的有用模式来改进其预测，即使这些模式出现在数百万个标记之前，就像代码的情况一样。

最后，我们看到这种改进的预测遵循规律的幂律结构。虽然众所周知，就训练计算量与模型性能 (NLL) 而言，语言模型遵循幂律 (Kaplan et al., 2020) 直到非常大的规模，但我们证明了在对数损失和上下文长度之间也存在幂律，直到极长的上下文长度。我们看到幂律拟合对于长文档来说直到 100 万个标记都非常准确，对于代码来说则大约为 200 万个标记。通过检查更接近 1000 万的较长代码标记预测，我们看到增加的上下文偶尔会带来巨大收益的现象（例如，由于代码块的重复），这可以解释幂律偏差。但是，这值得进一步研究，并且可能取决于所使用的数据集的确切情况。

**5. 核心能力评估**

我们用于 Gemini 1.5 Pro 的评估工具的最后一个组件衡量模型的核心能力（即在非长上下文任务上的性能）的质量。本节中的评估包括社区使用的公共和保留的已建立基准测试，涵盖所有三种模态，即文本、视觉和音频。

我们的选择标准主要旨在衡量 Gemini 1.5 Pro 与其前身 Gemini 1.0 系列模型 Gemini 1.0 Pro 和 Gemini 1.0 Ultra 相比的改进程度。我们的目标是突出 1.5 代 Gemini 模型在长上下文能力方面表现出色与其在非长上下文任务上的性能之间权衡的程度（如果存在）。特别是，随着我们开发 1.5 系列，我们的目标是在不损害其所有其他功能的质量的情况下增强模型在这种新的多模态长上下文维度上的熟练程度。

总而言之，我们发现 1.0 和 1.5 系列之间有明显的代际改进，Gemini 1.5 Pro 在我们全面的评估基准测试中全面优于 1.0 Pro，并接近（甚至经常超过）1.0 Ultra（在大多数基准测试中，这是一个最先进的模型），尽管训练效率要低得多。

**5.1. 核心文本评估**

我们首先比较三个主要的文本核心功能：(1) 数学、科学和推理；(2) 编码；(3) 多语言；以及 (4) 指令遵循。有关这些结果的摘要，请参见表 8。

**6. 负责任的部署**

与 Gemini 1.0 模型一致，我们遵循结构化方法进行 Gemini 1.5 Pro 的负责任部署，如图 13 所示。在本报告中，我们提供了有关 Gemini 1.5 Pro 影响评估、评估方法和最新模型的模型缓解工作的新信息。与 Gemini 1.0 系列一致的负责任部署生命周期中与 Gemini 1.5 Pro 相关的其他工作在 Gemini 1.0 技术报告 (Gemini-Team et al., 2023) 中进行了概述。

并突破了效率、多模态、长上下文推理和下游性能的界限。Gemini 1.5 Pro 将 Gemini 1.0 系列的内容窗口从 3.2 万个标记扩展到数百万个标记，使其成为第一个在跨模态方面大大超过 Claude 2.1 目前 20 万个标记上限的商用模型。我们进一步证明了长达 1000 万个标记的改进的长上下文性能。

我们使用诊断性和现实的多模态长上下文基准进行的广泛评估表明，1.5 Pro 能够在多模态版本的“大海捞针”中保持近乎完美的召回率（参见第 4.2.1.2 节），并能够有效地利用其上下文来检索和推理大量数据。这使得该模型能够执行现实的长上下文任务，例如从 70 万字的材料中进行长文档问答，以及从 40 到 105 分钟长的视频中进行长视频问答。最后，1.5 Pro 能够使用上下文学习将英语翻译成 Kalamang，这是一种资源极度匮乏的语言，只有不到 200 人使用 (Visser, 2020b)。这种能力是通过在推理时在其上下文中提供语法手册来实现的，这表明 Gemini 1.5 Pro 具有从训练时从未见过的信息中进行上下文学习的非凡能力。

最重要的是，长上下文性能的这种飞跃并没有以 1.0 系列擅长的多模态核心功能（即非长上下文任务的性能）为代价。相反，1.5 Pro 能够在我们本报告中提出的全面的评估基准测试中全面优于 1.0 Pro。有趣的是，1.5 Pro 尽管使用了明显较少的训练计算量，但在数学、科学和推理、代码、多语言和指令遵循等文本能力方面，与最先进的模型 1.0 Ultra 相当，甚至在某些功能方面超过了它。

**长上下文评估，行动号召**

评估能够处理非常长上下文的模型的能力带来了一系列新的挑战，尤其是在可以组合文本、图像、视频和音频的多模态领域。当前的基准测试通常无法充分压力测试像 Gemini 1.5 Pro 这样的模型，因为它们通常是为评估较短上下文模型而设计的。随着前沿模型的评估要求越来越需要具有长度和复杂性的基准测试，人工标记和标注的任务将变得更加昂贵和耗时。这也对严重依赖人工评估的传统评估方法提出了挑战。

因此，鉴于现有基准测试的局限性和人工标注的挑战，迫切需要创新的评估方法。这些方法应该能够有效地评估模型在非常长上下文任务上的性能，同时最大限度地减少人工标注的负担。为了开始解决其中一些问题，我们建议研究人员和从业者采用“多针大海捞针”设置进行诊断评估，我们观察到与“单针”对应物相比，这种设置信息丰富且更具挑战性。我们相信，基于新的或改进的自动指标的新基准测试任务有很大的发展空间，这些指标需要对长输入（包括人工生成和模型生成的）进行复杂的推理。这也是一个有趣的未来研究方向，可以创建具有挑战性的评估，而不仅仅强调长上下文模型的检索能力。我们将继续开发此类基准测试，以对多模态空间中的模型能力进行现实和全面的评估。通过解决这些未解决的挑战并开发新的基准测试和评估方法，我们可以推动非常长上下文 AI 模型领域的发展，并释放其全部潜力。