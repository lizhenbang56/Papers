---
Url: https://arxiv.org/pdf/2404.06542.pdf
Year: "2024"
Month: "04"
Publish: CVPR2024
---

## 摘要

开放词汇语义分割旨在将以文本形式表达的任意类别进行分割。先前的工作已经训练了大量的图像-标题对，以强化像素级多模态对齐。然而，标题提供了关于给定图像语义的全局信息，但缺乏对个别概念的直接定位。此外，对大规模数据集的训练不可避免地带来了显著的计算成本。在本文中，我们提出了FreeDA，一种无需训练的扩散增强方法，用于开放词汇语义分割，它利用了扩散模型定位生成概念的能力，并利用局部-全局相似性将类别不可知区域与语义类别匹配。我们的方法涉及一个离线阶段，在这个阶段，从大量标题开始收集文本-视觉参考嵌入，利用视觉和语义上下文。在测试时，这些嵌入被查询以支持视觉匹配过程，该过程通过联合考虑类别不可知区域和全局语义相似性来完成。广泛的分析表明，FreeDA在五个数据集上实现了最先进的性能，在mIoU方面超过了以往方法超过7.0个平均点，并且无需任何训练。我们的源代码可在aimagelab.github.io/freeda获得。

## 引言

语义分割是计算机视觉中的一个核心问题，旨在根据一组语义类别将图像分割为连贯的区域。由于手动注释大规模的训练数据成本高昂，将分割扩展到完全监督的大量概念集是不现实的。这最近将社区的焦点转向了开放词汇解决方案，这些解决方案可以从一个狭窄的已见类别集合或弱监督形式中学习，从而能够分割新的和未见类别。在这种设置中的一个主要挑战是如何将大规模视觉-语言模型（例如CLIP和ALIGN）匹配文本和图像的能力转移到文本像素对齐。在给定大规模网络抓取的图像-标题对集合的情况下，先前的方法通过对比学习技术与接地机制相结合[6, 43, 44]来迫使定位文本概念的能力出现。然而，标题通常捕获全局场景，可能对细粒度元素存在歧义，使得这种方法不够优化且计算密集。另外，扩散模型的进展在文本到图像生成方面表现出色，并且最近的工作表明它们的特征涵盖了生成对象的定位知识。这些信息可以被利用来生成大量的归因图，这些图在对应语义类别的区域更活跃，因此为语义分割提供了有价值的信息源。我们建议探索这种机制作为多模态对比训练的替代方案，在完全无需学习任何参数的方法中。与先前的工作相反，我们提出的方法遵循一个高效的两步协议：在离线阶段，我们利用扩散增强生成生成具有上下文感知的文本-视觉参考向量的集合。然后，在推理时，这些参考被检索以计算局部和全局相似性来分割输入图像。具体来说，我们使用大量的文本标题通过基于交叉关注机制的定位机制生成合成图像和相应的归因图。随后，我们利用自监督的视觉骨干DINOv2构建与文本向量相关联的一组视觉原型，每个原型代表其合成场景中的一个实例的上下文。在推理时，我们提取全局特征和局部密集特征，分别使用多模态编码器（即CLIP）和DINOv2，其具有高语义相关性，并使用超像素算法检测类别不可知区域。通过在文本-视觉参考嵌入集合中查询输入文本类别，然后将每个超像素分配给在全局和局部模态之间具有最高综合相似性的类别。由于我们的方法是无需训练的，并且依赖于扩散增强生成，我们将其命名为FreeDA。我们通过在Pascal VOC，Pascal Context，COCO Stuff和Object，Cityscapes和ADE20K上进行大量实验来验证所提出的框架。FreeDA在所有数据集上均表现出色，无需任何形式的训练，始终明显优于先前的方法，实现了最先进的性能。总的来说，我们的工作表明，非参数方法可以为开放词汇语义分割提供一个引人注目且高效的替代方案，并为随后的工作开辟了新的机会。综上所述，本文的贡献如下：
• 我们介绍了FreeDA，一种新颖的无需训练的方法，用于通过扩散模型生成具有上下文感知的文本-视觉参考嵌入来进行开放词汇语义分割。
• 我们提出了一个推理管道，利用DINOv2的语义对应性、超像素算法和局部与全局相似性的组合，实现了精确而稳健的分割预测。
• 我们的实验表明，我们的方法在五个数据集上实现了最先进的性能，无需任何形式的训练。

## 相关工作 

【开放词汇语义分割】在大规模视觉-语言模型在零样本分类方面取得成功的基础上，先前关于开放词汇分割的工作已经研究了将多模态图像-文本对齐策略转移到更精细的粒度（即区域或像素级别）的策略。一组文献一直致力于利用密集注释提供的监督信息，该信息仅适用于有限类别集合，以泛化到未见类别。OpenSeg [13]将任务解耦为区域提出者和将区域与标题中的单词对齐的grounding模块。类似地，OVSeg [22]采用了一个两阶段方法，其中类别不可知区域被屏蔽并提供给一个具有可学习的视觉提示的CLIP编码器。SAN [47]将一个辅助网络与CLIP结合起来提出区域，同时识别其对应的语义类别。然而，这些方法受到已见和未见类别之间性能差距的影响，并且由于密集注释的成本，只能在有限的领域中应用。 其他工作则利用了在大量图像-文本对上的对比训练，而无需密集注释。GroupViT [43]提出了一种Transformer架构，逐渐学习将图像区域进行分组。MaskCLIP [52]通过修改最后一个注意力层，使冻结的CLIP适应密集预测。TCL [6]提出了一个接地机制，在对比学习过程中学习将文本与区域关联起来。OVSegmentor [44]引入了一个基于槽注意力的模块，用于将Transformer的标记分组并与标题对齐。我们的方法属于这个研究方向，因为它仅依赖于一组标题作为支持，而无需密集注释。 扩散模型中的定位。扩散模型已经在图像生成方面证明了最先进的性能。少数工作致力于在生成过程中定位条件标题中提到的概念。DAAM [39]提出了利用稳定扩散中使用的交叉注意力机制来提取提示中提到的单词的归因图。DiffuMask [42]利用DAAM的进展来生成无需人工注释的地面真实分割掩码，并在其上训练分割模型。GroundedDiffusion [21]实现了一个接地模块，在扩散过程中对齐文本和视觉嵌入。 一些工作研究了扩散模型在开放词汇分割中的应用。ODISE [45]采用稳定扩散作为其掩码生成器的特征提取器。OVDiff [18]在预测时生成一组视觉参考以支持分割过程。我们的方法也依赖于图像的生成；然而，这是为了在离线阶段收集视觉原型，这个选择在预测时显著减少了计算负载。 超像素算法。超像素的概念源自一个观察：像素不是图像的自然表示。超像素是基于图像的视觉特征（如形状、亮度、颜色和纹理）而形成的一组同质像素。多年来，已经开发了几种提取策略，旨在提高其质量和效率，例如基于分水岭的和基于聚类的方法。在本文中，我们将超像素用作将图像划分为类别不可知区域的支持，从而计算局部视觉相似性。