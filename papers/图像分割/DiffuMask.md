---
Title: "DiffuMask: Synthesizing Images with Pixel-level Annotations for Semantic\rSegmentation Using Diffusion Models"
Year: "2023"
Month: "03"
Url: https://arxiv.org/pdf/2303.11681.pdf
创新点: 使用扩散模型生成图像分割数据集，包括图片和GT分割模板
---
收集和标注具有像素级标签的图像是耗时且繁琐的。相比之下，使用生成模型（例如，DALL-E、Stable Diffusion）可以自由获得合成数据。在本文中，我们展示了通过仅使用文本-图像对进行训练的现成Stable Diffusion模型生成的合成图像，可以自动获得准确的语义掩模的可能性。我们的方法，称为DiffuMask，利用了文本和图像之间的交叉注意力图的潜力，这种方法可以自然而无缝地将文本驱动的图像合成扩展到语义掩模生成。DiffuMask利用文本引导的交叉注意力信息来定位类/词特定区域，然后与实用技术相结合，创建新的高分辨率和类别区分度像素级掩模。这些方法有助于显著降低数据收集和标注成本。实验证明，在DiffuMask的合成数据上训练的现有分割方法可以在实际数据（VOC 2012、Cityscapes）的对应部分上取得竞争性性能。对于某些类别（例如，鸟类），DiffuMask表现出有希望的性能，接近于实际数据的最新结果（在3% mIoU差距内）。此外，在开放词汇分割（零样本）设置下，DiffuMask在VOC 2012的未见类别上取得了新的最新结果。项目网站可在DiffuMask中找到。

## 1. 引言 

语义分割是视觉领域中的一项基础任务，现有的数据密集型语义分割模型通常需要大量具有像素级别标注的数据才能取得显著进展。不幸的是，像素级掩模注释是一项劳动密集且昂贵的过程。例如，在Cityscapes中标记单个语义城市图像可能需要长达60分钟，突显了这项任务的难度。此外，在某些情况下，由于现有的隐私和版权问题，收集图像可能是具有挑战性甚至是不可能的。为了降低注释成本，近年来，弱监督学习已经成为一种流行的方法。这种方法涉及使用弱或廉价标签训练强分割模型，例如图像级别标签、点、涂鸦和边界框。尽管这些方法不需要像素级别注释，但仍然存在一些缺点，包括低性能准确度、复杂的训练策略、不可或缺的额外注释成本（例如边缘）和图像收集成本。

随着计算机图形学的巨大发展（例如，生成模型），另一种方法是利用合成数据，这些数据大多来自虚拟世界，并且像素级别的真实情况可以自由且自动地生成。DatasetGAN首先利用了经过训练的GAN的特征空间，并训练了一个浅层解码器来生成像素级别的标签。BigDatasetGAN扩展了DatasetGAN以处理ImageNet的大类多样性。然而，这两种方法都存在一定的缺点，需要少量像素级别标记的示例才能推广到其余潜在空间，并且由于不精确的生成掩模而导致性能不佳。

最近，大规模语言-图像生成（LLIG）模型，例如DALL-E和Stable Diffusion，展示了惊人的生成语义和构成能力。鉴于一个语言描述，文本条件图像生成模型可以创建相应的语义事物和材料，其中视觉和文本嵌入使用空间交叉注意力融合。我们深入研究了交叉注意力层，并探索了它们对生成语义对象和图像结构的影响。我们发现交叉注意力图是核心，它将提示文本的视觉像素和文本符号联系起来。此外，交叉注意力图包含丰富的类（文本符号）判别性空间定位信息，这对生成的图像具有关键性影响。

注意力图可以用作掩模注释吗？考虑语义分割 - ‘好的’像素级语义掩模注释应满足两个条件：（a）类别判别性（即，定位和区分图像中的类别）；（b）高分辨率、精确的掩模（即，捕获细粒度细节）。图2b展示了文本条件扩散模型（即，稳定扩散）的交叉注意力图的可视化。从稳定扩散的U-Net的不同层中提取8×8、16×16、32×32和64×64，作为四种不同分辨率。8×8特征图是最低分辨率的，包括明显的类别判别位置。32×32和64×64特征图包括高分辨率，并突出显示细粒度细节。平均图显示了我们可以用于语义分割的可能性，其中它是类别判别和细粒度的。为了进一步验证生成任务的注意力图的潜力，我们将概率图转换为具有固定阈值的二进制图，并使用Dense CRF进行细化，如图2c所示。使用0.35阈值，掩模在细节方面（例如‘马’的脚和耳朵）表现出出色的精度。

基于上述观察，我们提出了DiffuMask，一个自动生成大规模高质量图像和像素级语义标注的过程。与DatasetGAN和BigDatasetGAN不同，DiffuMask不需要任何像素级别的注释。这种方法充分利用了强大的零样本文本到图像生成模型，例如稳定扩散，这些模型是在Web规模的图像-文本对上训练的。DiffuMask主要包括两个挑战的优势：1）精确的掩模。提出了自适应阈值的二值化，将概率图（注意力图）转换为二进制图，作为掩模注释。此外，噪声学习用于过滤噪声标签。2）域差距：检索为基础的提示（各种各样和逼真的提示指导）和数据增强（例如，拼接），作为两种有效的解决方案，旨在通过增强数据的多样性来减少域差距。借助上述优势，DiffuMask可以为任何类别生成具有像素级注释的无限图像，无需人类努力。然后，这些合成数据可以用于训练任何语义分割架构，例如mask2former，以替换实际数据。

总之，我们的贡献有三个方面：

- 我们展示了一种新颖的见解，即可以从文本监督的预训练扩散模型自动获得合成图像和掩模注释。
- 我们提出了DiffuMask，一种无需人工干预和任何手动掩模注释的自动过程，可以生成大量图像和像素级语义注释，充分利用了文本和图像之间的交叉注意力图的潜力。
- 实验证明，使用DiffuMask训练的分割方法在实际数据上表现出竞争力，例如VOC 2012。对于某些类别，例如狗，性能接近于使用实际数据训练的性能（在3%的差距内）。此外，在开放词汇分割（零样本）设置下，DiffuMask在VOC 2012的未见类别上取得了新的最新结果。

## 4. 实验 

4.1. 实验设置 数据集和任务。数据集。在语义分割的先前工作[11, 36]中，我们使用了Pascal-VOC 2012 [19]、ADE20k [68]和Cityscapes [15]来评估DiffuMask。任务。我们的实验采用了三个任务，即语义分割、开放词汇分割和域泛化。 实现细节。我们采用了预训练的Stable Diffusion [49]、CLIP [47]的文本编码器以及AffinityNet [2]作为基础组件。