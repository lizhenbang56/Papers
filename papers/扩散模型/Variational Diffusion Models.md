---
论文链接: https://arxiv.org/pdf/2107.00630.pdf
Publish: NIPS2021
---
扩散基生成模型已经展示出在视觉上令人印象深刻的合成能力，但它们也能成为出色的似然模型吗？我们肯定地回答了这个问题，并引入了一系列基于扩散的生成模型，在标准图像密度估计基准上获得了最先进的似然值。与其他扩散模型不同，我们的方法允许有效地优化噪声调度以及模型的其余部分。我们展示了变分下界（VLB）在扩散数据的信噪比方面的表达式非常简洁，从而提高了我们对这一模型类的理论理解。利用这一见解，我们证明了文献中提出的几种模型之间的等价性。此外，我们还展示了连续时间VLB对噪声调度的不变性，除了在其端点处的信噪比。这使我们能够学习一个最小化得到的VLB估计器方差的噪声调度，从而加快了优化过程。结合这些进展和架构改进，我们在图像密度估计基准上获得了最先进的似然值，超越了多年来一直主导这些基准的自回归模型，而且通常优化速度更快。此外，我们展示了如何将该模型用作比特回退压缩方案的一部分，并展示了接近理论最优的无损压缩率。代码可在 https://github.com/google-research/vdm 获取。

## 1 Introduction

基于似然的生成建模是机器学习中的一个核心任务，是从语音合成 [Oord et al., 2016] 到翻译 [Sutskever et al., 2014]，再到压缩 [MacKay, 2003] 等各种应用的基础。由于它们易于处理的似然性和表达能力，自回归模型长期以来一直是这一任务的主导模型类别，如图1所示。最近，扩散模型在图像 [Ho et al., 2020, Song et al., 2021b, Nichol and Dhariwal, 2021] 和音频生成 [Kong et al., 2020, Chen et al., 2020] 方面展现出了令人印象深刻的结果，其感知质量表现出色，但在密度估计基准上仍然无法与自回归模型匹敌。在本文中，我们做出了几项技术贡献，使得扩散模型能够挑战自回归模型在该领域的主导地位。我们的主要贡献如下：

- 我们引入了一种灵活的基于扩散的生成模型族，其在标准图像密度估计基准（CIFAR-10 和 ImageNet）上实现了新的最先进的对数似然值。这得益于将 Fourier 特征纳入扩散模型中，并使用可学习的扩散过程规范，以及其他建模创新。
- 我们通过分析扩散模型的变分下界（VLB），提高了我们对密度建模的理论理解，导出了一个在扩散过程的信噪比方面极为简单的表达式。这一结果为模型类别提供了新的见解：对于连续时间（无限深度）的设置，我们证明了生成模型及其 VLB 对扩散过程规范的不变性，并且展示了文献中各种扩散模型在数据的平凡时间依赖重缩放方面的等价性。

## 2 Related work

我们的工作基于扩散概率模型（DPMs）[Sohl-Dickstein et al., 2015]，简称扩散模型。DPMs可以看作是一种变分自编码器（VAE）[Kingma和Welling，2013，Rezende等，2014]，其结构和损失函数允许有效地训练任意深度的模型。由于其令人印象深刻的图像生成结果，近年来对扩散模型的兴趣再次高涨 [Ho et al., 2020, Song and Ermon, 2020]。

Ho等人[2020]对原始的DPM引入了一些模型创新，在图像生成质量基准上取得了令人印象深刻的成果。他们表明，对于具有离散时间和跨输入维度共享扩散方差的扩散模型，VLB目标等效于多尺度去噪得分匹配，直到特定的噪声尺度权重为止。Nichol和Dhariwal [2021]提出了进一步的改进，导致更好的对数似然得分。Gao等人[2020]展示了如何利用扩散有效地优化能量基模型（EBMs）以接近对数似然目标，即使在长期MCMC链之后仍能产生高保真度样本。

Song和Ermon [2019]首次提出了通过多尺度去噪得分匹配目标学习生成模型，Song和Ermon [2020]中提出了改进方法。这一方法后来被扩展到基于扩散过程逆转的新型采样算法的连续时间扩散 [Song et al., 2021b]。

与我们的工作同时进行，Song等人[2021a]，Huang等人[2021]和Vahdat等人[2021]也推导出了在连续时间扩散模型下数据似然的变分下界。在我们考虑标准VAE的无限深度限制时，Song等人[2021a]和Vahdat等人[2021]基于随机微分方程提出了不同的导出方法。Huang等人[2021]考虑了两种观点，并讨论了两种方法之间的相似之处。与这些其他工作相比，我们分析的一个优势是，我们以扩散数据的信噪比为基础提出了VLB的直观表达式，导致离散时间和连续时间损失的表达式大大简化，使得实现简单且数值稳定。这也导致了关于生成模型及其VLB对扩散过程规范的不变性的新结果。我们在表1中与这些工作以及其他工作进行了实证比较。

先前对扩散概率模型的方法固定了扩散过程；相反，我们与模型的其余部分一起优化扩散过程参数。这将模型转变为一种类型的VAE [Kingma和Welling，2013，Rezende等，2014]。这得益于直接参数化边缘q(zt|z0)的均值和方差，而之前的方法则参数化了各个扩散步骤q(zt+ε|zt)。此外，我们的去噪模型包括几种架构更改，其中最重要的是使用Fourier特征，这使我们能够达到比先前的扩散概率模型更好的似然值。

## 3 模型 

我们将专注于生成建模的最基本情况，其中我们有一组观测到的 x 的数据集，并且任务是估计边缘分布 p(x)。与大多数生成模型一样，所描述的方法可以扩展到观测变量多个的情况，和/或估计条件密度 p(x|y)的任务。所提出的潜变量模型包括扩散过程（第3.1节），我们将其反转以获得分层生成模型（第3.3节）。正如我们将展示的那样，下面的模型选择导致了一个令人惊讶地简单的边缘似然的变分下界（VLB），我们将用它来优化参数。

### 3.1 正向时间扩散过程 

我们的出发点是一个高斯扩散过程，它从数据 $\textbf{x}$ 开始，并定义了一系列越来越嘈杂的 $\textbf{x}$ 的版本，我们将其称为潜变量 $\textbf{z}_t$，其中 $t$ 从 $t = 0$（最不嘈杂）到 $t = 1$（最嘈杂）。对于任意 $t \in [0, 1]$，在给定 $\textbf{x}$ 的条件下，潜变量 $\textbf{z}_t$ 的分布由以下公式给出：
$$q(\textbf{z}_t|\textbf{x}) = \mathcal{N}(\alpha \textbf{x}, \sigma^2_t \textbf{I})$$
我们假设 SNR(t) 在时间上严格单调递减，即对于任意 t > s，都有 SNR(t) < SNR(s)。这正式表达了随着时间的推移，zt 越来越嘈杂的概念。我们还假设 αt 和 σ^2_t 都是平滑的，即它们相对于时间 t 的导数是有限的。这个扩散过程的规范包括了作为特例的方差保持扩散过程，例如 [Sohl-Dickstein et al., 2015, Ho et al., 2020] 中使用的，其中 αt = sqrt(1 - σ^2_t)。另一个特例是方差爆炸型扩散过程，例如 [Song and Ermon, 2019, Song et al., 2021b] 中使用的，其中 α^2_t = 1。在实验中，我们使用了方差保持版本。

任意 t > s 的潜变量分布 q(zt|zs) 也是高斯分布，在附录 A 中给出。在任何后续时间步长 0 ≤ s < t < u ≤ 1，潜变量 (zs, zt, zu) 的联合分布是马尔可夫的：q(zu|zt, zs) = q(zu|zt)。给定上述分布，通过贝叶斯规则相对容易验证对于任意 0 ≤ s < t ≤ 1，q(zs|zt, x) 也是高斯分布。这个分布也在附录 A 中给出。

### 3.3 Reverse time generative model

我们通过反转第3.1节中的扩散过程来定义我们的生成模型，得到一个分层生成模型，该模型从 t = 1 开始向后采样一系列的潜变量 zt，时间从 t = 1 到 t = 0。我们考虑了这个序列由有限步骤 T 组成的情况，以及对应于 T → ∞ 的连续时间模型。我们首先介绍离散时间的情况。对于有限的 T，我们将时间均匀离散化为 T 个时间步长（段），每段的宽度为 τ = 1/T。定义 s(i) = (i − 1)/T 和 t(i) = i/T，我们的数据 x 的分层生成模型如下：...

## 6 Experiments

我们在 CIFAR-10 [Krizhevsky et al., 2009] 数据集和降采样的 ImageNet [Van Oord et al., 2016, Deng et al., 2009] 数据集上展示了我们提出的扩散模型类别，我们称之为变分扩散模型（VDMs），其中我们专注于最大化似然。对于我们使用数据增强的结果，我们使用了随机翻转、90度旋转和颜色通道交换。我们模型规范的更多细节请参见附录 B。