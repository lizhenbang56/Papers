---
论文链接: https://arxiv.org/pdf/2112.10752.pdf
---
## 摘要
  
将图像形成过程分解为一系列应用去噪自动编码器的步骤，扩散模型（DMs）在图像数据及其他领域实现了最先进的合成结果。此外，它们的表述允许引导机制来控制图像生成过程，无需重新训练。然而，由于这些模型通常直接在像素空间中操作，强大的扩散模型的优化通常需要消耗数百个GPU天，并且由于顺序评估而导致推理成本高昂。为了在有限的计算资源上训练扩散模型，同时保持其质量和灵活性，我们将它们应用于强大的预训练自动编码器的潜在空间。与以往的工作相比，通过在这样的表示上训练扩散模型，首次实现了在复杂性减少和细节保留之间达到近乎最优的点，大大提高了视觉保真度。通过在模型架构中引入交叉注意力层，我们将扩散模型转变为强大而灵活的生成器，适用于文本或边界框等通用条件输入，并且高分辨率合成变得以卷积方式实现。我们的潜在扩散模型（LDMs）在图像修复和类条件图像合成方面实现了新的最先进分数，并在各种任务上表现出高竞争力，包括文本到图像合成、无条件图像生成和超分辨率，同时与基于像素的DMs相比，大大降低了计算需求。

## 1. Introduction

$\textbf{图像合成}$是计算机视觉领域最近发展最引人注目的领域之一，但也是计算需求最大的领域之一。特别是对复杂自然场景的高分辨率合成目前主要由扩展基于可能包含数十亿参数的自回归（AR）变换器的基于可能包含数十亿参数的模型主导。与此相反，GANs的有希望的结果被发现主要局限于具有相对有限变异性的数据，因为它们的对抗学习过程不容易扩展到建模复杂的多模态分布。最近，扩散模型，这些模型由一系列去噪自动编码器构建，已经在图像合成以及其他领域取得了令人印象深刻的成果，并且在类条件图像合成和超分辨率方面定义了最先进的技术。此外，即使是无条件的DMs也可以轻松应用于诸如修复和着色或基于笔画的合成等任务，与其他类型的生成模型相比。作为基于似然的模型，它们不会出现GANs的模式崩溃和训练不稳定性，并且通过大量利用参数共享，它们可以在不涉及数十亿参数的情况下对自然图像的高度复杂分布进行建模。

扩散模型属于类似于可能会在建模数据的不可感知细节方面花费过多容量（因此计算资源）的可能性类的似然模型。虽然重加权变分目标的目标是通过对初始去噪步骤进行欠采样来解决这个问题，但是由于需要在RGB图像的高维空间中重复功能评估（和梯度计算），DMs仍然需要大量计算资源。例如，训练最强大的DMs通常需要数百个GPU天（例如，在一个A100 GPU上，产生50k个样本需要大约5天），这对于研究社区和一般用户来说有两个后果：首先，训练这样的模型需要大量的计算资源，这仅在该领域的一小部分人中可用，并且会留下巨大的碳足迹。其次，评估已经训练好的模型在时间和内存上也很昂贵，因为同一模型架构必须顺序运行多个步骤。为了增加这种强大模型类的可访问性并同时减少其显著的资源消耗，需要一种方法来降低训练和采样的计算复杂性。减少DMs的计算需求而不影响其性能对于增强其可访问性至关重要。我们的方法始于对像素空间中已经训练好的扩散模型的分析：图2显示了已经训练好的模型的速率-失真折衷。

与任何基于似然的模型一样，学习可以粗略地分为两个阶段：首先是一个感知压缩阶段，它消除高频细节，但仍然学习了一些语义变化。在第二阶段，实际的生成模型学习了数据的语义和概念组成（语义压缩）。因此，我们首先要找到一个在感知上等效但计算上更合适的空间，在该空间中我们将训练高分辨率图像合成的扩散模型。

我们将训练分为两个明确的阶段：首先，我们训练一个自动编码器，它提供了一个低维（从而高效）的表征空间，该空间在感知上等效于数据空间。重要的是，与以前的工作不同，我们不需要依赖于过度的空间压缩，因为我们在学习的潜在空间中训练DMs，该空间在空间维度方面具有更好的缩放性能。这种降低的复杂性还提供了从潜在空间中进行高效图像生成的单个网络传递。我们称之为Latent Diffusion Models（LDMs）。

这种方法的一个显著优势是，我们只需要训练一次通用自动编码器阶段，因此可以将其重复使用于多个DM训练或探索可能完全不同的任务。这使得可以高效地探索大量的扩散模型，用于各种图像到图像和文本到图像任务。对于后者，我们设计了一种将变换器连接到DM的UNet骨干的架构，并且使得任意类型的基于标记的条件机制成为可能。

总之，我们的工作做出了以下贡献：（i）与纯粹基于变换器的方法相比，我们的方法对于更高维数据的扩展更加优雅，因此可以（a）在提供比以前更忠实和详细的重建的压缩级别上工作，以及（b）可以有效地应用于百万像素图像的高分辨率合成。 （ii）我们在多个任务（无条件图像合成、修复、随机超分辨率）和数据集上实现了具有竞争力的性能，同时显著降低了计算成本。与基于像素的扩散方法相比，我们还显著降低了推理成本。（iii）我们发现，与先前的工作相比，该方法不需要对重建和生成能力进行细微的加权。这确保了极其忠实的重建，并且对潜在空间几乎没有任何正则化的要求。（iv）我们发现，对于密集条件任务，例如超分辨率、修复和语义合成，我们的模型可以以卷积方式应用，并且能够渲染出∼10242像素的大型一致图像。（v）此外，我们设计了一种基于交叉注意力的通用条件机制，实现了多模态训练。我们将其用于训练类条件、文本到图像和布局到图像模型。（vi）最后，我们在https://github.com/CompVis/latent-diffusion上发布了预训练的潜在扩散和自动编码模型，除了用于DMs的训练之外，还可以用于各种任务。

## 2. Related Work

### Generative Models for Image Synthesis

图像的高维特性给生成建模带来了独特的挑战。生成对抗网络（GAN）允许有效地采样具有良好感知质量的高分辨率图像，但很难优化，并且难以捕捉完整的数据分布。相比之下，基于似然的方法强调良好的密度估计，这使得优化更加稳定。变分自编码器（VAE）和流模型使得高分辨率图像的高效合成成为可能，但样本质量与GANs不相上下。虽然自回归模型在密度估计方面表现强劲，但计算要求高的架构和顺序采样过程限制了它们只能处理低分辨率图像。由于基于像素的图像表示包含几乎察觉不到的高频细节，最大似然训练会在对其进行建模时耗费不成比例的容量，导致训练时间长。为了扩展到更高分辨率，一些两阶段方法使用自回归模型来对压缩的潜在图像空间进行建模，而不是原始像素。

最近，扩散概率模型（DM）在密度估计以及样本质量方面取得了最先进的结果。这些模型的生成能力源自于它们对于图像样式数据的归纳偏差的自然契合，当它们的底层神经网络骨架实现为UNet时，合成质量通常最佳。当采用加权目标进行训练时，这种模型对应于一个有损压缩器，并且允许通过压缩能力来交换图像质量。

然而，在像素空间中评估和优化这些模型的缺点是推理速度慢且训练成本很高。虽然前者可以通过高级采样策略和分层方法部分解决，但在高分辨率图像数据上的训练总是需要计算昂贵的梯度。$\textbf{本文提出 LDM 来解决这两个缺点}$，它们在一个较低维度的压缩潜在空间中工作，这使得训练成本更低，推理速度更快，几乎没有降低合成质量。

## 3. Method

为了降低训练扩散模型以实现高分辨率图像合成的计算需求，我们观察到，虽然扩散模型允许通过对相应的损失项进行欠采样来忽略感知上无关紧要的细节，但它们仍然需要在像素空间中进行昂贵的函数评估，这导致了计算时间和能源资源的巨大需求。

我们提出通过明确分离压缩学习和生成学习阶段（见图2）来规避这个缺点。为了实现这一点，我们利用一个自动编码模型，它学习了一个在感知上等效于图像空间的空间，但提供了显著降低的计算复杂性。

这种方法具有几个优点：（i）通过离开高维图像空间，我们获得了在低维空间上执行采样的计算效率更高的DMs。 （ii）我们利用了DMs从其UNet架构[71]继承的归纳偏差，这使它们特别适用于具有空间结构的数据，因此减轻了以前方法所需的侵略性、降低质量的压缩级别的需求。 （iii）最后，我们获得了通用的压缩模型，其潜在空间可以用来训练多个生成模型，并且还可以用于其他下游应用，例如单图像CLIP引导合成。

### 3.1. Perceptual Image Compression

我们的感知压缩模型基于先前的工作，由一个自动编码器训练，组合了感知损失和基于补丁的对抗目标。这确保了通过实施局部真实性将重建限制在图像流形内，并且避免了仅依赖像素空间损失（如L2或L1目标）引入的模糊性。更具体地说，给定一个在RGB空间中的图像 $x \in \mathbb{R}^{H\times W \times 3}$，编码器 $\mathcal{E}$ 将 $x$ 编码为 latent representation $z = \mathcal{E}(x)$，解码器 $\mathcal{D}$ 从 lantent representation 中重建图像，得到 $\tilde{x} = \mathcal{D}(z) = \mathcal{D}(\mathcal{E}(x))$，其中 $z \in \mathbb{R}^{h \times w \times c}$。重要的是，编码器通过因子 $f = H/h = W/w$ 对图像进行下采样，我们研究不同的下采样因子 $f = 2^m$，其中 $m \in \mathbb{N}$。

为了避免潜在空间的任意高方差，我们尝试了两种不同类型的正则化。第一种变体KL-reg.，对学习到的潜在施加了轻微的KL惩罚，使其接近标准正态，类似于VAE，而VQ-reg.使用解码器内的矢量量化层。这个模型可以解释为一个VQGAN，但是量化层被解码器吸收了。由于我们后续的扩散模型被设计为与我们学到的潜在空间z = E(x)的二维结构一起工作，因此我们可以使用相对较轻的压缩率，并实现非常好的重建。这与先前的工作形成对比，先前的工作依赖于学习空间z的任意一维排序，以自回归方式对其分布进行建模，从而忽略了大部分z的固有结构。因此，我们的压缩模型更好地保留了x的细节。完整的目标和训练细节可以在附录中找到。

### 3.2. Latent Diffusion Models

扩散模型是一种概率模型，旨在通过逐渐去噪一个正态分布变量来学习数据分布 p(x)，这相当于学习长度为 T 的固定马尔可夫链的逆过程。对于图像合成，最成功的模型依赖于对 p(x) 的变分下界的加权变体，这与去噪得分匹配类似。这些模型可以解释为一系列等权重的去噪自动编码器 θ(xt, t)，其中 t = 1 . . . T，它们被训练来预测其输入 xt 的去噪变体，其中 xt 是输入 x 的噪声版本。相应的目标可以简化为：...，其中 t 从 {1, . . . , T} 中均匀采样。 通过我们训练的感知压缩模型，包括编码器 E 和解码器 D，我们现在可以访问一个高效的、低维的潜在空间，在这个空间中，高频的、难以察觉的细节被抽象化了。与高维像素空间相比，这个空间更适合于基于似然的生成模型，因为它们现在可以 (i) 关注数据的重要、语义位，并且 (ii) 在一个更低维度、计算效率更高的空间中进行训练。与以往依赖于自回归、基于注意力的变压器模型在高度压缩、离散潜在空间中的工作不同，我们可以利用模型提供的图像特定的归纳偏差。

### 3.3. Conditioning Mechanisms

与其他类型的生成模型类似，扩散模型原则上能够建模形式为 p(z|y) 的条件分布。这可以通过条件去噪自编码器 θ(zt, t, y) 实现，并为通过输入 y 控制合成过程铺平了道路，例如文本、语义地图或其他图像到图像的翻译任务。然而，在图像合成的背景下，将DM的生成能力与除了类标签或输入图像的模糊变体之外的其他类型的条件结合起来，目前是一个尚未充分探索的研究领域。我们通过将DM的基础UNet骨干与交叉注意力机制相结合，将DM转变为更灵活的条件图像生成器，交叉注意力机制对于学习各种输入模态的基于注意力的模型是有效的。为了预处理来自各种模态（如语言提示）的 y，我们引入了一个领域特定的编码器 τθ，将 y 投影到一个中间表示 τθ(y) ∈ RM×dτ，然后通过一个实现 Attention(Q, K, V) = softmax(QKT√d) · V 的交叉注意力层，将其映射到 UNet 的中间层。
## 4. Experiments

LDMs 提供了一种灵活且计算可行的扩散基础图像合成方法，适用于各种图像模态，我们在接下来的实证中进行了展示。然而，首先，我们分析了我们的模型在训练和推断中相对于基于像素的扩散模型的优势。有趣的是，我们发现在VQ正则化的潜在空间中训练的LDMs有时会在样本质量上表现更好，即使与其连续对应物相比，VQ正则化的第一阶段模型的重建能力稍微落后，参见表8。关于第一阶段正则化方案对LDM训练的影响以及它们对分辨率 > 256² 的泛化能力的视觉比较可以在附录 D.1 中找到。在E.2中，我们列出了本节中所有结果的架构、实施、训练和评估的详细信息。

### 4.2. Image Generation with Latent Diffusion

我们在CelebA-HQ、FFHQ、LSUN-Churches和LSUN-Bedrooms等数据集上训练了256²图像的无条件模型，并评估了i)样本质量和ii)它们对数据流形的覆盖度，使用了ii)FID和ii)精度-召回率。表1总结了我们的结果。在CelebA-HQ上，我们报告了一个新的FID最优结果为5.11，优于以前基于似然的模型以及GANs。我们还超越了LSGM，在LSGM中，潜在扩散模型与第一阶段一起进行训练。相比之下，我们在一个固定的空间中训练扩散模型，并且避免了权衡重建质量与学习潜在空间先验的困难，详见图1-2。我们在所有数据集上都超越了以前基于扩散的方法，除了LSUN-Bedrooms数据集，我们的分数接近ADM，尽管我们利用了一半的参数，并且需要的训练资源少了4倍（详见附录E.3.5）。

### 4.3. Conditional Latent Diffusion

#### 4.3.1 Transformer Encoders for LDMs

通过引入基于交叉注意力的条件化机制到LDMs中，我们为先前未被扩散模型探索的各种条件模态打开了大门。对于文本到图像的图像建模，我们训练了一个拥有1.45亿参数的KL正则化的LDM，该模型在LAION-400M上以语言提示作为条件进行训练。我们采用BERT-tokenizer并将τθ实现为一个transformer来推断出一个潜在编码，该编码通过（多头）交叉注意力映射到UNet中。这种特定于领域的专家组合学习语言表示和视觉合成的方式产生了一个强大的模型，它对复杂的、用户定义的文本提示具有很好的泛化能力。

对于定量分析，我们遵循先前的工作，并在MS-COCO验证集上评估文本到图像的生成，我们的模型在这方面优于强大的AR和基于GAN的方法。我们注意到，应用无分类器的扩散引导显著提高了样本质量，使得引导的LDM-KL-8-G与最近的AR和扩散模型在文本到图像合成方面具有相当的水平，同时大幅减少了参数数量。为了进一步分析基于交叉注意力的条件化机制的灵活性，我们还训练了模型来根据OpenImages上的语义布局合成图像，并在COCO上进行微调。最后，我们根据先前的工作，评估了我们在ImageNet中最佳表现的类别条件模型。在这里，我们在超过ADM的基础上表现出色，同时显著降低了计算需求和参数数量。

### 4.4. Super-Resolution with Latent Diffusion

LDMs可以通过直接在低分辨率图像上进行条件化（参见第3.3节）来有效地进行超分辨率训练。在第一个实验中，我们按照SR3进行4×降采样，并在ImageNet上进行训练，遵循SR3的数据处理流程。我们使用在OpenImages上预训练的f = 4自编码模型（VQ-reg.，参见表8），并将低分辨率条件y与UNet的输入连接起来，即τθ为恒等映射。我们的定性和定量结果（见图10和表5）显示出竞争性的性能，LDM-SR在FID方面优于SR3，而SR3的IS更好。一个简单的图像回归模型实现了最高的PSNR和SSIM分数；然而，这些指标与人类感知不太吻合，并且倾向于模糊而不是完美对齐的高频细节。此外，我们进行了一项用户研究，将像素基线与LDM-SR进行了比较。我们按照SR3的方法，让人类主体在两张高分辨率图像之间看到一张低分辨率图像，并询问其偏好。表4中的结果证实了LDM-SR的良好性能。通过使用后处理引导机制，可以提高PSNR和SSIM，并且我们通过感知损失实现了这种基于图像的引导器，详情见第D.6节。