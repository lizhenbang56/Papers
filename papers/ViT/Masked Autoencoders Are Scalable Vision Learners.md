## 摘要 

本文表明，遮蔽自编码器（MAE）是计算机视觉中可扩展的自监督学习器。我们的MAE方法很简单：我们遮蔽输入图像的随机块，并重建缺失的像素。它基于两个核心设计。首先，我们开发了一种不对称的编码器-解码器架构，其中编码器仅对可见子块（不使用遮罩令牌）进行操作，以及一个轻量级解码器，从潜在表示和遮罩令牌中重建原始图像。第二，我们发现，遮蔽高比例的输入图像，例如75%，产生了一个非平凡且有意义的自监督任务。将这两个设计结合起来使我们能够高效而有效地训练大型模型：我们加速了训练（3倍或更多），并提高了准确性。我们的可扩展方法允许学习泛化能力强的高容量模型：例如，普通的ViT-Huge模型在仅使用ImageNet-1K数据的方法中实现了最佳准确性（87.8%）。在下游任务中的转移性能优于监督预训练，并显示出有希望的规模化行为。
## 介绍 

深度学习见证了不断增长的能力和容量的架构的爆炸性增长。在硬件迅速进步的支持下，现在的模型可以轻松地过拟合一百万张图片，并开始需要数亿的标记图片。

数据需求的增加在自然语言处理中已经成功解决了自监督预训练。基于GPT中的自回归语言建模和BERT中的遮蔽自编码的解决方案是概念上简单的：它们移除了一部分数据并学会预测被移除的内容。这些方法现在能够训练包含一百亿个参数的可泛化的NLP模型。

遮蔽自编码器的想法是更一般的去噪自编码器的一种形式，在计算机视觉中也是自然而然且适用的。实际上，在BERT之前，与计算机视觉中的遮蔽自编码器密切相关的研究在视觉上先于BERT。然而，尽管在BERT的成功之后对这个想法有了显著的兴趣，但在计算机视觉中自编码方法的进展仍然落后于自然语言处理。我们问：遮蔽自编码在视觉和语言中有何不同？我们试图从以下几个角度回答这个问题：

1. 直到最近，架构是不同的。在视觉上，卷积网络在过去的十年中占据主导地位。卷积通常在规则网格上运行，将‘指示器’（如BERT中的遮罩令牌或位置嵌入）整合到卷积网络中并不直接。然而，这个架构上的差距已经通过引入Vision Transformers（ViT）得到了解决，不应再构成障碍。
    
2. 语言和视觉之间的信息密度不同。语言是人类生成的信号，具有高度的语义和信息密度。当训练模型仅预测每个句子中少量缺失的单词时，这个任务似乎引发了复杂的语言理解。相比之下，图像是自然信号，具有重复的空间冗余——例如，可以从相邻的块中恢复缺失的块而不需要高层次的部件、对象和场景的理解。为了克服这种差异并鼓励学习有用的特征，我们展示了一种在计算机视觉中简单的策略：遮蔽非常高比例的随机块。这种策略大大减少了冗余，并创建了一个需要超越低级图像统计的整体理解的具有挑战性的自监督任务。
    
3. 自编码器的解码器，在将潜在表示映射回输入时，在重建文本和图像方面发挥不同的作用。在视觉上，解码器重建像素，因此其输出的语义级别低于常见的识别任务。这与语言不同，语言中的解码器预测包含丰富语义信息的缺失单词。虽然在BERT中解码器可能是微不足道的（一个多层感知器），但我们发现，在图像中，解码器的设计在确定学习到的潜在表示的语义级别方面起着关键作用。

由于这些分析，我们提出了一种简单、有效和可扩展的遮蔽自编码器（MAE）形式，用于视觉表示学习。我们的MAE从输入图像中遮蔽随机块，并在像素空间中重建缺失的块。它具有不对称的编码器-解码器设计。我们的编码器仅对可见子块（不使用遮罩令牌）进行操作，我们的解码器轻量级且从潜在表示中重建输入，同时使用遮罩令牌（见图1）。在我们的不对称编码器-解码器中将遮罩令牌移至小解码器会大大减少计算量。在这种设计下，非常高的遮罩比例（例如75%）可以实现双赢：它优化了准确性，同时允许编码器仅处理小部分（例如25%）的块。这可以将整体预训练时间减少3倍或更多，并减少内存消耗，使我们可以轻松将MAE扩展到大型模型。

我们的MAE学习了非常高容量的模型，具有良好的泛化能力。通过MAE预训练，我们可以在ImageNet-1K上训练数据需求量大的模型，如ViT-Large/-Huge，具有改进的泛化性能。使用普通的ViT-Huge模型，我们在ImageNet-1K上微调时实现了87.8%的准确率。这优于所有先前仅使用ImageNet-1K数据的结果。我们还评估了目标检测、实例分割和语义分割的迁移学习。在这些任务中，我们的预训练方法比其监督预训练对应方法取得了更好的结果，并且更重要的是，我们观察到通过扩展模型获得了显著的增益。这些观察结果与NLP中自监督预训练所见相一致，我们希望它们将使我们的领域能够探索类似的轨迹。

## 相关工作 

遮蔽语言建模及其自回归对应方法，例如BERT和GPT，是NLP中非常成功的预训练方法。这些方法保留了输入序列的一部分，并训练模型来预测缺失的内容。这些方法已被证明能够优秀地扩展，并且大量证据表明，这些预训练表示在各种下游任务上具有良好的泛化性能。

自编码是学习表示的经典方法。它具有将输入映射到潜在表示的编码器和将输入重建的解码器。例如，PCA和k-means是自编码器。去噪自编码器（DAE）是一类将输入信号损坏并学习重建原始未损坏信号的自编码器。一系列方法可以被认为是在不同损坏下的广义DAE，例如遮蔽像素或删除颜色通道。我们的MAE是一种去噪自编码器，但与经典的DAE在许多方面不同。

遮蔽图像编码方法是从受到遮蔽的图像中学习表示的方法。最初的工作将遮蔽作为DAE中的一种噪声类型。Context Encoder使用卷积网络对大型缺失区域进行修复。受NLP成功启发，最近的相关方法基于Transformers。iGPT在像素序列上操作并预测未知像素。ViT论文研究了用于自监督学习的遮蔽块预测。最近，BEiT提出了预测离散令牌。

自监督学习方法在计算机视觉中引起了极大的兴趣，通常侧重于不同的预文本任务进行预训练。最近，对比学习已经变得流行，例如，建模两个或多个视图之间的图像相似性和不相似性（或仅相似性）。对比和相关方法强烈依赖于数据增强。自编码追求一个概念上不同的方向，并且如我们将要展示的，它表现出不同的行为。
