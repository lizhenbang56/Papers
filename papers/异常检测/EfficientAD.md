---
Publish: WACV2024
Url: https://arxiv.org/pdf/2303.14535.pdf
Title: "EfficientAD: Accurate Visual Anomaly Detection at Millisecond-Level Latencies"
创新点: 速度快
Year: "2023"
Month: "03"
Stars: "184"
代码: https://github.com/nelson1425/EfficientAD
---
## 摘要 

在图像中检测异常是一项重要任务，特别是在实时计算机视觉应用中。在这项工作中，我们专注于计算效率，并提出了一种轻量级特征提取器，能够在现代GPU上处理一幅图像不到一毫秒的时间。然后，我们采用**师生模型**方法来检测异常特征。我们训练一个**学生网络**来预测正常图像的特征。在测试时，通过学生网络无法预测异常特征，从而实现异常的检测。

我们提出了一个训练损失，阻碍**学生网络**在正常图像之外模仿 teacher feature extractor。这使得我们能够大幅降低师生模型的计算成本，同时提高异常特征的检测能力。

我们进一步解决了检测具有挑战性的逻辑异常的问题，这些异常涉及正常局部特征的无效组合，例如对象顺序错误。我们通过有效地整合全局分析图像的自编码器来检测这些异常。我们在来自三个工业异常检测数据集集合的32个数据集上评估了我们的方法，称为EfficientAD。EfficientAD为异常的检测和定位都设立了新的标准。在每秒600幅图像的吞吐量和两毫秒的延迟下，它实现了对异常的快速处理。加上其低错误率，这使其成为现实应用的经济解决方案，也为未来的研究奠定了丰富的基础。

## 1. 引言 

在过去的几年里，深度学习方法持续改善了各种计算机视觉应用的最新技术。这一进步伴随着神经网络架构的加速和更高效的发展。现代分类架构，例如，专注于特征提取、吞吐量、内存消耗和可训练参数数量等特性。这确保了随着网络变得更加强大，它们的计算需求仍适用于实际应用。视觉异常检测领域近年来也取得了快速进展，尤其是在工业异常检测基准上。然而，最先进的异常检测方法通常牺牲了计算效率以换取更高的异常检测性能。常见的技术包括集成、使用大型主干网络和将输入图像分辨率增加到768×768像素。

现实世界中的异常检测应用经常对方法的计算要求施加限制。有些情况下，过晚地检测到异常会导致重大的经济损失，例如金属物体进入谷物收割机内部。在其他情况下，甚至会危及人类健康，例如机械操作员的肢体接近刀片。此外，工业环境通常涉及严格的运行时间限制，这是由于高产量造成的。不遵守这些限制会降低相应应用的生产率，从而降低其经济可行性。因此，关注异常检测方法的计算和经济成本是保持其适用于实际应用的重要因素。

在这项工作中，我们提出了EfficientAD，这是一种为异常检测性能和推断运行时间设定新标准的方法。我们首先介绍了一种高效的网络架构，能够在现代GPU上以不到一毫秒的时间计算出丰富的特征。为了检测异常特征，我们采用了师生模型方法。我们训练一个学生网络来预测经过预训练的老师网络在正常图像上计算出的特征。由于学生没有在异常图像上进行训练，它通常无法模仿老师的行为。因此，老师和学生之间的输出之间的巨大差异使得在测试时能够检测到异常。为了进一步增加这种效果，我们提出了一种通过训练损失来阻碍学生在正常图像之外模仿老师的不对称性。这种损失不会影响测试时的计算成本，也不会限制架构设计。它使我们能够在学生和老师之间都使用高效的网络架构，同时提高异常特征的检测能力。

识别异常的局部特征使得可以检测到在结构上与正常图像不同的异常，例如制造产品上的污染或污渍。然而，一个具有挑战性的问题是违反关于位置、大小、排列等正常对象的逻辑约束。为了解决这个问题，EfficientAD包括一个自编码器，它学习训练图像的逻辑约束，并在测试时检测违规行为。我们展示了如何有效地将自编码器与师生模型结合起来。此外，我们提出了一种通过校准自编码器和师生模型的检测结果来提高异常检测性能的方法。

我们的贡献总结如下： 
• 我们在工业基准上显著改进了异常检测和定位的最新技术，在每秒600幅图像的吞吐量和2毫秒的延迟下。
• 我们提出了一种高效的网络架构，使特征提取速度比最近方法中使用的特征提取器提高了一个数量级。
• 我们引入了一种训练损失，显著提高了师生模型的异常检测性能，而不影响推断运行时间。 • 我们实现了基于高效自编码器的逻辑异常检测，并提出了一种校准自编码器和师生模型检测结果的方法。

## 相关工作 

### 2.1. 异常检测任务 

视觉异常检测是一个快速发展的研究领域，涵盖了各种应用，包括医学成像、自动驾驶和工业检测。这些应用通常具有特定的特征，例如监视数据集中的图像序列或医学成像数据集（MRI、CT、X射线等）的不同模态。本工作侧重于在RGB或灰度图像中检测异常，而不是基于图像序列的预测。我们使用工业异常检测数据集来将我们提出的方法与现有方法进行对比。 MVTec AD数据集的引入促进了针对工业应用的方法的发展。它包括15个单独的检测场景，每个场景包含一个训练集和一个测试集。每个训练集仅包含正常图像，例如无缺陷的螺钉，而测试集还包含异常图像。这在实际应用中经常是一个挑战，因为在开发异常检测系统时，缺陷的类型和可能的位置是未知的。因此，方法在仅在正常图像上进行训练时表现良好是一个具有挑战性但至关重要的要求。 最近，引入了几个新的工业异常检测数据集。例如，Visual Anomaly (VisA)数据集和MVTec Logical Constraints (MVTec LOCO)数据集遵循MVTec AD的设计，分别包含十二个和五个异常检测场景。它们包含的异常比MVTec AD中的异常更具挑战性。此外，MVTec LOCO不仅包含结构性异常（如污渍或划痕），还包含逻辑异常，即逻辑约束的违反，例如对象的错误排序或错误组合。我们将MVTec AD、VisA和MVTec LOCO称为数据集集合，因为每个场景都是一个单独的数据集，包含一个训练集和一个测试集。这三个数据集提供了用于评估方法异常定位性能的像素精确的缺陷分割掩码。 

### 2.2. 异常检测方法 

传统的计算机视觉算法已经成功应用于工业异常检测任务数十年[62]。这些算法通常要求在几毫秒内处理一幅图像。Bergmann等人评估了一些这样的方法，发现当要求如良好对齐的对象未满足时，它们会失败。已经证明，基于深度学习的方法可以更稳健地处理这些情况。 最近一种成功的方法是在预训练和冻结的卷积神经网络（CNN）的特征空间中应用异常值检测和密度估计方法。如果特征向量可以映射到输入像素，将其异常值分配给相应的像素将产生像素异常分数的二维异常地图。常见的方法包括多元高斯分布、高斯混合模型、正态流以及k最近邻算法。基于k最近邻的方法在推断过程中搜索最近邻时会遇到运行时瓶颈。因此，Roth等人通过在聚类特征向量的减少数据库上执行k最近邻，实现了对MVTec AD的最先进的异常检测结果。在我们的实验中，我们包括了PatchCore和FastFlow，后者是一种最近提出的基于正态流的方法，具有相对较低的推断运行时。 Bergmann等人提出了一种师生（S-T）框架用于异常检测，其中老师是一个预训练的冻结的CNN。他们训练学生网络在训练图像上模仿老师的输出。由于学生在训练期间未见过异常图像，它们通常无法预测这些图像上的老师的输出，从而实现了异常检测。已经提出了多种S-T的修改。Rudolph等人通过限制老师是一个可逆神经网络，在MVTec AD上实现了竞争性的异常检测性能。我们将我们的方法与他们的不对称师生方法以及原始的S-T方法进行了对比。 生成模型如自编码器和GAN已广泛用于异常检测。最近的自编码器方法依赖于正常图像的准确重构和异常图像的不准确重构。这使得可以通过将重构与输入图像进行比较来检测异常。常见的问题是由于正常图像的不准确重构而导致的假阳性检测。为了避免这种情况，GCAD让一个自编码器在预训练网络的特征空间中重构图像。另一个最近的基于重构的方法是DSR，它使用预训练自编码器的潜在空间，并在其中生成合成异常。在我们的实验中，我们包括了GCAD、DSR和SimpleNet。

## 3. 方法

我们在以下小节中描述EfficientAD的组成部分。它始于第3.1节中对预训练神经网络进行高效特征提取的方法。我们使用EfficientAD-S的图2中显示的网络架构，以完全卷积的方式将其应用于图像，从而在单个前向传递中产生所有特征。在第3.2节中描述了在测试时使用轻量级师生模型检测异常特征。一个关键挑战是在保持整体运行时低的情况下实现竞争性的异常检测性能。为此，我们引入了一个新颖的损失函数来训练师生模型。在第3.3节中，我们解释了如何使用基于自动编码器的方法高效检测逻辑异常。最后，在第3.4节中，我们提供了一个解决方案，用于校准和结合自动编码器的检测结果与师生模型的检测结果。

### 3.1. 高效的Patch描述符 

最近的异常检测方法通常使用深度预训练网络的特征，例如WideResNet-101。我们使用一个深度大大减小的网络作为特征提取器。它仅包含四个卷积层，如图2所示。每个输出神经元具有一个33×33像素的感受野，因此每个输出特征向量描述一个33×33的图像块。由于这种明确的对应关系，我们将该网络称为Patch描述网络（PDN）。PDN是完全卷积的，可以应用于可变大小的图像，在单个前向传递中生成所有特征向量。S-T方法也使用了具有少量卷积层的网络的特征。尽管这些网络的计算成本很高，但由于卷积和池化层中缺乏下采样，这些网络的计算成本很高。S-T使用的网络的参数数量相对较低（每个网络在1.6到2.7百万之间）。然而，在我们的实验中，执行单个网络比GCAD方法中使用的具有3100万参数的U-Net需要更长的时间并且需要更多的内存。这表明参数数量可能是一种误导性的代理指标，用于方法的延迟、吞吐量和内存占用。现代分类架构通常在早期进行下采样，以减小特征图的大小，从而减少运行时和内存需求。我们通过在第一和第二个卷积层后引入步幅平均池化层来实现这一点。使用提出的PDN，我们能够在NVIDIA RTX A6000 GPU上以少于800 µs的时间获得大小为256×256的图像的特征。

### 3.2. 轻量级师生模型 

为了检测异常特征向量，我们使用了师生（S-T）方法，其中 teacher 由我们提炼的PDN给出。由于我们可以在一毫秒内执行PDN，我们也使用其架构作为学生，从而实现低整体延迟。然而，这种轻量级的师生配对缺乏以前方法中用于提高异常检测性能的技术：使用多个师傅和学生进行集成，使用来自层金字塔的特征，并且使用学生和教师网络之间的架构不对称。因此，我们引入了一个训练损失，它在不影响测试时的计算需求的情况下显著改善了异常检测。

我们观察到，在标准S-T框架中，增加训练图像的数量可以提高 student 在异常上模仿 teacher 的能力。这会降低异常检测性能。同时，故意减少训练图像的数量可能会压制关于正常图像的重要信息。

我们的目标是向学生展示足够的数据，以便它可以在正常图像上充分模仿 teacher，同时避免将模仿泛化到异常图像。

类似于在线困难样本挖掘，我们因此将学生的损失限制在图像的最相关部分。这些是学生当前模仿师傅最少的区域。我们提出了一个硬特征损失，它仅使用具有最高损失的输出元素进行反向传播。

形式上，我们将教师T和学生S应用于训练图像I，从而产生T(I) ∈ R C×W×H和S(I) ∈ R C×W×H。我们计算每个元组（c，w，h）的平方差作为Dc,w,h = (T(I)c,w,h − S(I)c,w,h) 2 。基于挖掘因子phard ∈ [0, 1]，然后计算D的元素的phard分位数。给定phard分位数dhard，我们计算训练损失Lhard，其为所有Dc,w,h ≥ dhard的均值。在我们的实验中，我们将phard设置为0.999，这相当于在每个维度上平均使用十分之一的D值进行反向传播。图4可视化了phard = 0.999的硬特征损失的效果。在推理过程中，2D异常评分图M ∈ RW×H由Mw,h = C −1 P c Dc,w,h给出，即D在通道上的平均。它为每个特征向量分配一个异常评分。通过使用硬特征损失，我们避免了正常图像上异常评分中的异常值，即错误的正检测。除了硬特征损失外，我们在训练期间还使用损失惩罚，进一步阻止学生在不属于正常训练图像的图像上模仿师傅。在标准S-T框架中，师傅是在图像分类数据集上预训练的，或者它是这样一个预训练网络的精炼版本。学生没有在该预训练数据集上进行训练，而只在应用程序的正常图像上进行训练。我们建议还在训练学生时使用来自师傅预训练的图像。具体来说，在每个训练步骤中从预训练数据集（在我们的情况下是ImageNet）中随机采样一个随机图像P。我们将学生的损失计算为LST = Lhard + (CWH) −1 P c ∥S(P)c∥ 2 F。这个惩罚阻止了学生将其对师傅的模仿泛化到分布之外的图像。

### 3.3. 逻辑异常检测 

逻辑异常有许多类型，如缺失、错位或多余的对象或违反几何约束，例如螺钉的长度。根据MVTec LOCO数据集的作者的建议，我们使用自动编码器学习训练图像的逻辑约束，并检测这些约束的违反。图5描述了EfficientAD的异常检测方法。它包括前述的师生配对和一个自动编码器。自动编码器被训练来预测师傅的输出。形式上，我们将自动编码器A应用于训练图像I，得到A(I) ∈ R C×W×H，并计算损失LAE = (CWH) −1 P c ∥T(I)c − A(I)c∥ 2 F。我们使用标准的卷积自动编码器，其中编码器中使用步幅卷积，解码器中使用双线性上采样。与基于Patch的学生不同，自动编码器必须通过64个潜在维度的瓶颈对完整图像进行编码和解码。在具有逻辑异常的图像上，自动编码器通常无法为在师傅特征空间中重建图像的正确潜在代码。然而，在正常图像上，自动编码器的重构也存在缺陷，因为自动编码器通常难以重构细粒度的模式。在图5的背景网格中就是如此。使用师傅输出和自动编码器重构之间的差异作为异常映射会导致这些情况下的假阳性检测。因此，我们在学生网络中增加了输出通道的数量，并训练它在预测师傅输出的同时还能预测自动编码器的输出。设S ′ (I) ∈ R C×W×H为学生的额外输出通道。学生的额外损失为LSTAE = (CWH) −1 P c ∥A(I)c − S ′ (I)c∥ 2 F。总的训练损失是LAE、LST和LSTAE的总和。学生学习了自动编码器在正常图像上的系统性重构错误，例如模糊的重构。同时，它不会学习异常的重构错误，因为这些不是训练集的一部分。这使得自动编码器输出和学生输出之间的差异非常适合计算异常映射。类似于师生配对，异常映射是两个输出之间的平方差的平均值。我们将这个异常映射称为全局异常映射，将学生-师傅配对生成的异常映射称为局部异常映射。我们将这两个异常映射平均以计算组合异常映射，并使用其最大值作为图像级别的异常评分。因此，组合异常映射包含了师生配对的检测结果和自动编码器-学生配对的检测结果。在计算这些检测结果时使用学生的隐藏层使得我们的方法能够保持低计算要求，同时实现结构和逻辑异常的检测。

### 3.4. 异常映射归一化 

在将局部和全局异常映射平均以获得组合异常映射之前，必须将它们归一化到相似的比例。这对于仅在其中一个映射中检测到异常的情况非常重要，例如在图5中。否则，一个映射中的噪声可能使另一个映射中的准确检测在组合映射中不可辨认。为了估计正常图像上噪声的尺度，我们使用验证图像，即训练集中未见的图像。对于两种异常映射类型中的每一种，我们计算跨验证图像的所有像素异常分数的集合。然后，我们为每个集合计算两个p-分位数：qa和qb，分别对应于p = a和p = b。我们确定一个线性变换，将qa映射到异常评分为0，将qb映射到0.1的评分。在测试时，局部和全局异常映射使用相应的线性变换进行归一化。通过使用分位数，归一化变得对正常图像上异常评分的分布变化变得鲁棒，这些评分可以在不同的场景之间变化。是否在qa和qb之间的分数遵循正态分布，或者是高斯混合或遵循另一种分布，都不会影响归一化。我们的实验包括关于a和b值的消融研究。选择映射目标值0和0.1对异常检测指标（如ROC曲线下面积）没有影响。这是因为AU-ROC仅取决于分数的排名，而不取决于它们的比例。我们选择0和0.1是因为它们产生了适用于标准从零到一的颜色尺度的映射。