---
Publish: CVPR2024
Url: https://arxiv.org/pdf/2404.05231.pdf
Year: "2024"
Title: "PromptAD: Learning Prompts with only Normal Samples for Few-Shot Anomaly Detection"
创新点: CLIP
Month: "04"
---
- 单类，无监督，小样本

## 摘要

视觉语言模型已经极大地改进了少样本工业异常检测，通常需要通过提示工程设计数百个提示。对于自动化场景，我们首先使用传统的多类别范式下的提示学习作为基线，自动学习提示，但发现在单类别异常检测中效果不佳。为解决上述问题，本文提出了一种用于少样本异常检测的单类别提示学习方法，称为PromptAD。首先，我们提出了语义连接，通过将正常提示与异常后缀连接起来，将正常提示转置为异常提示，从而构建大量负样本，用于引导单类别设置中的提示学习。此外，为了缓解由于缺乏异常图像而带来的训练挑战，我们引入了显式异常边界的概念，该边界用于通过超参数明确控制正常提示特征与异常提示特征之间的边界。对于图像级/像素级异常检测，PromptAD 在 MVTec 和 VisA 上的 11/12 个少样本设置中均取得第一名。代码可在 [https://github.com/FuNz0/PromptAD.git](https://github.com/FuNz0/PromptAD.git) 获取。

## 引言 

异常检测（AD）是计算机视觉中的一个关键任务，在工业和医学中有着广泛的应用，例如在工业生产和医学影像中的缺陷检测。本文关注无监督工业异常检测，这是一个被称为单类别分类（OCC）的挑战。在这种框架中，训练阶段仅有正常样本可用，但在测试阶段，模型需要识别异常样本。由于工业异常检测通常需要为各种工业生产线定制模型，因此快速使用少样本训练模型的能力对实际应用具有重要意义。

由于基础模型具有强大的零样本能力，WinCLIP 被提出作为第一个利用视觉语言基础模型（即 CLIP）来增强模型在少样本设置中的异常检测性能的工作。为了更好地利用提示引导，WinCLIP 引入了一种名为“提示集合”的提示工程策略，将足够数量的手动设计提示组合在一起。其他方法如 SAA+ 和 AnoVL 也利用提示工程来增强模型性能，这已成为提示引导异常检测的惯例。然而，提示工程涉及人为干预，需要仔细设计，这不符合工业场景的自动化要求。

提示学习旨在通过对比学习自动学习提示来指导图像分类。提示学习用于异常检测的想法很有趣。然而，由于异常检测的单类别设置，使用上述提示学习范式作为基线效果不佳，且不如在图像级结果上使用手动提示的 WinCLIP。本文提出了单类别提示学习方法 PromptAD，以解决上述挑战。为了解决第一个挑战，我们提出了语义连接（SC）。直观地，通过将提示与反义文本连接起来，可以转置其语义。此外，在异常检测中，由于异常样本不可用，无法通过对比损失显式控制正常和异常提示特征之间的边界。为了解决第二个挑战，我们提出了显式异常边界（EAM）的概念，其中引入了一个超参数，以确保正常特征与正常提示特征之间的距离小于正常特征与异常提示特征之间的距离。因此，确保正常提示和异常提示之间有足够的边界。总之，本文的主要贡献是探索了单类别异常检测中提示学习的可行性，并提出了一种称为 PromptAD 的单类别提示学习方法，彻底击败了传统的多类别提示学习方法。语义连接（SC）被提出，可以通过连接异常后缀来转置正常提示的语义，从而为正常样本构建足够的负提示。显式异常边界（EAM）被提出，可以通过超参数明确控制正常提示特征和异常提示特征之间的距离。对于图像级/像素级异常检测，PromptAD 在 MVTec 和 VisA 上的 11/12 个少样本设置中均取得第一名。

## 相关工作

视觉语言模型。利用对比学习和视觉变换器，一些视觉语言模型（VLM）近年来取得了巨大成功。CLIP是其中最常用的VLM之一，它在网络规模的图文数据上进行训练，并展现出强大的零样本分类能力。CLIP的代码在LAION-400M和LAION-5B规模的预训练中是开放的。通过预训练的CLIP和提示工程师，一些下游任务取得了巨大的进展。受自然语言处理（NLP）中提示学习的成功启发，最近出现了一大批用于少样本图像分类任务的提示学习方法。这些方法旨在通过对比学习自动学习更好的提示，以引导基于CLIP的图像分类。

异常检测。大多数异常检测方法主要关注三种范式：特征嵌入范式、知识蒸馏范式和基于重建的范式。特征嵌入范式通过神经网络提取图像的补丁特征，然后进行异常检测。知识蒸馏范式让学生网络仅学习教师网络的正常样本知识，并通过教师网络和学生网络之间的差异完成异常检测。重建范式希望模型能够将异常图像重建成正常图像，并通过重建图像与异常图像之间的差异来实现异常检测。

少样本异常检测。TDG和RegAD是首次探索少样本异常检测方法的方法，PatchCore和DifferNet也展示了在少样本设置中的性能。WinCLIP和RWDA将CLIP模型引入异常检测，并在少样本设置中极大地提高了性能。最新的FastRecon通过回归与分布正则化重建异常特征，并取得了出色的性能。

## 初步

### 3.1. CLIP 和提示学习 

对比语言图像预训练，简称 CLIP [37]，是一种大规模的视觉语言模型，以其零样本分类能力而闻名。具体而言，给定一个未知图像 $\textbf{i}$，以及 $K$ 个文本提示 $\{\textbf{s}_1, \textbf{s}_2, \cdots, \textbf{s}_K\}$，CLIP 可以预测 $\textbf{i}$ 属于这 $K$ 个文本提示的分布：p(y|i) = exp < f(i), g(sy)/τ > / PK i=1 exp < f(i), g(si)/τ > , (1) 其中 f(·) 和 g(·) 分别是视觉和文本编码器。< ·, · > 表示余弦相似度，τ 是温度超参数。

用于 CLIP 零样本分类的初始文本提示仍然很简单，比如一个[class]的照片等，略好于直接使用类名作为提示。 

【Prompt Learning】受自然语言处理（NLP）中提示学习的成功启发，CoOp [59] 将这一范式引入到少样本分类中，旨在自动学习有效的提示来提高 CLIP 在下游分类任务上的性能。具体而言，CoOp 中使用的提示不是冻结的文本描述，而是一组可训练的参数： sk = [P1][P2] . . . [PEP ][classk], (2) 其中 [P1][P2] . . . [PEP ] 是可训练的标记，[classk] 是第 k 个类别的名称，不可训练。提示学习旨在自动训练有效的提示，以改善 CLIP 在下游分类任务上的性能。
### 3.2. CLIP 手术 

作为一个分类模型，没有经过微调的 CLIP 在引导图像定位任务中远不如人。为了弄清楚为什么 CLIP 无法完成图像定位任务，一些 CLIP 可解释性研究 [31, 57] 分析了 CLIP 提取视觉特征的机制。这些研究观察到 Q-K 自注意力的全局特征提取影响了 CLIP 的定位能力，具体如下： Attn(Q, K, V) = sof tmax(Q · K T · scale) · V. (3) 为此，CLIP-Surgery [31] 提出了一种 V-V 注意机制，可以增强模型对局部特征的关注，而不破坏原始结构。如图 2 所示，特征提取过程描述如下： Z l−1 ori = [tcls; t1; t2, ...; tT ], (4) Z l−1 = [t ′ cls; t ′ 1 ; t ′ 2 , ...; t ′ T ], (5) [Q l , K l , V l ] = QKV P roj.l (Z l−1 ori ), (6) Z l = P roj.l (Attn(V l , V l , V l )) + Z l−1 , (7) 其中 Z l−1 ori 表示原始 CLIP 视觉编码器的 (l − 1) 层输出，Z (l−1) 表示第 l − 1 层的局部感知输出，QKV P roj.l 和 P rojl 表示由原始 CLIP 的视觉编码器参数初始化的 QKV 投影和输出投影。最终的原始输出和局部感知输出分别为 Zori 和 Z，CLS 特征 Zori[0] ∈ R d 用于图像级别的异常检测，局部特征图 Z[1 :] ∈ R T ×d 用于像素级别的异常检测。在本文中，我们将修改后的 CLIP 作为骨干，并称之为 VV-CLIP。

## 4. 方法论 

### 4.1. 概述 

我们提出的 PromptAD 概述如图 2 所示。PromptAD 建立在 VV-CLIP 上，其视觉编码器用于提取全局和局部特征。我们提出的语义串联（SC）用于设计提示。具体而言，N 个可学习的 normal prefixes 和 objective name 连接在一起以获取 normal prompts（NPs），然后 N 个 normal prompts 分别与 M 个 manual anomaly suffixes 和 L 个可学习 anomaly suffixes 连接在一起，以获得 N×M 个 manual anomaly prompt（MAPs）和 N×L 个可学习 anomaly prompts（LAPs）。通过对比损失和提出的显式异常边界（EMA）损失来利用 visual features 和 prompt features 完成提示学习。EMA 可以通过超参数控制 normal prompt features 和 anomaly prompt features 之间的显式边界。最后，通过提示学习得到的提示用于提示引导的异常检测（PAD）。

除了 PAD 外，我们还引入了基于视觉引导的异常检测（VAD），参考 WinCLIP+ [21]。具体而言，如图 2 所示，在训练期间，由视觉编码器输出的第 i 层特征（不包括 CLS 特征）被存储为表示正常视觉记忆的 R。在测试阶段，查询图像的第 i 层特征图 F ∈ R h×w×d 与 R 进行比较，以获得异常分数图 M ∈ [1, 0]h×w： Mij = min r∈R 1 2 (1− < Fij , r >)。 在实践中，我们使用两个层的中间特征作为记忆，为每个查询图像获取两个分数图，然后平均这两个分数图以获得最终的基于视觉引导的分数图 Mv。

#### 4.2. 语义串联 

在异常检测**训练**过程中，**只有正常样本可用**，这导致没有负样本来指导提示学习，从而削弱了其效果。我们发现通过串联可以改变提示的语义。例如，a photo of cable 具有正常语义，在将其与后缀串联后，a photo of cable with flaw 就转换为异常语义。因此，我们提出了语义串联（SC）方法，通过将 normal prompts 与 anomaly suffixes 串联起来，将 normal prompts 转置为 anomaly prompts，以便基于可学习的正常提示构建足够的对比提示。具体而言，遵循 CoOp [59] 的格式，可学习的正常提示（NP）设计如下：...

将可学习的正常提示与异常后缀串联后，可以将其转换为异常提示。特别地，我们从数据集的异常标签中生成异常后缀，例如，`[] with color stain, [] with crack` 等，然后将这些文本与 NP 连接以获得 manual anomaly prompt（MAP）：...

备注：在单类异常检测中，传统的提示学习只能设计可学习的正常提示，这不利于对比损失的效果。所提出的语义串联可以将正常提示的语义转换为具有共享参数的异常语义，使得正常样本与语义转置（异常提示）形成对比。

### 4.3. 显式异常边界

由于训练中缺乏异常视觉样本，MAPs 和 LAPs 只能将 normal visual features 作为负样本进行对比，缺乏正常和异常提示之间的显式边界。因此，我们提出了显式异常边界（EAM）用于 AD 提示学习，它可以控制 normal prompt features和 anomaly prompt features 之间的边界。EAM 实际上是通过边界超参数实现的正则化损失，其定义如下：...

### 4.4. 异常检测

在测试阶段，通过以下公式计算图像级别得分 $\textbf{S}_t \in [0,1]$：$$score = \frac{\exp\langle\textbf{z}_t, \bar{\textbf{w}}^n /\tau \rangle}{\exp \langle\textbf{z}_t, \bar{\textbf{w}}^n / \tau\rangle + \exp  \langle\textbf{z}_t, \bar{\textbf{w}}^a / \tau\rangle}$$其中 $\textbf{z}_t$ 是图像特征。$\bar{\textbf{w}}^n$ 是 normal prototype。$\bar{\textbf{w}}^a$ 是 anomaly prototype。