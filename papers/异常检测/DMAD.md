---
Publish: arXiv2024
监督方式: 有监督
Year: "2024"
文档链接: "[[2403.12362 DMAD.pdf]]"
合成异常的方式: 在正常图像特征上添加噪声
类别数: 多类
Month: "03"
方法类别: 基于异常图像显式监督
创新点: 若有异常训练图像，则显式监督；若无异常训练图像，则在正常图像的特征空间添加噪声作为伪负样本。
I-AUROC-MVTecAD多类无监督: "96.3"
I-AUROC-MVTecAD多类半监督: "99.0"
P-AUROC-MVTecAD多类无监督: "97.2"
P-AUROC-MVTecAD多类半监督: "98.2"
---
现有的异常检测方法仅使用正常样本进行训练，忽视了真实场景中能够获取的非常少量但是非常重要的异常样本。
本文将异常检测算法分类两类：
- 无监督的和半监督的。
- 统一的（多类）和分离的（单类）

|     | 无监督                                   | 半监督                                                                                              |
| --- | ------------------------------------- | ------------------------------------------------------------------------------------------------ |
| 统一  | [[UniAD]]<br>[[OmiAL]]                | [[DMAD]]                                                                                         |
| 分离  | [[RDA]]<br>[[PaDiM]]<br>[[SimpleNet]] | [[DRA]]<br>[[PRNet]]<br>[[BGAD]] |

#### 参考文献
[[DeepSAD]]
[[DRA]]
[[PRNet]]
[[BGAD]]

# 摘要

训练统一模型被认为更适合实际工业异常检测场景，因为它具有泛化能力和存储效率。然而，这种多类别设置仅使用正常数据，忽略了现实世界中少量但重要的可访问注释异常。为了解决现实世界异常检测的挑战，我们提出了一个名为双存储增强表示学习的异常检测框架（DMAD）。该框架在统一（多类别）设置中处理无监督和半监督场景。DMAD采用双存储库来计算正常和异常模式之间的特征距离和特征注意力，从而封装了关于正常和异常实例的知识。然后，利用这些知识构建了用于异常评分学习的增强表示。我们在MVTec-AD和VisA数据集上评估了DMAD。结果表明，DMAD超越了当前最先进的方法，突显了DMAD在处理现实世界异常检测场景复杂性方面的能力。代码将会公开提供。

# 引言

图像异常检测（Image Anomaly Detection），也称为表面缺陷检测（Surface Defect Detection），是一种将图像分类为正常和异常类别，并在像素级别确定异常的过程。基于深度学习的异常检测方法相较于手动异常定位表现出更高的效率。目前主流的方法通常为每个对象训练一个独特的模型，如图1（a）左下角所示。然而，随着对象类别数量的快速增长，这种方法导致了存储消耗的增加。为了解决这个问题，UniAD [25]提出了一个多类别设置，利用所有对象的正常数据来训练一个统一的模型，如图1（a）左上角所示。此外，在假设异常数据不可用的情况下，当前的异常检测方法 [6, 14, 23, 31] 主要依赖于无监督学习。它们明确定义了正常数据的边界，如图1（a）左侧所示。然而，由于在训练过程中缺乏真实的异常数据，特别是在处理轻微缺陷时，这些边界可能缺乏足够的准确性。最近的研究 [8,16,24,28] 表明，在现实世界的情况下获取少量的异常是可行的。这些半监督方法，如图1（a）右下角所示，可以帮助模型预测潜在的异常模式并增强其性能。在我们的提议中，针对现实世界的异常检测，训练一个统一的模型更加合适。此外，除了无监督场景外，还需要考虑半监督场景，其中提供了少量注释的异常。我们将这种带有少量注释异常的新统一设置称为统一半监督设置，如图1（a）右上角所示。这种新设置填补了研究空白。

在统一半监督设置下，模型利用所有对象类别的数据，包括正常数据、可见异常数据以及它们的对应监督信息进行训练。这种方法具有几个优点。首先，它与实际情况更加贴近，因为总是有一些注释的异常可供使用。其次，这种设置更加统一和方便，因为所有数据，包括注释，都由一个单一模型利用。第三，我们观察到在不同对象类别中存在视觉上的常见缺陷，如图1（b）所示。通过采用这种设置进行异常检测，这些相似的缺陷可以在训练过程中提供额外的优势。这种设置的挑战在于准确地建模多类别分布，同时避免对可见异常过拟合，并有效利用可见异常。为了解决这个问题，我们提出了一个新颖的框架：双存储增强表示学习的异常检测（DMAD）。DMAD不仅适用于统一半监督设置，还适用于一般统一（多类别）设置，其中没有可用的注释异常。这使得它非常适用于现实世界的异常检测，其中异常可能最初不可访问。然而，随着系统的运行，某些注释的异常可能会出现以供使用。

具体来说，DMAD首先利用一个补丁特征编码器提取补丁特征。为了建立一个统一的决策边界，构建了一个双存储库，包括一个正常存储库和一个变量异常存储库。在无监督情况下，从正常和异常特征的特征融合中生成的伪异常特征集被用作异常存储库。在半监督场景中，为了缓解数据不平衡，我们采用了异常中心采样策略。该策略扩展了异常存储库，补充了观察到的异常和伪异常特征集。双存储库计算了补丁特征与其在两个存储库中最近特征之间的距离和交叉注意力，创建了关于正常数据和异常数据的知识库。特征本身及其两个计算出的知识组成了一个增强表示。最后，我们使用多层感知器（MLP）来学习这个表示与异常分数之间的映射。

总之，我们的贡献如下：

1. 为了解决实际世界的异常检测问题，包括通用统一设置和统一半监督设置，我们提出了一个基于双存储库的新框架，名为DMAD。DMAD利用正常存储库和可变异常存储库来处理这两种情况。
2. 为了有效利用双存储库，我们引入了一个知识增强模块。该模块计算距离和交叉注意力，形成一个知识表示，有助于改进异常分数的学习。
3. 我们在MVTec-AD和VisA数据集上进行了大量实验。结果表明，我们的模型在各种设置下明显优于当前最先进的竞争对手。

# 相关工作

## Multi-class Unsupervised Anomaly Detection

大多数方法提出为不同类别的对象训练单独的模型。然而，在实际的应用场景中，类内或类间的数量可能非常大，单独训练的方法变得不太合适且消耗内存。在其中，[[UniAD]] 首次提出使用统一框架从不同对象中检测异常。与此同时，UniAD 引入了一个逐层查询解码器到变压器框架中，以削弱**基于重构的方法**特别是在统一设置中的“相同快捷方式”问题。OmniAL [30] 通过使用面板引导的合成异常数据改进了异常合成、重构和定位。这些方法在实际应用中很方便，因为它们使用了一个可以覆盖所有对象的统一模型。然而，它们不能利用缺陷来增强性能。在本文中，我们提出了DMAD，它可以建模多类分布并有效利用可用的异常。

# 方法

**问题陈述**    在实际工业场景中，训练一个统一模型被认为更加兼容和存储效率更高。统一的异常检测系统同时面临两种情况：通用的统一（多类别）设置 [25] 和一个带有少量注释异常的统一设置，可以称为统一半监督设置。这种双重情况取决于异常的可用性。在通用的统一设置中，模型的训练集表示为 Xtrain = {X i n}Mi=1。这里，M表示数据集中的对象数量，而Xn表示正常数据。当一些注释异常变得可用时，设置转换为统一半监督，并且训练集变为 Xtrain = {X i n}Mi=1 ∪ {X i as}Mi=1。Xas表示已见的注释异常。目标是训练一个统一的神经网络，表示为 m：X → R，能够将异常分配给异常的得分高于正常实例。对于实际世界的异常检测，模型需要适应这两种设置。

**概述**    我们提出了一个名为双存储增强表示学习的异常检测（DMAD）的新框架，旨在解决实际世界异常检测的挑战。DMAD是一个统一的模型，不仅利用正常数据进行训练，而且有效地利用可访问的异常。DMAD的概述可以在图2中找到。DMAD主要由三个组件组成：
- 补丁特征编码器（第3.1节）
- 基于双存储库的知识增强（第3.2节）
- 异常分数映射器（第3.3节）

接下来，我们将详细介绍这三个组件。

## Patch Feature Encoder

Patch Feature Encoder由特征提取器 $F_\varPhi : x \to q$ 和可选的特征过滤器操作 $Filter$ 组成。特征提取器 $F_\varPhi$ 用于从图像中提取补丁特征，其中包括一个预训练的主干网络和一个聚合操作。训练图像表示为 $x \in \mathbb{R}^{3 \times H \times W}$，补丁特征表示为 $q \in \mathbb{R}^{N \times C}$。这里，$N = H_0 \times W_0$，$H_0$ 和 $W_0$ 分别表示特征的高度和宽度，$C$ 表示特征通道数。

对于一个普通的统一设置，只能使用正常数据，对于每个正常图像xn，我们直接获得其补丁特征qn：$q_n=F_{\Phi }(x_n)$

随着检测系统的运行，一些已注释的异常变得可访问，并可以纳入DMAD的训练中。对于每个已见异常xas，我们另外使用Filter操作从其提取的补丁特征FΦ(xas)中分离出异常部分。之所以采用Filter，是因为我们观察到图像缺陷通常只占图像的一小部分，需要被过滤掉。我们在第4.5节进行了消融实验，以说明Filter的重要性。更具体地说，我们将有缺陷图像的注释表示为y ∈ {0, 1}1×H×W。如果图像中的位置(h, w)是正常的，则y(h, w) = 0；否则，y(h, w) = 1。我们最初使用双线性插值来缩放y以匹配特征的分辨率，然后过滤掉相应的异常部分。因此，对于每个**有缺陷的图像** $x_a$，我们可以计算其**异常的补丁特征** $q_a \in \mathbb{R}^{N_f \times C}$：$$q_a=Filter(F_{\Phi }(x_{a_s}),y)$$这里，Nf表示异常补丁的数量，且Nf ≪ N。补丁特征随后将通过双存储器增强。

## Dual Memory Bank-based Knowledge Enhancement

异常中心采样策略，即向计算得到的**平均异常特征** $q^{\text{avg}}_a \in \mathbb{R}^{N \times C}$ 添加一个小扰动 ϵ ∼ N(0, 0.01)，以生成**伪异常特征集合** $\mathcal{M}_p$。 对于统一的半监督设置（Unified Semi-Supervised Setting），异常存储库实际上是 $\mathcal{M}_o$、$\mathcal{M}_{a_s}$ 和 $\mathcal{M}_p$ 的并集。一旦构建了 $\mathcal{M}_n$ 和 $\mathcal{M}_a$，它们将被保存在磁盘上且不会改变。

距离和注意力矩阵都包含有关特征正常性或异常性的知识。当情景转移到统一的半监督设置（Unified Semi-Supervised Setting）时，即异常是可访问的，我们执行相同的操作来计算每个已见异常xas的异常特征qa的必要知识ka·n和ka·a。需要注意的是，在统一的半监督设置（Unified Semi-Supervised Setting）中，不使用注意力矩阵。这是因为我们发现独立计算距离会产生更好的结果。这部分的消融研究结果显示在表4中。 获取知识后，将投影层Pθ应用于特征和两部分知识。随后，将特征本身与两部分知识组合形成**增强的正常表示** $o_n \in \mathbb{R}^{N \times 3C}$：
$$o_n=Cat(\mathcal {P}_{\theta }(q_{n}),\mathcal {P}_{\theta }(k_{n \cdot n}),\mathcal {P}_{\theta }(k_{n \cdot a}))$$
$Cat$ 表示连接操作。对于统一的半监督场景（Unified Semi-Supervised Scenarios），我们还有**增强的异常表示** $o_a \in \mathbb{R}^{N_f \times 3C}$：
$$o_a=Cat(\mathcal {P}_{\theta }(q_{a}),\mathcal {P}_{\theta }(k_{a \cdot n}),\mathcal {P}_{\theta }(k_{a \cdot a}))$$
## Anomaly Score Mapper

我们采用一个 MLP，表示为 $\Psi$，来学习我们构建的增强表示 $o$ 和异常分数 $S \in \mathbb{R}^{H_0 \times W_0}$ 之间的映射。我们利用一个铰链损失函数来优化网络。在一般的统一（多类别）场景中，当没有负样本可用时，我们采用特征增强策略。该策略涉及使用高斯噪声生成器创建**伪负样本** $o_p \in \mathbb{R}^{N×3C}$。当带标签的异常可访问时，使用三部分铰链损失进行模型优化。
$$\mathcal {L} = \max (0, 0.5 - \Psi (o_n)) + \lambda _1 \max (0, 0.5 + \Psi (o_p)) + \lambda _2 \max (0, 0.5 + \Psi (o_a))$$
## Anomaly Detection and Localization

对于给定的测试图像 $x_\text{test}$，我们可以利用一个训练良好的 DMAD 来得出其**补丁级别的异常分数** $S_\text{test}$。我们采用前5个异常分数的平均值作为其**图像级别的分数**。对于**像素级别的分数**，我们首先对 $S_\text{test}$ 应用双线性插值，然后进行高斯平滑以细化其值。

## 实验

### 4.1 Datasets and Evaluation Metrics

【MVTec-AD】MVTec-AD [1]是一个广泛认可的异常检测基准，包含来自各个领域的5,354张高分辨率图像的多样化数据集。该数据集被分类为5种纹理类型和10种对象类型。数据被分为训练集和测试集，训练集包含3,629张无异常的图像，确保重点放在正常样本上。另一方面，测试集包含1,725张图像，提供了正常和异常样本的综合评估。为了帮助异常定位评估，提供了像素级注释。

【VisA】VisA [32]数据集包括10,821张高分辨率图像，包括9,621张正常图像和1,200张异常图像。该数据集被组织成12个独特的对象类别。这12个对象类别可以进一步分为三种不同的对象类型：复杂结构、多个实例和单个实例。对于我们的研究，我们特别利用了VisA数据集的2类少样本设置，其中训练集和测试集都包含正常和异常样本。

【评估指标】我们利用了一套全面的标准评估指标，包括接收器操作特征曲线下面积（AUROC）、平均精度（AP）和最大F1分数（F1max）。此外，对于异常定位，我们使用了区域重叠度（PRO）指标。

### 4.4 Anomaly Detection and Localization

我们在MVTec-AD和VisA数据集上进行了一系列定性和定量比较实验。随后对结果进行了分析。我们选择了统一（多类别）设置的基准，UniAD [25]，一种最先进的单类方法，SimpleNet [14]，以及两种半监督方法，DRA [8]和BGAD [24]进行比较。由于PRN [28]的代码不可用，我们没有将其纳入比较范围。此外，由于DRA [8]的异常图生成代码尚未发布，我们没有展示其像素级度量。值得注意的是，这些方法不提供统一设置的结果，因此我们自己实现了它们，用右上角的∗表示。表1和表2呈现了异常检测的定量比较结果。

在无监督场景中，尽管DMAD并非专为此类情况设计，但在MVTec-AD数据集上的测试中表现与UniAD [25]相当。此外，在VisA数据集上，它的性能优于UniAD [25]，分别实现了AUROC和AP的提升5.8↑和42.9↑。

当有少量注释的异常可用时，DMAD利用双内存库学习更精确的决策边界，从而在MVTec-AD和VisA数据集上均实现了最先进的性能。具体而言，在有10个异常的情况下，DMAD在MVTec-AD中可以实现99.0的AUROC和99.7的AP，以及在VisA中的94.9 AUROC，79.7 F1max和84.9 AP。异常定位性能比较如表2和表3所示。DMAD在所有不同设置下实现了SOTA AUROC/AP/PRO指标，表明其能够有效处理实际场景中出现的挑战。具体来说，DMAD在MVTec-AD数据集上最高可达98.2 AUROC和58.7 AP，以及在VisA数据集上的99.3 AUROC，43.7 AP和92.9 PRO。我们还进行了异常定位的定性评估，如图4所示。直观地说，我们的方法有助于更准确地识别异常。