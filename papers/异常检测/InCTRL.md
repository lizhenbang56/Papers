---
标题: Toward Generalist Anomaly Detection via In-context Residual Learning with Few-shot Sample Prompts
代码: https://github.com/mala-lab/InCTRL
Publish: CVPR2024
Year: "2024"
Month: "03"
创新点: 基于CLIP的小样本上下文学习
文档链接: https://arxiv.org/pdf/2403.06495.pdf
I-AUROC-MVTecAD-8shot: "97.7"
---
#### 术语对译
- In-Context Learning：上下文学习
- In-Context Prompts：上下文提示
#### 参考文献
[[A Survey on Visual Anomaly Detection]]
```mermaid
graph LR;
	InCTRL-->现有异常检测范式-->为每个训练数据集构建单独的模型;
	InCTRL-->通用异常检测模型-->一个模型可泛化到不同数据集;
	InCTRL-->小样本异常检测-->少量正常样本可用;
	InCTRL-->上下文学习-->使用少量上下文提示使LLM适应新任务
```

## 摘要 

本文探讨了通用异常检测（GAD）的问题，旨在训练一个单一的检测模型，该模型能够在不需要对目标数据进行进一步训练的情况下，泛化到不同应用领域的多样数据集中检测异常。一些最近的研究表明，像CLIP这样的大型预训练视觉语言模型（VLMs）在检测来自各种数据集的工业缺陷方面具有很强的泛化能力，但它们的方法严重依赖于关于缺陷的手工制作的文本提示，这使得它们难以推广到其他应用中的异常，例如，医学图像异常或自然图像中的语义异常。在这项工作中，我们提出使用少量正常图像作为样本提示动态地训练一个GAD模型。为此，我们引入了一种新颖的方法，该方法学习了一种上下文残差学习模型，称为InCTRL。它在辅助数据集上训练，以根据查询图像与少量正常样本提示之间的残差的整体评估来区分异常和正常样本。无论数据集如何，根据异常的定义，异常的残差预期比正常样本的残差要大，从而使InCTRL能够在不进行进一步训练的情况下在不同领域泛化。我们在九个AD数据集上进行了综合实验，建立了一个GAD基准，涵盖了工业缺陷异常、医学异常和语义异常的检测，在一对所有和多类别设置下，InCTRL表现最佳，并显著优于最先进的竞争方法。代码可在[https://github.com/mala-lab/InCTRL获取。](https://github.com/mala-lab/InCTRL%E8%8E%B7%E5%8F%96%E3%80%82)

## 引言 

异常检测（AD）是一项至关重要的计算机视觉任务，旨在检测与数据集中大部分样本明显不同的样本。由于其广泛的实际应用，如工业检测、医学图像分析和科学发现等，AD当前的范式侧重于在训练数据上单独构建模型，例如，目标数据集的无异常样本集，例如数据重建方法、一类分类和知识蒸馏方法。尽管这些方法在各种AD基准测试中显示出了显著的检测性能，但它们需要大量的训练数据和对每个数据集的检测模型的熟练训练。

因此，它们在目标数据集上不允许训练的应用场景中变得不可行，例如由于数据隐私问题，例如由于机器取消学习而使用这些数据在训练模型时产生的问题，或者在部署新应用程序时大规模训练数据不可用。

为了解决这些挑战，本文探讨了学习通用异常检测（GAD）模型的问题，旨在训练一个单一的检测模型，该模型能够在不同应用领域的多样数据集中检测到异常，而无需对目标数据进行训练。

由于预先在网络规模的图像文本数据上进行了训练，大型视觉语言模型（VLMs）如CLIP展示了近年来出色的泛化能力，实现了在不同数据集上的准确视觉识别，而无需在目标数据上进行任何微调或适应。更重要的是，一些最近的研究（例如WinCLIP）表明，这些VLMs也可以用于在不同的缺陷检测数据集上实现显著的泛化。

然而，这些模型的一个显著限制是它们依赖于一个大型的手工制作的与缺陷相关的提示集。这种依赖性限制了它们的适用性，使得将它们用于检测其他数据领域的异常变得具有挑战性，例如，医学图像异常或在一对所有或多类设置中的语义异常。

为了解决这个问题，我们提出了一种GAD模型，旨在利用任何目标数据集中的少量正常图像作为样本提示来支持即时的GAD，如图1（顶部）所示。少样本设置的动机在于在现实世界的应用中通常很容易获得少量正常图像。

此外，这些少量样本不用于模型训练/调整；它们只是在推断期间用作样本提示，以启用测试图像的异常评分。

这种表述与当前的少样本AD方法不同，这些方法使用这些目标样本及其广泛的增强版本来训练检测模型，这可能导致对目标数据集的过度拟合，并且无法泛化到其他数据集，如图1（底部）所示。

然后，我们引入了一种GAD方法，这是第一种根据CLIP学习上下文残差学习模型的方法，称为InCTRL。它训练了一个GAD模型，通过学习识别查询图像与辅助数据中的一组少量正常图像之间的残差/差异来区分异常和正常样本。

少量样本图像，即上下文样本提示，用作正常模式的原型。根据异常的定义，与这些正常模式的特征相比，在不同领域的数据集中通常会对异常样本期望更大的残差，因此学习的上下文残差模型可以泛化到检测不同类型的异常。

为了更好地捕捉残差，InCTRL在图像和补丁级别模拟上下文残差，获得了对构成异常的内容的深入上下文理解。

此外，我们的上下文残差学习还可以实现正常/异常文本提示引导的先验知识无缝地纳入检测模型，从而为从文本-图像对齐语义空间进行检测提供了额外的优势。

因此，我们做出以下主要贡献。 
• 我们引入了一个GAD任务，以评估AD方法在识别各种情景中的异常时的泛化能力，而无需对目标数据集进行训练/调整。据我们所知，这是首个致力于异常检测的通用方法的研究，涵盖了工业缺陷、医学异常和语义异常。 
• 然后，我们提出了一种针对GAD的上下文残差学习框架，称为InCTRL。它旨在通过检测测试图像和来自任何目标数据集的上下文少量正常样本提示之间的残差来区分异常和正常样本。InCTRL在辅助数据上进行了优化，以实现一模型适用于各种数据集的目标，而无需对目标数据进行任何训练。 
• 对九个不同的AD数据集进行了全面的实验，建立了一个GAD基准，涵盖了三种流行的AD任务类型，包括工业缺陷异常检测、医学图像异常检测以及在一对所有和多类设置下的语义异常检测。我们的结果表明，InCTRL明显优于最先进的竞争方法。

## 3. InCTRL：上下文残差学习 

### 3.1. 问题陈述 

GAD的目标是训练一个单一的AD模型，能够在来自不同应用领域的测试数据集上有效检测异常，而无需对目标数据进行任何训练。因此，假定训练集与测试集来自不同的分布。

形式上，设 $\mathcal{D}_{train} = \{X_{train}, Y_{train}\}$ 为一个辅助训练数据集，具有正常和异常类别标签，其中 $X_{train} = \{x_i\}^N_{i=1}$ 包含 $N$ 个正常和异常图像，$Y_{train} = \{y_i\}^N_{i=1}$，其中 $y_i = 0$ 表示正常，$y_i = 1$ 表示异常。给定一组测试集T = {D1test, D2test, · · · , DMtest}，其中Djtest = {Xjtest, Yjtest}，来自M个不同应用领域的各种类型的异常。这些测试集来自与Dtrain不同的分布。然后，目标是训练一个通用的异常评分函数：Dtrain → R，以便在任何测试数据集中将异常样本的异常评分分配得比正常样本高。在具有少量正常样本的GAD上下文中，推断过程中会提供一小组少量从目标域中随机抽取的正常图像，记为P = {p1, p2, · · · , pK}，其中K通常是一个小数字，例如K ≪ N，但在训练通用检测模型期间，P无法以任何方式获得。 3.2. 我们方法InCTRL的概述 我们的方法InCTRL旨在有效地建模查询图像与一组少量正常样本提示之间的上下文残差，利用CLIP的泛化能力来检测来自不同应用领域的异常的异常残差。CLIP是一个包含文本编码器ft(·)和视觉编码器fv(·)的VLM，通过在网络规模的文本-图像数据上进行预训练，这些编码器产生的图像和文本表示是对齐的。InCTRL通过在图像编码器上进行上下文残差学习来优化辅助数据Dtrain，通过文本编码器引导的先验知识增强了学习。 具体而言，如图2所示，我们首先模拟一个包含一个查询图像x和一组少量从辅助数据Dtrain中随机抽取的正常样本提示P'的上下文学习示例。然后，通过视觉编码器，我们进行多层面向补丁和图像的残差学习，分别捕捉查询图像与少量正常样本提示之间的局部和全局差异。此外，我们的模型允许根据文本提示嵌入与查询图像的相似性，无缝地将文本提示引导的正常和异常先验知识结合到模型中。InCTRL的训练是通过在视觉编码器附加几个投影/适应层来进行的，以学习在Dtrain中对异常样本比正常样本有更大的异常评分，同时保持两个编码器的原始参数不变；在推断过程中，一个测试图像，以及来自目标数据集的少量正常图像提示和文本提示，通过我们经过调整的基于CLIP的GAD网络，其输出是测试图像的异常评分。接下来我们详细介绍这些模块。

### 3.3. Multi-Layer Patch-Level Residual Learning

对于一个 training query image $x$，我们提取一系列 patch token embedding maps $\{T_x^l\}_{l=1}^n$ 和 $\{T_{x'}^l\}_{l=1}^n$，其中 $T_{(\cdot)}^l \in \mathbb{R}^{h\times w \times d}$，$x' \in \mathcal{P}'$，$h,w,d$分别是特征图 $T$ 的高、宽、通道数。

对于一个查询图像 $x$，其在 $l$ 层的 patch-level in-context residual map $\textbf{M}_x^l \in \mathbb{R}^{h\times w}$ 定义为：$$\textbf{M}_x^l(i,j) = 1 - \langle T_x^l (i,j), h(T_x^l (i,j)|\mathcal{P}')\rangle$$其中$h(T_x^l (i,j)|\mathcal{P}')$ 返回 $\mathcal{P}'$ 中所有 image tokens 中与 $T^l_x(i,j)$ 最接近的 patch token 的 embedding。

最终的 patch-level residual map $\textbf{M}_x \in \mathbb{R}^{h\times w}$ 定义为： $$\textbf{M}_x = \frac{1}{n} \sum^n_{l=1} \textbf{M}_x^l$$

### 3.6. Training and Inference

#### In-Context Residual Learning

查询图像 $x$ 的 holistic in-context residual map 定义为：$$\textbf{M}_x^+ = \textbf{M}_x \oplus s_i(x) \oplus s_a(x)$$

设 $\phi$ 是一个打分函数，$\Theta_\phi$ 是其参数，则最终的异常得分定义为：
$$s(x) = \phi(\textbf{M}^+ ; \Theta_\phi) + \alpha s_p (x)$$


最终，我们使用 $X_{train}$ 优化最终的异常得分 $s(x)$：
$$\mathcal{L}_h = \frac{1}{N} \sum_{x\in X_{train}} \mathcal{L}_b (s(x), y_x)$$