---
Url: https://arxiv.org/pdf/2011.08785.pdf
Publish: ICPR2020
Year: "2020"
创新点: 学习图片的每个空间位置的特征向量的高斯分布，根据阈值判断正常和异常
I-AUROC-MVTecAD单类无监督: "97.9"
P-AUROC-MVTecAD单类无监督: "97.5"
---
## 摘要

我们提出了一种新的补丁分布建模框架，PaDiM，用于在单类学习设置中同时检测和定位图像中的异常。PaDiM利用预训练的卷积神经网络（CNN）进行补丁嵌入，并利用多变量高斯分布来获得正常类的概率表示。它还利用CNN不同语义级别之间的相关性来更好地定位异常。在MVTec AD和STC数据集上，PaDiM在异常检测和定位方面均优于当前的最新方法。为了与真实世界的视觉工业检验相匹配，我们扩展了评估协议，以评估非对齐数据集上异常定位算法的性能。PaDiM的最新性能和低复杂度使其成为许多工业应用的良好选择。

## I. 引言

人类能够在一组同质自然图像中检测异构或意外的模式。这项任务被称为异常或新颖性检测，并且有大量应用，其中包括视觉工业检验。然而，在制造线上，异常事件非常罕见且难以手动检测。因此，异常检测自动化将通过避免注意力减弱和促进人类操作员工作来实现持续的质量控制。在本文中，我们专注于异常检测，特别是在工业检验环境中的异常定位。在计算机视觉中，异常检测涉及为图像提供异常分数。异常定位是一个更复杂的任务，它为每个像素或每个像素补丁分配一个异常分数，以输出异常图。因此，异常定位产生了更精确和可解释的结果。我们的方法生成的异常地图示例用于在MVTec异常检测（MVTec AD）数据集中定位图像中的异常。

异常检测是正常和异常类之间的二元分类。然而，对于这项任务，不可能使用完全监督的模型进行训练，因为我们经常缺乏异常示例，而且异常可能具有意外的模式。因此，异常检测模型通常在单类学习设置中进行估计，即训练数据集仅包含来自正常类的图像，并且在训练期间不可用异常示例。在测试时，与正常训练数据集不同的示例被分类为异常。

近年来，已经提出了几种方法来在单类学习设置中结合异常定位和检测任务。然而，要么它们需要深度神经网络训练，这可能很麻烦，要么它们在测试时在整个训练数据集上使用K最近邻（K-NN）算法。KNN算法的线性复杂度会随着训练数据集大小的增加而增加时间和空间复杂度。这两个可扩展性问题可能会阻碍异常定位算法在工业环境中的部署。为了缓解上述问题，我们提出了一种名为PaDiM的新的异常检测和定位方法，用于补丁分布建模。它利用预训练的卷积神经网络（CNN）进行嵌入提取，并具有以下两个特性：

- 每个补丁位置由多变量高斯分布描述；
- PaDiM考虑了预训练CNN的不同语义级别之间的相关性。

有了这种新的高效方法，PaDiM在MVTec AD和ShanghaiTech Campus（STC）数据集上优于现有的最新方法，不仅在异常定位上表现良好，而且在测试时，时间和空间复杂度低，独立于数据集训练大小，这对于工业应用是一个优点。我们还扩展了评估协议，以在更真实的条件下评估模型性能，即在非对齐数据集上。

## II. 相关工作

异常检测和定位方法可以分为基于重建和基于嵌入相似性两类。

基于重建的方法被广泛用于异常检测和定位。诸如自动编码器（AE）[1]、变分自动编码器（VAE）[3]、生成对抗网络（GAN）[15]等神经网络架构被训练用于仅重建正常训练图像。因此，异常图像可以被发现，因为它们无法很好地重建。在图像级别，最简单的方法是将重建误差作为异常分数[10]，但来自潜空间[16]、中间激活[19]或鉴别器[17]、[20]的额外信息可以帮助更好地识别异常图像。然而，基于重建的方法可以将像素级重建误差[1]或结构相似性[9]作为异常分数。另外，异常图也可以是从潜空间[3]、[14]生成的视觉注意图。尽管基于重建的方法非常直观和可解释，但由于自动编码器有时对异常图像也能产生良好的重建结果[21]，因此其性能受到限制。

基于嵌入相似性的方法使用深度神经网络提取描述整个图像用于异常检测[6]、[22]、[23]或图像补丁用于异常定位的有意义向量[2]、[4]、[5]、[25]。然而，仅执行异常检测的基于嵌入相似性的方法给出了有希望的结果，但常常缺乏可解释性，因为无法知道异常图像的哪一部分导致高异常分数。在这种情况下，异常分数是测试图像的嵌入向量与来自训练数据集正常性的参考向量之间的距离。正常参考可以是包含来自正常图像的嵌入的n球的中心[4]、[22]、高斯分布的参数[23]、[26]或整个正常嵌入向量集合[5]、[24]。SPADE[5]使用的是最后一种选项，其具有报告的最佳异常定位结果。然而，它在测试时在一组正常嵌入向量上运行K-NN算法，因此推断复杂度与数据集训练大小成线性关系。这可能会阻碍该方法在工业上的部署。

我们的方法PaDiM生成用于异常定位的补丁嵌入，类似于前述方法。然而，PaDiM中的正常类通过一组高斯分布来描述，这些分布还模拟了所使用的预训练CNN模型的语义级别之间的相关性。受到[5]、[23]的启发，我们选择了ResNet [27]、Wide-ResNet [28]或EfficientNet [29]作为预训练网络。由于这种建模，PaDiM优于当前最先进的方法。此外，它的时间复杂度低，且在预测阶段不依赖于训练数据集的大小。

## III. 补丁分布建模

### A. 嵌入提取

预训练的CNN能够输出与异常检测相关的特征[24]。因此，我们选择通过仅使用预训练的CNN生成补丁嵌入向量来避免繁重的神经网络优化。PaDiM中的补丁嵌入过程类似于SPADE中的过程，并且在图2中进行了说明。在训练阶段，正常图像的每个补丁都与预训练CNN激活图中的空间对应的激活向量相关联。然后，来自不同层的激活向量被连接起来，以获得包含来自不同语义级别和分辨率的信息的嵌入向量，以便编码细粒度和全局上下文。由于激活图的分辨率低于输入图像，许多像素具有相同的嵌入，然后在原始图像分辨率中形成无重叠的像素补丁。因此，输入图像可以被划分为(i, j) ∈ [1, W] × [1, H]位置的网格，其中WxH是用于生成嵌入的最大激活图的分辨率。最后，此网格中的每个补丁位置(i, j)与根据上述描述计算的嵌入向量xij相关联。

生成的补丁嵌入向量可能携带冗余信息，因此我们实验性地研究了减小它们大小的可能性（第V-A节）。我们注意到，随机选择少量维度比传统的主成分分析（PCA）算法[30]更有效。这种简单的随机降维显著降低了我们模型的复杂性，同时保持了最先进的性能。最后，在测试时，来自测试图像的补丁嵌入向量用于借助下一小节描述的学习的正常类的参数化表示输出异常图。

### B. 正常性的学习

为了学习位置(i, j)处的正常图像特征，我们首先计算来自N个正常训练图像的补丁嵌入向量集合Xij = {x k ij , k ∈ [[1, N]]}，如图2所示。为了总结此集合所携带的信息，我们假设Xij由一个多变量高斯分布N (µij , Σij )生成，其中µij是Xij的样本均值，样本协方差Σij估计如下： Σ��=1�−1∑�=1�(����−���)(����−���)�+��Σij​=N−11​∑k=1N​(xkij​−μij​)(xkij​−μij​)T+ϵI

其中正则化项 I 使得样本协方差矩阵Σij是满秩和可逆的。最后，每个可能的补丁位置与一个多变量高斯分布相关联，如图2所示的高斯参数矩阵。

我们的补丁嵌入向量携带来自不同语义级别的信息。因此，每个估计的多变量高斯分布N (µij , Σij )也捕获来自不同级别的信息，并且Σij包含了级别间的相关性。我们通过实验证明（第V-A节），对预训练CNN的不同语义级别之间的关系进行建模有助于提高异常定位性能。

C. 推断：计算异常图

受到[23]、[26]的启发，我们使用马氏距离[31]M(xij)给测试图像中位置(i, j)处的补丁赋予一个异常分数。M(xij)可以解释为测试补丁嵌入xij和学习的分布N (µij , Σij )之间的距离，其中M(xij)计算如下： �(���)=(���−���)�Σ��−1(���−���)M(xij​)=(xij​−μij​)TΣij−1​(xij​−μij​)​

因此，形成异常图的马氏距离矩阵M = (M(xij))1<i<W,1<j<H可以被计算出来。在这张图中，高分数表示异常区域。整个图像的最终异常分数是异常图M的最大值。最后，在测试时，我们的方法不像基于K-NN的方法[4]–[6]、[25]那样具有可扩展性问题，因为我们不需要计算和排序大量距离值来获取补丁的异常分数。