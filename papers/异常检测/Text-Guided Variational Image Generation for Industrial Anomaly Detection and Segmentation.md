---
Publish: CVPR2024
Url: https://arxiv.org/pdf/2403.06247v2.pdf
Year: "2024"
Month: "03"
创新点: 根据少量正常图像生成大量正常图像
---
## 摘要

我们提出了一种文本引导的变分图像生成方法，以解决工业制造中异常检测的**难以获取非缺陷数据**的问题。我们的方法利用了关于目标对象的文本信息，从广泛的文本库文档中学习，以**生成类似输入图像的非缺陷数据图像**。所提出的框架确保生成的非缺陷图像与从文本和基于图像的知识推导出的预期分布保持一致，确保了稳定性和通用性。实验结果表明了我们方法的有效性，甚至在有限的非缺陷数据下也超越了先前的方法。我们的方法通过对四个基线模型和三个不同数据集进行泛化测试来验证。

## 1. 引言 

在工业制造中识别异常组件，即异常检测任务，一直是一个具有挑战性但重要的问题。传统的异常检测方法通过训练非缺陷数据的分布来解决这个问题，试图识别缺陷[8, 21, 24–26, 28]。最近，还提出了通过概率方法将图像训练成高斯分布的可逆函数，而无需适应目标分布[14, 22, 23, 29]。异常检测的有效性取决于可用的非缺陷数据的数量和质量，因为这些因素直接影响模型包含目标对象外观的各种光谱的能力。最重要的是，工业缺陷的视觉分类很困难，因为错误可能从细微的变化，如细小的划痕，到显著的结构缺陷，如缺少零件，变化不一。

这种困难自然落入分布之外检测的问题，其中模型必须区分从训练数据分布获得的样本和超出其范围的样本。因此，获取有效地代表数据分布并且与缺陷情况区分开来的各种非缺陷数据至关重要。 然而，工业领域面临各种数据问题。

第一个问题是非缺陷数据不平衡的问题，其中非缺陷数据本身可能呈现出接近均匀的状态，只有少数图像展示出可接受的缺陷。

第二个问题与数据的敏感性有关，特别是在外观和缺陷程度上，由于所使用的机器类型和捕获条件的不同，它们可能会发生显著变化。最后一个问题是在收集非缺陷数据时，有可能错误地将缺陷数据误标为非缺陷数据。 

为了克服大量**非缺陷数据**的要求带来的问题，我们提出了一种文本引导的变分图像生成方法，用于工业异常检测和分割。为了解决所提供的**非缺陷数据缺乏**多样性的问题，我们广泛利用了有关目标对象的文本信息，通过全面的文本库文档学习，生成与输入图像最相似的非缺陷数据图像。此外，重要的是要认识到，正常分布也可能受到所提供的非缺陷图像数据的影响，其行为受我们新的变分图像生成器框架预测的方差的调节。整合文本信息和图像数据确保了我们提出的框架可以生成多个非缺陷图像，同时保持从文本和基于图像的先验知识推导出的预期非缺陷分布。通过利用从我们的生成器生成的一堆非缺陷图像，我们可以将我们的框架应用于各种异常检测方法，从而潜在地提高其整体性能。

我们通过对四个基线模型和三个不同数据集进行泛化测试来验证所提出的方法。有趣的是，如图1所示，即使依赖单个或少量非缺陷图像，我们的方法也优于以前需要大量非缺陷数据的方法。 我们的贡献可以总结如下：

- 为了确保泛化和稳健性，我们开发了一个基于变分的图像生成器来预测和保留所提供的非缺陷图像的方差。
- 为了解决好产品数据缺乏多样性的问题，我们开发了一个关键字到提示的生成器，通过将关于目标对象的文本信息与输入图像进行全面学习，生成最佳提示。
- 为了弥合不同模态产生的语义鸿沟，我们开发了一种文本引导的知识整合方法，其中潜在的图像特征与目标对象的文本信息对齐。
- 为了验证我们方法的有效性，我们将我们的方法合并到几种最新算法中，并在各种真实世界工业数据集上进行了广泛测试，实验结果证明，即使是单个或少量非缺陷图像，我们的框架也显示出令人印象深刻的性能。

## 相关工作

【文本引导的异常检测】大多数异常检测方法包括基于表示的方法，这些方法提取用于补丁的判别特征，并计算分布之间的距离[14, 29]，以及使用生成对抗网络的基于重构的方法[21, 30]。随着异常检测的进展，由于[3]最新研究[1, 2, 27]，在全射击设置中的基准数据集的性能已经饱和。然而，最近的研究采用了不同的设置和方法，例如基于文本的异常检测。例如，WinCLIP [15]通过混合状态词和文本候选项为输入图像生成预文本提示。然后，它通过二进制掩码提取输入图像的多尺度特征，并计算生成提示之间的相似度得分以检测异常。

相比之下，我们的方法侧重于基于输入图像和基于文本的先验知识的相似性生成非缺陷图像。通过将不同属性的新生成图像馈送到一般异常检测方法中，它通过提供更多的非缺陷数据来提高性能。

【文本到图像生成】最近，广泛研究了文本到图像生成模型[16, 19]，这些模型基于给定的文本和所有先前预测的像素值来预测或生成下一个像素值。例如，DALL-E [20]从GPT系列模型中获取文本输入来预测下一个像素，然后将其添加到初始图像中，以及文本一起作为后续输入。通过多次重复这个过程，DALL-E可以生成整个图像。GAN [12]以高质量和逼真的图像生成而闻名，无需提示，而对比语言图像预训练（CLIP）是另一个神经网络，可以确定说明或提示与图像的匹配程度。通过VQGAN-CLIP [5]，其中VQGAN [10]创建一个图像，CLIP [19]检查来自VQGAN的生成图像是否与文本匹配。当这个过程重复时，创建的图像逐渐类似于输入文本。

然而，以前的文本引导图像生成方法忽略了给定图像数据的表示方差的重要性，这对于在异常检测任务中推广非缺陷图像数据至关重要。与以前的基于文本的图像生成方法相比，我们的目标是预测非缺陷图像分布的方差，这有助于避免生成缺陷图像，同时扩大非缺陷图像的外观变化。

## 初步分析 

【假设】由于使用的机器类型和捕获条件的不同，与敏感性相关的数据问题，尤其是在外观和缺陷级别方面，可能会有显著变化。因此，生成图像与原始图像之间的相似性与性能增强高度相关，生成图像的视觉方差也对性能增强有所贡献。在图2中，生成图像与原始图像之间的相似性与性能增强高度相关，并且生成图像的方差也有助于性能提升。这些结果从经验上验证了我们的假设。

图2. 假设的相关性。我们使用不同的图像重复测试以确认我们的假设。性能增强与生成图像与原始图像之间的相似性密切相关，并且生成图像的视觉方差也有助于性能提升。 生成的图像应与所提供的非缺陷图像的外观相似，同时保留其视觉方差。此外，我们还比较了原始图像与朴素提示（0.39）、仅单词（0.35）以及我们的相关性（0.54），这证实了我们假设中设计良好提示的必要性。 

【初步分析】我们在一个简单的场景中使用各种图像重复进行初步实验，以验证我们的假设。在这个场景中，我们比较了基线异常检测模型和使用从网络搜索或图像生成器生成的一个额外训练图像的相同模型之间的性能。我们从MVTecAD数据集[3]中选择了一个榛果图像，使用Patchcore[21]作为基线异常检测模型。 

我们构建了各种类型的生成图像： 原始图像、网络图像[13]、Midjourney[17]、以及DALL-E[20]、VQGAN-CLIP（仅单词）和VQGAN-CLIP（Na¨ıve提示）。首先，原始图像利用给定的单个原始图像来训练异常检测模型，而网络图像则添加了从网络检索到的一个附加图像，关键词为“榛果”。

对于基于文本的图像生成器，我们首先使用GPT-4从原始榛果图像生成文本说明，结果为：“这张图像展示了一个带有纹理的榛果顶部的单个榛果。果仁本身呈暖棕色，有可见的条纹和标记，表明其自然起源。它靠在深色背景上，突出了果仁的细节纹理和有机形状。”。

仅单词和Na¨ıve提示分别使用“榛果”和“榛果的照片”作为提示。这三种类型的提示被馈送到Midjourney、DALL-E和VQGAN-CLIP中，以生成额外的训练图像。图3显示了来自各种生成方案的额外训练图像，表明结果高度取决于图像生成模型的类型和提示。

初步实验的结果在表1中表示，表明性能受生成的图像影响。有趣的是，初步结果显示，良好的图像质量并不一定有助于提高性能，正如DALL-E的低性能所示。与此同时，鉴于网络图像的性能相对较高，可以假设如果原始图像的轮廓和角度等元素在额外图像中得以保留，性能就可以得到提高。因此，虽然简单生成的图像不能用于异常检测模型，但我们需要考虑几个额外因素来有效地训练非缺陷分布的生成图像。首先，生成的图像应与所提供的非缺陷图像的外观相似，同时保留其视觉方差。其次，找到生成视觉结构良好图像的最佳提示是很重要的。最后，基于以上两种信息内容，即使给定的非缺陷图像数量不足，我们也应该创建具有较小语义差距的图像。

## 方法

如 Fig. 4所示，我们的框架包括：
- 关键词到提示生成器
- 方差感知图像生成器
- 文本引导知识整合器

关键词到提示生成器基于输入文本中呈现的关键词生成一组包含不同词组合的提示，并从生成的提示中选择与输入图像具有可比性信息的最佳提示。

方差感知图像生成器**生成一组非缺陷图像**，将非缺陷图像的视觉特征编码到正态分布中以保留其方差。

生成过程随着生成器的更新而迭代进行，而文本引导知识整合器通过评估关键词到提示生成器生成的文本提示与图像集之间的潜在分布相似性来确定**生成的图像**的最佳集合。

最后，**生成的图像**的最佳集合被用作基线异常检测模型的**附加训练集**。

### 4.1. 生成模块 

图像生成模块包括：
- 关键词到提示生成器
- 方差感知图像生成器

关键词到提示生成器将目标对象名称Wo与预定义状态词集合（{W1，W2，...，WT}）结合起来生成多个候选提示（{S1，S2，...，ST}）。然后，关键词到提示生成器根据它们与原始图像Io的潜在距离选择最佳提示。接着，我们将输入图像{Io}转换成多个增强图像I1、I2、...、IN，这些图像被馈送到方差感知图像生成器，该生成器将图像Ii编码成相应的潜在分布zi。最后，我们通过采样解码zi来生成新的多图像集合{I+1，I+2，...，I+M}。

#### 4.1.1 关键词到提示生成器 

关键词到提示生成器基于**给定的对象名称** $W^o$ 和**原始训练图像** $I^o$ 生成**最合适的提示** $P$。我们使用WordNet [11]构建了一组不同的词{W1，W2，...，WT}，以获取替换了{W1，W2，...，WT}的对应单词的候选提示（S1，S2，...，ST），其中St是“一个{Wo}带有{Wt}”的替代词。使用WordNet [11]，我们可以收集包含Wo高语义相关性的同义词、上位词、下位词和部分-整体关系的大型数据库。

我们通过两个阶段找到候选提示中的最佳提示：基于距离的异常值移除和嵌入相似度估计。首先，我们使用候选提示和原始图像之间的L2距离移除异常值提示。我们定义了正提示集，其中移除了异常值提示，由S p = Sj |d(Sj，Io)> 0.5确定，其中d(Si，Io) = ||f(Io) − G(Si)||2，f(I)和G(S)分别是图像I的图像嵌入向量和提示S的文本嵌入向量。我们使用CLIP编码器 [19]来获取图像和文本嵌入向量。然后，从正提示集S p中，我们通过以下余弦相似度确定**最佳提示** $P$。

#### 4.1.2 方差感知图像生成器 

作为方差感知图像生成器的基线架构，我们采用了VQGAN模型[10]。该模型整合了矢量量化过程，将连续的潜在空间映射到离散的码书。由于这一特性，编码器的输出特别遵循潜在向量的近似后验分布，这使得通过解码器有效地重构给定的输入图像成为可能。矢量量化过程发挥着关键作用，它通过将连续表示映射到固定的码书，有效地在潜在空间内表示图像。此外，VQGAN模型确保潜在变量的分布与标准正态分布密切近似。 VQGAN的架构可以表示为：...。

然而，现有的VQGAN统一地将潜在向量的方差σ设为1，忽视了目标对象在各个补丁的外观可能存在的多样性。特别是，在非缺陷图像的训练分布确定缺陷的异常检测模型中，必须考虑外观的多样性。为了解决这个问题，我们扩展了VQGAN的架构，以预测潜在变量的方差。方差感知图像生成器的表示如下：...

### 4.2. Text-guided Knowledge Integrator

在这个过程中，我们生成与最佳提示P相吻合的非缺陷图像，并将它们添加到异常检测模型的非缺陷数据池中。从关键字到提示生成器中选取的P中，我们通过CLIP文本编码器提取文本剪辑特征zt，如zt = G(P)。同时，我们通过方差感知图像生成器生成图像集{I+1, I+2, ..., I+M}，并通过对多个图像特征求平均来估计视觉剪辑特征，即：...。

## 5. Experimental Result

### 5.1. Quantitative Results

我们对我们新设计的框架在一次性、少量（5张图像）和完整（全部训练图像）训练情况下与基线方法的泛化性能进行了比较分析。首先，我们将基于MVTecAD数据集[3]的最新基线方法[9, 14, 21]和最新基线模型[2]应用到不同类别的平均性能中。此外，我们分析了性能提升最高的五个类别，以展示我们方法的优势。其次，我们使用包含两种对象和纹理的BTAD数据集[18]进行了实验，以找出我们模型表现良好的对象类型。
  
在图5中，使用MVTecAD数据集进行的泛化检测实验结果表明，相对于所有基线方法，性能有所提升，从而验证了我们模型的泛化能力。结果显示，在一次性、少量和完整训练数据情况下，平均增幅分别为15.7%、14.1%和5.6%，验证了我们的框架即使在训练图像数量较少的情况下也能取得显著的性能提升。此外，我们对一次性任务中性能提升最高的五个类别进行了分析，如图5的第二行所示。结果显示，Patchcore模型中的电缆和螺母等对象类型表现出显著的性能提升，分别为19.1%和18.5%。其他基线方法在对象类型上也呈现出类似的趋势，而反向蒸馏模型在纹理类型（如皮革）中也表现出显著增长，增幅达到73.3%。

如图6所示，我们在BTAD数据集上进行了额外实验，重新验证了我们的模型在哪些缺陷方面效果良好。如图6（顶部）的图表所示，与基线相比，检测AUROC显示对象类型（第一类）提升了20.2%，纹理类型（第二类）提升了4.0%。类似地，分割AUROC对对象类型的改进也更为显著，对象类型提升了4.4%，纹理类型提升了1.3%。在图6（底部）的定性结果中，对象类型对于定位接近地面真值的异常段产生了更好的结果。因此，这个实验证实了我们的模型在对象类型上更加稳健。


