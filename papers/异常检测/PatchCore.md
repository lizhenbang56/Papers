---
Publish: CVPR2022
文档链接: https://arxiv.org/pdf/2106.08265.pdf
Year: "2021"
Month: "06"
代码: https://github.com/amazon-science/patchcore-inspection
Stars: "619"
I-AUROC-MVTecAD单类无监督: "99.6"
创新点: 比较测试图像补丁特征和训练数据集补丁特征集合的相似度
---
- PatchCore 在 MVTec-AD 上的无监督设置下实现了 99.3% 的图像级 AUC，但在使用统一阈值进行推断时，其准确率降至了 79.76%。——[[AnomalyGPT]]

## 摘要

能够识别有缺陷的零件在大规模工业制造中是一个至关重要的组成部分。我们在这项工作中要解决的一个特殊挑战是冷启动问题：仅使用正常（非有缺陷）的示例图像来拟合模型。虽然针对每个类别的手工解决方案是可能的，但目标是构建能够同时在许多不同任务上自动运行的系统。性能最佳的方法是将来自ImageNet模型的嵌入与异常检测模型相结合。在这篇论文中，我们延伸了这一工作，并提出了PatchCore，它使用最大限度的代表性存储器库来存储正常补丁特征。PatchCore在达到最先进性能的同时，提供了竞争性的推理时间，同时实现了检测和定位的最先进性能。在具有挑战性的广泛使用的MVTec AD基准测试中，PatchCore实现了高达99.6%的图像级异常检测AUROC分数，与下一个最佳竞争对手相比，错误减少了一半以上。我们还在另外两个数据集上报告了竞争性结果，并在少样本情况下发现了竞争性结果。代码：github.com/amazon-research/patchcore-inspection。

## 1. Introduction

人类的认知深深地融入了在图像中检测异常模式的能力。人类能够在只看过少量正常实例后区分数据中的预期变化和异常值。在这项工作中，我们解决了这个问题的计算版本，即冷启动异常检测，用于工业图像数据的视觉检查。这种问题在许多工业场景中都会出现，其中获取正常示例图像很容易，但是指定预期的缺陷变化却是昂贵且复杂的。

这个任务自然被看作是一个分布外检测（out-of-distribution detection）问题，模型需要区分从训练数据分布中绘制的样本和其支持范围之外的样本。工业视觉缺陷分类特别困难，因为错误可能从细微的变化（如细小划痕）到较大的结构缺陷（如缺失组件）都有所体现。图1显示了MVTec AD基准数据集中的一些示例，以及我们提出的方法的结果。现有的冷启动工业视觉异常检测工作依赖于通过自编码方法、GANs或其他无监督适应方法学习正常分布的模型。最近，一些研究提出利用ImageNet分类的常见深度表示，而无需适应目标分布。尽管缺少适应性，但这些模型提供了强大的异常检测性能，甚至对缺陷进行了可靠的空间定位。这些技术的关键原则是在利用深度特征表示的多尺度性质的同时，对测试样本和正常样本进行特征匹配。精细的缺陷分割由高分辨率特征覆盖，而结构偏差和完整的图像级异常检测则应该由更高抽象级别的特征覆盖。由于这种方法是非自适应的，其固有缺点是在更高抽象级别上的匹配置信度有限：ImageNet训练中的高级抽象特征与工业环境中所需的抽象特征几乎没有相符。此外，在测试时可用的正常上下文受到可提取的高级特征表示数量的限制。

在本文中，我们提出PatchCore作为一种有效的方法，通过（1）在测试时最大化可用的正常信息，（2）减少对ImageNet类的偏见，并且（3）保留高速推理。由于一张图像只要有一个补丁是异常的就可以被归类为异常，PatchCore通过利用局部聚合的中间级别特征补丁来实现这一点。中间级别网络补丁特征的使用使得PatchCore在高分辨率上能够以最小的偏见对ImageNet类进行操作，同时对局部邻域进行特征聚合确保了足够的空间上下文。这导致了一个广泛的存储库，使PatchCore能够在测试时最优地利用可用的正常上下文。最后，为了实际适用性，PatchCore还引入了贪心核心子采样作为一种关键元素，用于减少在提取的补丁级别内存库中的冗余，并显著降低存储内存和推理时间，使PatchCore在实际工业用例中非常具有吸引力。对多样化的MVTec AD以及专门的磁砖缺陷（MTD）工业异常检测基准进行了彻底的实验，展示了PatchCore在工业异常检测中的强大能力。它在MVTec AD和MTD上实现了最先进的图像级别检测得分，MVTec AD几乎完美（达到AUROC 99.6%），将先前方法的检测错误减少了一半以上，以及最先进的工业异常定位性能。PatchCore实现了这一点，同时保持快速的推理时间，而无需在手头的数据集上进行训练。这使PatchCore在工业异常检测的实际应用中非常有吸引力。此外，进一步的实验展示了PatchCore的高样本效率，与现有的异常检测方法在性能上匹敌，同时仅使用一小部分正常训练数据（nominal training data）。
  
## 相关作品 

大多数异常检测模型依赖于学习与正常数据固有的表示相关的能力。例如，这可以通过使用自动编码模型[44]来实现。为了鼓励更好地估计正常特征分布，提出了基于高斯混合模型[60]、生成对抗训练目标[2,39,43]、对预定义物理增强的不变性[25]、隐藏特征对重构的鲁棒性[29]、原型记忆库[21]、注意力引导[52]、结构目标[7, 59]或约束表示空间[38]的扩展。其他无监督表示学习方法也可以类似地利用，比如通过GANs[13]、学习预定义几何变换[20]或通过归一化流[42]。在具有相应正常表示和新颖测试表示的情况下，异常检测可以简单地通过重构错误[44]、到k最近邻的距离[18]或对这些特征进行单类分类模型的微调，例如OC-SVMs[46]或SVDD[50, 56]来完成。对于这些方法的大多数，异常定位基于像素级重构错误，基于显著性的方法，如GradCAM[47]或XRAI[28]，也可以用于异常分割[42, 45, 52]。 

工业异常检测。虽然关于通过学习的正常表示进行一般异常检测的文献广泛，但工业图像数据具有其自身的挑战[5]，最近的工作从[4]开始展示了使用在大型外部自然图像数据集（如ImageNet[16]）上预训练的模型在不对数据进行任何适应的情况下展示了最先进的检测性能。这导致了其他依赖于更好地重用预训练特征的工业异常检测方法的出现，例如利用包含各种特征层次结构的内存库进行精细化的基于kNN的[18]异常分割和图像级异常检测。类似地，[14]最近提出了PaDiM，它利用了一种局部约束的特征包方法[8]，用于估计基于马氏距离测量的补丁级特征分布矩（均值和协方差）。这种方法类似于在完整图像上研究的[40]。为了更好地考虑自然预训练和工业图像数据之间的分布转移，可以进行后续适应，例如通过学生-教师知识蒸馏[24]，如[6, 45]或在预训练网络特征之上训练的归一化流[17, 30]。 

PatchCore中使用的具体组件与SPADE和PaDiM最相关。SPADE利用从预训练的骨干网络提取的正常特征的内存库，并采用了用于图像和像素级异常检测的不同方法。PatchCore类似地**使用内存库**，但是关键在于**邻域感知的补丁级特征**，这对于实现更高的性能至关重要，因为保留了更多的正常上下文并且合并了更好的拟合归纳偏差。此外，内存库被coreset-子采样以确保更低的推断成本和更高的性能。长期以来，在基本的kNN和kMeans方法[22]或混合模型[19]中已经使用了coresets，通过找到最佳近似某个可用集合的结构，并允许以明显降低的成本进行近似解决方案的找到。最近，基于coreset的方法也已经进入了深度学习方法，例如网络剪枝[34]，主动学习[48]，以及增加改进的GAN训练[49]或表示学习[41]的小批量的有效数据覆盖。后三者使用了贪婪的coreset选择机制。因为我们的目标是近似内存库特征空间的覆盖范围，所以我们同样采用了贪婪的coreset机制来适应PatchCore。最后，我们对图像级别异常检测和异常分割的补丁级方法与PaDiM相关，目标是鼓励更高的异常检测灵敏度。我们使用一个高效的补丁特征内存库，所有补丁在测试时都可以访问，而PaDiM将补丁级别的异常检测限制为特定于每个补丁的马氏距离测量。通过这样做，PatchCore不再依赖于图像对齐，同时使用了更大的正常上下文来估计异常。此外，与PaDiM不同，输入图像在训练和测试期间不需要相同的形状。最后，PatchCore利用局部感知的补丁特征分数来考虑局部空间变化，并减少对ImageNet类别的偏见。

## 方法 

PatchCore方法由几个部分组成，我们将依次描述：聚合到内存库的局部补丁特征（§3.1），增加效率的coreset-减少方法（§3.2）以及最终的算法，用于检测和定位决策（§3.3）。 

### 3.1. 局部感知的补丁特征 

我们使用 $\mathcal{X}_N$ 来表示训练时可用的正常图像（nominal images）集合（$\forall x \in \mathcal{X}_N : y_x = 0$），其中 $y_x \in \{0, 1\}$ 表示图像 $x$ 是正常（0）还是异常（1）。

我们定义 $\mathcal{X}_T$ 为测试时提供的样本集，其中 $\forall x \in \mathcal{X}_T : y_x \in \{0, 1\}$。

根据[4]、[10]和[14]，PatchCore使用在ImageNet上预训练的网络φ。由于特定网络层次的特征起着重要作用，我们使用φi,j = φj(xi)来表示图像xi ∈ X（具有数据集X）的特征和预训练网络φ的层次j。如果没有另外说明，在与现有文献一致的情况下，j索引来自ResNet-like [23]架构的特征图，例如ResNet-50或WideResnet-50 [57]，其中j ∈ {1, 2, 3, 4}表示相应空间分辨率块的最终输出。 补丁表示的一种选择是网络特征层次结构中的最后一级。这在[4]或[10]中完成，但会引入以下两个问题。首先，它会丢失更多局部化的正常信息[14]。由于在测试时遇到的异常类型不是先验已知的，这对下游的异常检测性能是有害的。其次，ImageNet预训练网络中非常深和抽象的特征偏向于自然图像分类的任务，与冷启动的工业异常检测任务和手头评估的数据之间的重叠很少。 

因此，我们建议使用一个补丁级特征的内存库M，包括中间或中级特征表示，以利用提供的训练上下文，避免过于通用或过于偏向于ImageNet分类的特征。在ResNet-like架构的特定情况下，这将指的是例如j ∈ [2, 3]。为了形式化补丁表示，我们扩展了先前引入的符号。假设特征图φi,j ∈ Rc_×h_×w_是一个三维张量，深度为c_，高度为h*，宽度为w*。然后，我们使用φi,j(h, w) = φj(xi, h, w) ∈ Rc_来表示位置为h ∈ {1, . . . , h_}和w ∈ {1, . . . , w*}处的c_维特征片。假设每个φi,j的感受野大小大于一，这实际上与图像补丁特征表示相关。理想情况下，每个补丁表示都在足够大的感受野尺寸上操作，以考虑到对局部空间变化具有意义的异常上下文。虽然这可以通过步幅池化和进一步下降网络层次结构来实现，但由此创建的补丁特征变得更具体于ImageNet，并且对于手头的异常检测任务不太相关，而且训练成本增加，特征图分辨率降低。 这就解释了在组成每个补丁级特征表示时进行局部邻域聚合的动机，以增加感受野尺寸和对小空间偏差的鲁棒性，而不会丢失空间分辨率或特征图的可用性。为此，我们扩展了φi,j(h, w)的上述符号，以考虑不均匀的补丁尺寸p（对应于考虑的邻域大小），并合并邻域N(h,w)p中的特征向量，如下所示： φi,j [N(h,w)p] = fagg {[φi,j (a, b)|(a, b) ∈ N(h,w)p]}, 其中fagg是邻域N(h,w)p中特征向量的聚合函数。对于PatchCore，我们使用自适应平均池化。这类似于对每个单独的特征图进行局部平滑，结果是在预定义维度d上的单个表示，该表示对所有具有h ∈ {1, ..., h_}和w ∈ {1, ..., w*}的对都执行，从而保留了特征图的分辨率。对于特征图张量 $\phi_{i,j}$，其局部感知的补丁特征集合 $\mathcal{P}_{s,p}(\phi_{i,j})$ 为： Ps,p(φi,j) = {φi,j [N(h,w)p] | h, w mod s = 0, h < h*, w < w*, h, w ∈ N}， 其中我们设置s为1，除了在§4.4.2中进行的消融实验中。根据经验和与[10]和[14]类似的，我们发现多个特征层次的聚合会带来一些好处。然而，为了保持所使用特征的普适性以及空间分辨率，PatchCore仅使用两个中间特征层次j和j+1。这可以通过计算Ps,p(φi,j+1)并将每个元素与所使用的最低层次的补丁特征（即最高分辨率）进行聚合来实现，我们通过双线性地重新缩放Ps,p(φi,j+1)来实现，使得|Ps,p(φi,j+1)|和|Ps,p(φi,j)|匹配。 

【内存库的定义】最后，对于所有正常训练样本 $x_i \in \mathcal{X}_N$，PatchCore内存库 $\mathcal{M}$ 简单地定义为：$$\mathcal{M} = \bigcup_{x_i \in \mathcal{X}_N} \mathcal{P}_{s,p}(\phi_j(x_i))$$
### 3.2. coreset减少的补丁特征内存库 

对于越来越大的 $\mathcal{X}_N$，$\mathcal{M}$ 变得非常庞大，随之而来的是评估新的测试数据和所需存储的推断时间。这个问题已经在SPADE[10]中注意到，用于像素级异常分割，它使用低级和高级特征图。由于计算限制，SPADE需要基于全图像、深层特征表示的较弱图像级异常检测机制的特征图预选择阶段，即最后一个特征图的全局平均值。这导致了从完整图像计算得到的低分辨率、ImageNet偏向的表示，可能会对检测和定位性能产生负面影响。 这些问题可以通过使M在更大的图像尺寸和数量上具有意义的可搜索性来解决，从而允许基于补丁的比较对异常检测和分割都有益。这要求保留在M中编码的正常特征覆盖范围。不幸的是，随机子采样，特别是通过几个数量级，会丢失M中可用的信息，这些信息编码在正常特征的覆盖范围中（也可以参见§4.4.2中进行的实验）。在这项工作中，我们使用coreset子采样机制来减少M，我们发现这样可以减少推断时间同时保持性能。 从概念上讲，coreset选择旨在找到一个子集S⊂A，使得通过S计算的问题解决方案可以最接近地，特别是更快地由A计算出来[1]。根据特定的问题，感兴趣的coreset会有所不同。因为PatchCore使用最近邻计算（下一节），我们使用最小最大设施位置coreset选择，参见例如[48]和[49]，以确保在补丁级特征空间中，M-coreset MC的覆盖与原始内存库M相似。

M∗C的确切计算是NP-Hard的[54]，我们使用[48]中建议的迭代贪婪近似。为了进一步减少coreset选择时间，我们遵循[49]，利用Johnson-Lindenstrauss定理[11]通过随机线性投影ψ：Rd → Rd∗将元素 $m \in \mathcal{M}$ 的维度降低到d∗ < d。内存库的缩减总结如算法1所示。在符号方面，我们使用PatchCore-n%来表示原始内存库被子采样到的百分比n，例如，PatchCore-1%是M的100倍减少。图3给出了贪婪coreset子采样与随机选择的空间覆盖的可视印象。

### 3.3. 使用PatchCore进行异常检测 

通过标准修补特征记忆库 $\mathcal{M}$，我们估计测试图像 $x^{\text{test}}$ 的图像级异常分数 $s \in \mathbb{R}$，方法是计算其修补集合P(x_test)中测试修补特征的最大距离分数s*，即到每个相应最近邻m∗中的测试修补特征： � ∗ = max ⁡ � test ∈ � ( � test ) min ⁡ � ∈ � ( � test − � ) 2 2 s ∗ =max m test ​ ∈P(x test ​ ) ​ min m∈M ​ 2 (m test ​ −m) 2 ​ 为了得到s，我们使用缩放参数w对s*进行调整，以考虑邻域修补的行为：如果最接近异常候选m_{\text{test,∗}}、m∗的记忆库特征本身远离邻域样本，因此已经是一个罕见的标准情况，我们增加异常分数： � = ( 1 − exp ⁡ ∥ � test,∗ − � ∗ ∥ 2 ∑ � ∈ Nb ( � ∗ ) exp ⁡ ∥ � test,∗ − � ∥ 2 ) ⋅ � ∗ s=(1− ∑ m∈Nb(m∗) ​ exp∥m test,∗ ​ −m∥ 2 ​ exp∥m test,∗ ​ −m∗∥ 2 ​ ​ )⋅s ∗ 这里Nb(m∗)表示测试修补特征m∗的M中b个最近修补特征。我们发现这种重新加权比仅使用最大修补距离更健壮。给定s，分割直接跟随。方程7中的图像级异常分数（第一行）需要通过arg max操作计算每个修补的异常分数。通过根据它们的空间位置重新调整计算的修补异常分数，可以在同一步骤中计算分割图，类似于[14]。为了匹配原始输入分辨率（我们可能想要使用中间网络特征），我们通过双线性插值放大结果。此外，我们使用宽度为σ = 4的高斯核对结果进行了平滑处理，但没有优化此参数。