---
Title: "Finding Dino: A plug-and-play framework for\runsupervised detection of out-of-distribution\robjects using prototypes"
Publish: arXiv2024
Year: "2024"
Url: https://arxiv.org/pdf/2404.07664.pdf
创新点: 无监督
Month: "04"
---
## 摘要

在任何场景中检测和定位未知或分布外（OOD）对象可能是视觉领域中的一项具有挑战性的任务，特别是在涉及自动驾驶车辆或列车等自主系统的安全关键情况下。监督异常分割或开放世界物体检测模型依赖于对每个领域进行详尽注释的数据集进行训练，并且仍然难以区分背景和OOD对象。在这项工作中，我们提出了一个即插即用的通用框架 - PRototype-based zero-shot OOD detection Without Labels（PROWL）。这是一种基于推理的方法，不需要在领域数据集上进行训练，并依赖于从自监督预训练模型中提取相关特征。PROWL可以通过指定来自该领域的已知类别列表轻松适应于检测该领域中的OOD对象。

作为一种无监督方法，PROWL在提供的SegmentMeIfYouCan（SMIYC）基准测试中的RoadAnomaly和RoadObstacle数据集上，优于其他无辅助OOD数据训练的监督方法。我们还展示了它在其他领域（如铁路和海上）的适用性。 

关键词：OOD对象检测 · 异常分割 · 原型学习 

## 1 引言 

人工智能（AI）已经成为自主系统的基石 - 特别是在感知周围环境方面。在现实世界中运行的系统必须动态适应开放世界环境中的任何情况。这意味着在任何给定的场景中：系统应该能够理解其上下文，通常通过检测和定位相关对象来实现。为此，AI模型通常会根据给定的操作设计领域（ODD）中的对象类别进行广泛的训练。借助高质量的公开可用数据集，如Cityscapes，RailSem19和MODD，几个最先进的深度神经网络（DNN）为封闭的对象类别集提供了出色的性能。然而，它们无法识别和分类未知对象，即不属于任何训练类别的对象。在训练数据中从未学到的障碍物可能会出现，例如道路上的随机动物或海上无人表面舰船（USVs）前方的未知浮动障碍物。由于开放世界的设置，任何时候都可能出现大量此类未知或分布外（OOD）对象，几乎不可能用注释的数据集对所有可能的已知对象类别和对象变化进行详尽训练，特别是在复杂领域（如自动驾驶）中。

与图像分类相比，在基于摄像头的物体检测背景下，OOD检测的主要挑战在于明确区分未知对象和常见背景，即场景中不相关的任何物体。因此，大多数现有方法依赖于监督异常分割和在训练过程中使用选定的OOD样本。特别是后者是一种严重的限制，当尝试检测在模型训练时不知道的东西时。另一方面，开放世界物体检测最近引起了一些关注，但在理解什么是相关对象方面存在着应用依赖性的困难。 在这项工作中，我们提出了一种新颖的框架，用于在图像中检测未知对象：PRototype-based zero-shot OOD detection Without Labels（PROWL）。它可以以零-shot即插即用的方式在任何领域的场景中检测任意数量的未知对象，即在目标域上不需要任何额外的模型训练。它利用了来自预训练基础模型（如DINOv2）的丰富多样的特征，将已知对象类别稳健地捕获为原型特征库中的原型。然后，将这些原型的相似性用于计算每个给定测试图像的像素级相似度分数。这个分数可以进行阈值处理以检测OOD像素。

此外，我们提出将无监督分割提供的前景掩码与这些像素级分数相结合，以将它们细化为OOD或未知对象的单个实例的高质量掩码。通过利用来自基础模型的预训练视觉特征，这些特征提供了几乎任何对象的稳健表示，PROWL可以通过简单的推理步骤轻松跨应用域进行泛化，只需指定ODD类别列表即可确定相应的原型特征库。它可以在不需要对地面真实（GT）类别进行任何训练的情况下，在简单的推理步骤中检测未知对象，并且在性能上与现有的监督方法相媲美。据我们所知，PROWL是首个端到端框架，可用于在任何场景中无监督的零-shot OOD检测，而无需对地面真实（GT）类别进行任何训练。

在PROWL框架内，我们根据生成的前景掩码的质量比较了几种不同的无监督分割和检测方法的性能。在缺乏多对象场景下无监督异常分割的直接基线的情况下，我们进一步将我们的结果与来自已建立的SMIYC基准测试的其他监督分割方法进行了比较，基于给定的指标和数据集。此外，我们展示了PROWL在各种场景中发现未知对象的适用性，例如道路驾驶，铁路轨道，甚至海上。总之，我们的框架PROWL的主要贡献是：

- PROWL是第一个可以充分可靠地区分OOD对象和背景的无监督OOD对象检测和分割框架；
- PROWL是一种零-shot OOD对象检测框架，它依赖于来自基础模型的预训练特征，而不需要在领域数据上进行额外的训练；
- PROWL可以作为一个可适应的即插即用模块应用于任何场景中的新领域，而不需要领域特定的训练。我们通过应用到道路驾驶等新领域之外的新领域，如铁路和海上，来证明这一点。对于铁路领域，我们还通过创建带有修复OOD对象的数据集做出了额外贡献；
- PROWL在道路驾驶SMIYC基准测试的RoadAnomaly和RoadObstacle数据集的验证集上优于未经辅助OOD数据训练的监督方法，并在Fishyscapes基准测试中显示了与其他监督方法相当的性能。

## 相关工作

在视觉任务中，检测未知/OOD对象已经在不同的方向下得到了表述。

开放世界目标检测（OWOD）：与标准的封闭世界目标检测相比，OWOD提出了几个挑战，例如在潜在的未知对象上生成高质量的候选提议或将未知对象与背景区分开。最近的方法[14, 17, 34]探索了基于未知对象的目标度分数和通过增量学习和重新训练学习新类的概率模型。但是它们在将未知类别与背景区分开方面仍有很大的改进空间。

异常检测：异常或分布外（OOD）检测最初是在图像分类的背景下进行的。OOD检测被广泛用于找到与内部分布（ID）即训练数据不同的偏差。它包括分布偏移的偏差，例如扰动、天气或光照条件以及语义类别的变化，这些类别在训练期间之前未见过。源自图像分类的方法侧重于开发旨在量化由DNN的分类输出产生的置信值的不确定性的技术（例如，最大softmax概率[19]，马氏距离[22]）。其他方法通过使用生成模型[29]进行概率估计或通过负面或辅助数据（例如ODIN [23]，Outlier exposure [20]）从OOD样本中进行区分性训练来发现异常。另一项工作是在物体中找到异常或缺陷部分，例如工业异常检测中的缺陷部分检测[25]。尽管被开发为图像级别的异常/OOD检测，但大多数这些方法都可以通过根据每个像素的置信度找到潜在的异常来应用于异常分割。

异常分割：其目标是为图像中的每个像素预测异常概率。不同的工作使用了区分性或生成性方法[12,24]。大多数方法在训练期间依赖于辅助的分布外（OOD）数据。例如，最大熵[8]预测异常区域中的高熵，并使用OOD数据上的元分类器减少假阳性。DenseHybrid [15]结合了区分性和生成性建模。然而，基于像素的推理通常会产生噪声异常分数，特别是对于边界像素和定位不准确的异常。最近的方法专注于基于掩码的方法，这些方法将异常视为整个对象。这些方法预测区域而不是像素，导致较少的误报[9]。RbA [26]，EAM [16]，Maskomaly [1]和Mask2anomaly [28]利用基于掩码的分类。然而，所有这些方法都是使用监督标签训练的，有时还使用OOD数据。我们提出的方法消除了区分ID和OOD对象掩码的需要。我们将每个对象都学习为前景掩码，而没有OOD/ID对象类的概念。我们分别进行无监督的前景分割和OOD检测。

## 3 方法

在本节中，我们提供了我们的框架PROWL的概述。如图2中的架构图所示，PROWL包括三个模块 - 一个即插即用的原型匹配模块（第3.2节），一个用于使用SOTA无监督分割方法生成前景掩码的精化模块（第3.1节），以及最后的OOD检测模块（第3.3节）。 

### 3.1 准备工作：前景掩码生成 

在精化模块中，我们依赖于生成图像中每个对象的前景掩码，而不考虑它们的各自类别。我们发现SOTA无监督分割方法，如STEGO或CutLER，可以提供高质量的这些掩码。让使用这些方法生成的前景掩码表示为M = {m1, m2, ..., mN}。STEGO [18]是一个无监督语义分割模型，它利用对比损失从DINO [6]中提取预训练的无监督视觉特征，从而发现和分割语义对象，而无需对每个数据集进行人工监督。CutLER [31]是一种用于训练无监督目标检测和分割模型的方法。它专门在未标记的ImageNet [11]数据上进行训练，而不需要任何额外的域内数据。使用预训练的自监督特征，它使用MaskCut策略来发现多个粗糙的对象掩码。此外，它通过多轮自训练来训练检测器，以检测多个前景对象和相应的实例分割掩码。因此，与STEGO不同，CutLER不会以密集分割作为输出，而是为图像中检测到的前景对象提供零样本对象检测和实例分割。通过调整检测器阈值，CutLER可以检测到一系列大小的对象。 第 2 图：我们提出的框架PROWL的概述。首先，在即插即用的原型匹配模块中，通过从预训练基础模型中提取特征，为指定的ODD对象类别创建原型特征库，并生成原型匹配，以便为给定的测试图像生成每个对象类别的相应热图。热图显示了在测试图像中发现给定对象的最大激活（以黄色显示）。在OOD检测步骤中，不满足给定相似度阈值的对象像素被检测为OOD或“未知”（以红色显示）。为了进行更少噪声和更精确的OOD检测，我们将原型热图与原型热图结合的另一个精化步骤，首先以无监督方式提取场景中每个对象的前景掩码。最后，将这些前景掩码检测为ODD类或OOD。 

### 3.2 即插即用的原型匹配模块 

我们流程的第一步是为ODD中指定的每个类别创建具有原型的特征库。创建原型特征库：我们的目标是创建离线的“原型特征库”，它是特定对象类别或图像部分的全局特征空间表示。来自DINO [6]等基础模型的预训练特征使用通过师生网络的知识蒸馏进行自监督学习。DINO的作者观察到，自监督的Vision Transformer（ViT）可以在很大程度上学习图像块的基本感知分组和图像之间的语义对应关系。这种特性在DINOv2特征 [27]中得到了加强，它们是在更大的图像语料库上训练并蒸馏到更小的模型。因此，我们使用DINOv2的稳健的通用视觉特征，为ODD中的每个已知对象类别使用来自训练集分割样本的最少数量。我们假设ODD对象类别列表（由专家指定）可以在给定场景中找到。让它包含K个已知类别C = {c1，c2，...，cK}，以及每个类别P = {p1，p2，...，pK}的原型向量列表。假设对每个类别ck的每个原型向量pk有L个样本贡献。对于每个类别ck的每个对象实例ol ∈ ck类，提取实例的分割掩码sol，使得每个原型样本图像仅包含给定对象实例，并将背景归零，如图2所示。因此，计算对象实例的感兴趣区域的特征如下：zol = mean(z ∗ sol)。最后，更新类别ck的原型向量pk为：pk = {zol}；ol：l ∈ {1，L}，即扩展原型向量列表pk，直到添加了L个ck类的对象实例。对所有K个ODD对象类别重复此过程。与需要大量训练样本的监督训练方法相比，根据数据集的复杂性，一定数量的原型样本可以满足每个对象的L ∈ {5，20}（见第5.3节）。 原型匹配：对于每个输入图像x，基于来自DINOv2的特征向量计算推理输出z。现在，根据输入图像和原型向量之间的余弦相似性，将每个像素分类为K个类别中的一个，从而产生K个热图中的一个。因此，对于类别ck的原型热图通过取相应类别的原型向量pk和特征z之间的余弦相似性的最大值计算如下：hk = max (z · pk)。所有K个ODD类别的原型热图列表为H = {h1，h2，...，hK}。对于x中的每个像素[i，j]，分配的类别标签（y）和分数（v）如下所示：y_{[i,j]} = argmax(H)，v_{[i,j]} = max(H)。 

### 3.3 OOD检测 

下一步是根据方程2中每个像素的原型分类，检测OOD像素或对象掩码。通过将方程3中获得的余弦相似性分数与给定阈值t，t∈ [0,1]进行比较来完成这一步骤。对于每个像素，我们计算一个反标准化的余弦相似性分数如下所示：w_{[i,j]} = 1 - norm(v_{[i,j]})，norm(x) = \frac{x-min(x)}{max(x)-min(x)}。因此，其中w[i,j]> t的像素被指定为OOD像素。我们直接根据方程1得到的原型热图进行每个像素的OOD检测性能研究。虽然基于DINOv2特征的OOD检测可能是相当可靠的，但结果往往嘈杂，并且通常OOD像素可能无法精确地定位相关对象。因此，PROWL的输出可以通过将第3.1节中获得的实例级前景掩码与原型热图结合来进一步精化。由于这些模型是以自监督方式在大型通用数据集上训练的，因此它们可以可靠地在场景中检测到多个前景对象掩码，而无需已知或未知对象类的概念。这些掩码倾向于捕捉场景中每个实体的对象性，而不是像在监督检测情况下那样将其学习为背景。因此，现在将大多数像素指定为OOD的每个掩码m都被视为整个掩码的OOD。正如图2所示，PROWL与来自CutLER的前景掩码结合使用，正确检测并精确定位了“未知”的确切OOD对象掩码，而未与原型库中列出的任何类别匹配。

## 4 实现细节 

### 4.1 数据集 

我们通过在三个不同的操作设计领域（ODD）中评估我们的方法，展示了它们的即插即用性能。 

【道路驾驶场景】我们从Cityscapes [10]生成了城市驾驶道路ODD场景的原型。它是一个具有像素级和实例级语义场景理解的基准套件。为了在具有真实OOD对象的道路场景数据集上进行评估，我们参考了SegmentMeIfYouCan（SMIYC）[7]中的异常分割数据集和基准套件。它提供了两个新颖的真实世界数据集：RoadAnomaly21和RoadObstacle21。 RoadAnomaly21包括100个测试和10个验证图像，其中真实对象或动物作为OOD出现在场景中的任何位置。相比之下，RoadObstacle21具有出现在道路或自车轨道上的OOD对象（或障碍物）。SMIYC的作者保留了测试集的GT，只有通过将方法提交给官方基准才能访问分数。

此外，我们还在Fishyscapes [2]异常分割基准的FS Static子集上进行评估。它包括30张验证图像，其中包含从PASCAL VOC [13]合成叠加在Cityscapes图像上的通用对象。 

【铁路场景】对于铁路ODD，我们使用RailSem19 [33]数据集，该数据集提供了从铁路车辆（火车或有轨电车）的自我视角拍摄的多样化图像，其中包括轨道的广泛语义标注。关于OOD检测，在铁路场景中尚无公开可用的包含OOD对象的数据集。因此，我们创建了包含10张图像的验证数据。我们使用Inpaint Anything [32]，它使用SAM、LaMa和Stable Diffusion的组合，将潜在的OOD对象（如动物、汽车、手推车等）涂抹到RailSem19图像上。更多细节请参阅补充材料。 

【海上场景】在海上ODD（MODD）场景中，障碍物检测和分割对于无人表面舰艇（USVs）的自主操作非常普遍。在这里，任务是检测和分割所有位于天空、海洋类别之外的障碍物为“未知”。我们将其构建为OOD检测任务，其中原型是从MaStr1325（海上语义分割训练数据集）[4]的训练集中生成的。对于OOD检测评估，我们在相应的测试数据集上进行评估。我们不与MODS基准[5]进行比较，因为我们不包括考虑IMU校准的多模态数据用于海岸线检测的评估。 

4.2 实验设置 

PROWL是一种零训练方法，这意味着它不依赖于任何训练，而仅仅需要一些推断步骤。我们采用了DINO-v2 [27]的ViT-S/14作为PROWL的特征提取器，该模型在一个包含142百万图像的数据集上进行了预训练。我们观察到，当余弦相似度阈值（公式4）默认设为0.55，CutLER检测器阈值设为0.2时，在所有数据集上都获得了令人满意的性能。我们进一步报告说，根据OOD对象的大小和OOD数据集的复杂性，这个最优阈值往往足够在更高的值上产生满意的性能，如在Cityscapes的OOD数据集的消融研究中所示（第5.3节）。 

4.3 评估指标 

据我们所知，尚不存在关于从场景中检测多个未标记OOD对象的无监督OOD检测的先前工作。因此，对于这个任务，没有建立的基准和评估指标。接收者操作特征（ROC）曲线下面积（AUROC）是图像分类OOD检测的标准度量。然而，在具有高度不平衡的OOD对象数量的多个OOD对象检测和分割任务中，精确度-召回率曲线下面积（AUPRC）是更合适的选择。因此，为了与SMIYC基准提供的异常分割指标进行比较，我们使用AUPRC和在真正阳性率为95%时的假阳性率（FPR）指标进行像素级评估。此外，对于评估为二进制分割任务，我们选择了一个固定的余弦相似度阈值，用于所有数据集，并且对于确定为OOD的像素预测为1（阳性），否则为0。这个二进制预测掩码与GT掩码进行比较，并使用平均交集联合（mIoU）和F1得分进行评估。