---
Url: https://arxiv.org/pdf/2404.16789
---
## 持续学习大型语言模型：全面综述

**摘要**

近年来，基于静态、预先收集的通用数据集训练的大型语言模型 (LLM) 取得了巨大的成功，并催生了众多研究方向和应用。其中一个方向致力于解决将预训练 LLM 集成到动态数据分布、任务结构和用户偏好中的非凡挑战。这个问题的主要挑战在于平衡模型的适应性和知识保留。预训练的 LLM 在针对特定需求进行定制时，往往会在先前的知识领域出现显著的性能下降，这种现象被称为“灾难性遗忘”。虽然在持续学习 (CL) 社区中对此进行了广泛的研究，但在 LLM 领域，它呈现出新的表现形式。在本综述中，我们全面概述并详细讨论了在持续学习背景下，大型语言模型的当前研究进展。除了介绍预备知识外，本综述还分为四个主要部分：我们首先概述了持续学习 LLM，它包含两个连续性方向：垂直连续性（或垂直持续学习），即从一般能力到特定能力的持续适应；水平连续性（或水平持续学习），即跨时间和领域的持续适应（第 3 节）。在垂直连续性之后，我们总结了现代 CL 背景下 LLM 学习的三个阶段：持续预训练 (CPT)、领域自适应预训练 (DAP) 和持续微调 (CFT)（第 4 节）。然后，我们概述了 LLM 持续学习的评估协议以及当前可用的数据源（第 5 节）。最后，我们讨论了与 LLM 持续学习相关的一些有趣问题（第 6 节）。本综述揭示了 LLM 持续预训练、适应和微调领域相对较少被研究的现状，表明需要社区给予更多关注。需要立即关注的关键领域包括开发实用且可访问的评估基准，以及专门设计用于对抗遗忘和在不断发展的 LLM 学习范式中实现知识迁移的方法。本综述中审查的所有论文的完整列表可在 [https://github.com/Wang-ML-Lab/llm-continual-learning-survey](https://github.com/Wang-ML-Lab/llm-continual-learning-survey) 获取。

**1 引言**

近年来，大型语言模型 (LLM) 的发展展示了实现通用人工智能 (AGI) 的巨大潜力 [233, 27, 217, 2, 50, 7, 279, 280, 124]。研究人员观察到，随着参数规模的增加，多步推理、少样本上下文学习和指令遵循等复杂能力得到了提高 [304, 303, 334, 301, 198]。LLM 的发展具有重大影响和革命性意义，促使机器学习从业者重新考虑传统计算范式，以应对曾经具有挑战性的人类水平任务，例如问答、机器翻译和对话系统 [143, 11, 65]。然而，LLM 通常在包含通用领域的静态、预先收集的数据集上进行训练，导致性能随着时间的推移逐渐下降 [175, 120, 127, 119, 6, 68]，并在不同内容领域之间存在差异 [89, 127, 131, 273, 55, 91, 231, 46, 232]。此外，单个预训练的大型模型无法满足所有用户需求，需要进一步微调 [306, 307, 365, 307, 21, 365, 12, 133, 342, 230, 47]。虽然一种潜在的解决方案是重新收集预训练数据并根据特定需求重新训练模型，但这种方法成本高昂，在实际场景中不切实际。

为了有效地将 LLM 适应下游任务，同时最大限度地减少先前知识领域的性能下降，研究人员采用了持续学习的方法，也称为终身学习或增量学习 [223, 48, 282, 288]。持续学习受人类大脑中观察到的增量学习模式启发 [194, 128, 219, 328, 54, 216, 170, 193]，涉及按顺序在一系列任务上训练机器学习模型，期望保持所有任务的性能 [140, 161, 347, 240, 29, 80, 75, 74]。在整个训练过程中，模型对先前数据的访问受限或无法访问，这对保留过去的知识构成挑战，因为在当前任务学习期间，来自先前未见数据的优化约束条件不存在 [161, 265, 99, 173, 38, 240, 29, 260]。这种挑战被称为灾难性遗忘，自持续学习研究开始以来一直是其核心问题。多年来，研究人员探索了各种技术来减轻机器学习模型中的遗忘。这些技术包括基于重放的方法 [38, 254, 240, 29, 260]、参数正则化 [140, 241, 4, 270] 和模型架构扩展 [237, 287]。这些技术共同显着推进了在跨各种任务、模型架构和学习范式的持续学习中实现零遗忘的目标。

在按顺序训练和调整 LLM 的背景下，CL 的重要性也在发生语义上的转变。为了更好地突出这种持续的转变，在本综述中，我们全面概述并详细讨论了在 CL 背景下 LLM 的当前研究进展。对于持续学习 LLM 的总体情况，我们将其分为从业者需要解决的两个连续性方向（第 3 节）：

- **垂直连续性（或垂直持续学习）**：指的是 LLM 从大规模通用领域过渡到小规模特定领域时持续进行的适应过程，涉及学习目标和执行实体的转变。例如，医疗机构可能会开发针对医疗领域的 LLM，同时保留其针对用户的一般推理和问答能力。
    
- **水平连续性（或水平持续学习）**：指的是跨时间和领域的持续适应，通常涉及多个训练阶段，并且更容易受到灾难性遗忘的影响。例如，社交媒体平台会持续更新 LLM 以反映最新趋势，确保下游服务（例如广告和推荐）的准确性，同时为现有用户保持无缝的用户体验。
    

在图 1 中，遵循垂直连续性，我们描述了现代 CL 中 LLM 学习的三个关键阶段：持续预训练 (CPT)、领域自适应预训练 (DAP) 和持续微调 (CFT)（第 4 节）。在 CPT 中，现有研究主要调查三种类型的分布变化：时间、内容级别和语言级别。每种类型都呈现出不同的关注点和挑战。在 DAP 中，虽然它主要被视为为下游任务准备 LLM 的过程，但 CL 评估和技术经常被使用。然而，考虑到传统 CL 社区的成熟度，这些技术缺乏多样性。在 CFT 中，我们关注 LLM 学习的新兴领域，涵盖了持续指令调优 (CIT)、持续模型细化 (CMR)、持续模型对齐 (CMA) 和持续多模态 LLM (CMLLM) 等主题。接下来，我们介绍了公开可用的评估协议和基准的汇编（第 5 节）。我们以讨论 LLM 持续学习的最新出现属性、传统增量学习类型和内存约束在持续 LLM 背景下的作用变化以及该主题的未来研究方向来结束我们的综述（第 6 节）。

**2 预备知识**

在本节中，我们将概述大型语言模型 (LLM) 和持续学习 (CL) 的基本概念，确保不熟悉这些主题的读者能够清晰地理解。我们首先介绍本文使用的符号。随后，我们将讨论 LLM 的预训练和下游适应，以及主流的 LLM 系列（第 2.1 节），然后介绍社区研究的基本持续学习技术（第 2.2 节）。

**2.1 大型语言模型**

在过去的二十年中，神经语言建模已成为深度学习的主要领域，并取得了显着且快速的进展。主要基于 Transformer 架构构建的预训练语言模型 (PLM)（如 BERT）通过在大规模无标签文本语料库上的广泛预训练建立了一个通用的隐藏嵌入空间。在预训练和微调范式之后，PLM 在少量特定任务数据上进行微调后，在各种自然语言处理任务中表现出良好的性能 [67, 171, 235]。

关于缩放定律的研究表明，增加模型规模可以增强语言模型的能力 [129, 107]。通过将参数扩展到数十亿甚至数千亿，并在庞大的文本数据集上进行训练，PLM 不仅展示了卓越的语言理解和生成能力，而且还表现出新兴能力，例如上下文学习、指令遵循和多步推理，这些能力在小型语言模型（如 BERT）中是缺乏的 [304, 303, 334, 301, 198]。这些较大的模型通常被称为大型语言模型 (LLM)。

**2.1.1 LLM 的预训练**

预训练对于语言模型获取广泛的语言表示至关重要。仅解码器模型通常在预训练期间使用概率语言建模 (LM) 任务。在本文中，LM 特指自回归 LM。给定一个令牌序列 x = [x1, x2, ..., xN]，LM 根据所有先前的令牌 x<t = [x1, x2, ..., xt-1] 自回归地预测下一个令牌 xt，并通过最小化负对数似然来训练整个网络：

```
LLM(x) ≜ - Σ_{t=1}^N log P(xt|x<t)  (1)
```

content_copyUse code [with caution](https://support.google.com/legal/answer/13505487).

其中 P(x1|x<1) ≜ P(x1) 是第一个令牌的无条件概率估计。三种最流行的仅解码器模型系列是 GPT、PaLM 和 LLaMA。由 OpenAI 开发的 GPT 系列包括 GPT-2 [233]、GPT-3 [27]、ChatGPT [217] 和 GPT-4 [2] 等模型。值得注意的是，GPT-3 是第一个表现出小型 PLM 中没有的新兴能力的 LLM。另一个值得注意的系列是 Google 开发的 PaLM（路径语言模型），它与 GPT 系列相当 [50, 7]。虽然 GPT 和 PaLM 系列都是闭源的，但 Meta 发布的 LLaMA 是目前最流行的开源 LLM 系列 [279, 280]。这些模型的权重在非商业许可下提供给研究社区。

掩码语言建模 (MLM) 任务是仅编码器模型（如 BERT）[67, 171] 的常见预训练目标。在 MLM 中，输入序列中的某些令牌被掩码，表示为 m(x)，并使用未掩码部分 x\m(x) 来预测掩码部分。与传统的 LM 类似，MLM 的总体目标是最小化负对数似然，如以下等式所示：

```
LMLM(x) ≜ - Σ_{xb∈m(x)} log P(xb|x\m(x))  (2)
```

content_copyUse code [with caution](https://support.google.com/legal/answer/13505487).

一些编码器-解码器架构模型（如 T5 [235]）也使用序列到序列 MLM 任务作为预训练目标。它们将掩码句子作为编码器输入，并使用解码器按顺序预测掩码令牌。

**2.1.2 LLM 的适应**

在预训练之后，LLM 需要进行有效的适应，以更好地服务于下游任务。已经针对特定目标提出了一系列适应方法。由于 LLM 在预训练期间主要侧重于生成语言连贯的文本，因此它们的性能可能不一定与人类用户的实际需求相符，也不一定符合人类的价值观、偏好和原则。此外，由于预训练数据的时效性等问题，LLM 还可能遇到知识截止或谬误问题。因此，提出了指令调优、模型细化和模型对齐来解决这些问题 [353, 218, 234, 60]。以下是 LLM 三种适应任务的正式定义。

**定义 2.1（指令调优，IT）** 设 h(x) 是一个语言模型，它将数据 x 作为输入，x 通常由自然语言指令或查询组成。指令调优 (IT) 是一种专门的训练方法，旨在增强模型准确有效地响应特定指令的能力。IT 的目标是通过使用指定的训练示例集 I = {(xi, ybi)}^N_{i=1} 来调整 h 的参数，其中 ybi 表示 x 的期望输出。此集合经过精心策划，以针对需要改进性能的特定任务或功能。形式上，更新后的模型 h' 定义如下：

```
h'(x0) = yb0, ∀(x0, yb0) ∈ I  (3)
```

content_copyUse code [with caution](https://support.google.com/legal/answer/13505487).

**定义 2.2（模型细化，MR）** 假设我们有一个模型 h(x)，它将数据 x（例如，自然语言查询）作为输入。考虑一个大小为 N 的编辑集 E = {(xe, ye, ybe)}^N_{e=1}，其中 ybe 表示 xe 的真实标签，但模型错误地为 xe 输出 ye。模型细化 (MR) 旨在有效地将模型从 h 更新到 h'，使其能够正确预测编辑集 E，同时保留 E 以外的原始输出。形式上，我们的目标是找到满足以下条件的 h'：

```
h'(x0) = { 
yb0 if (x0, yb0) ∈ E,
h(x0) otherwise 
}  (4)
```

content_copyUse code [with caution](https://support.google.com/legal/answer/13505487).

**定义 2.3（模型对齐，MA）** 考虑一个模型 h(x)，它被设计用于在决策场景中处理输入 x。将大小为 M 的对齐数据集定义为 A = {(xa, ya, yba)}^M_{a=1}，其中 ya 表示模型对输入 xa 的原始决策，yba 表示符合指定道德准则或预期结果的对齐决策。模型对齐 (MA) 的目标是将 h 修改为 h'，以便对于对齐数据集中的任何 xa，h'(xa) 都产生 yba，从而使模型的决策与对齐标准一致。形式上，

```
h'(x0) = yb0, ∀(x0, yb0) ∈ A  (5)
```

content_copyUse code [with caution](https://support.google.com/legal/answer/13505487).

**备注** 将防止对一般知识进行灾难性遗忘的约束条件纳入 IT，以及在 MA 的优化目标中减少对齐税 [165] 仍然是一个悬而未决的问题。简单地从等式 4 中的模型细化约束条件扩展，即 h'(x0) = h(x0), ∀(x0, yb0) ∈ A/，在这种情况下可能过于严格，因为我们当然希望 A 所代表的偏好能够泛化到其他相似但不同的输入。

**2.2 持续学习**

当代机器学习模型与人类学习过程不同。人类在跨任务学习时逐渐积累知识和技能，而不会在先前任务上出现明显的性能下降 [194, 128, 219, 328, 54, 216, 170, 193]。相反，机器学习模型通常以数据为中心，最小化后续任务的训练损失会导致模型在旧任务上失败，这种现象被称为“灾难性遗忘”。解决这一挑战是持续学习研究的重点。在持续学习社区中，对如何在不遗忘的情况下有效地使模型适应一系列连续任务的问题进行了广泛的研究 [223, 48, 282, 288]。这些研究是在持续学习的著名内存约束下进行的，如下所示。

**定义 2.4（持续学习的内存约束）** 假设 T 组观测值 {St ∼ Tt}^T_{t=1} 作为序列输入，其中 {Tt}^T_{t=1} 表示 T 个任务分布。在 t > 1 的学习阶段，观测值集 {Si}^{t-1}_{i=1} 不可访问（强约束）或部分可访问（弱约束）。

**备注** 在持续学习的早期阶段，工作主要集中在强内存约束 [140, 161, 4, 173]；随着研究领域的进展，更多地关注将内存约束放宽到一个用于重放的小缓冲区 [239, 38, 29, 260]；一些现代持续学习工作考虑完全放弃内存约束，但存在计算预算约束的场景 [31, 228, 283]。

**2.2.1 三种类型的持续学习**

主要存在三种类型的持续学习场景：任务增量学习 (TIL)、领域增量学习 (DIL) 和类增量学习 (CIL)。为了为后续讨论奠定基础（如表 3 和第 6.2 节所示），我们遵循 [282, 139, 288] 提出的概念框架，并为这三种持续学习场景提供正式定义。

**定义 2.5（任务增量学习，TIL）** 假设 T 个任务分布 {Tt}^T_{t=1} 作为序列输入，其中 Tt 表示第 t 个任务的输入空间和标签空间 (Xt, Yt) 上的联合分布。将 X ≜ ∪^T_{t=1} Xt 和 Y ≜ ∪^T_{t=1} Yt 分别表示输入空间和标签空间的并集。在定义 2.4 中定义的内存约束下，任务增量学习 (TIL) 旨在找到满足以下条件的最优假设 h* : X × [T] → Y：

```
h* = arg min_h Σ^T_{t=1} E_{(x,y)∼Tt}[1_{h(x,t)≠y}]  (6)
```

content_copyUse code [with caution](https://support.google.com/legal/answer/13505487).

**定义 2.6（领域增量学习，DIL）** 假设 T 个领域分布 {Dt}^T_{t=1} 作为序列输入，其中 Dt 表示第 t 个在共享输入空间和标签空间 (X, Y) 上的联合分布。在定义 2.4 中定义的内存约束下，领域增量学习 (DIL) 旨在找到满足以下条件的最优假设 h* : X → Y：

```
h* = arg min_h Σ^T_{t=1} E_{(x,y)∼Dt}[1_{h(x)≠y}]  (7)
```

content_copyUse code [with caution](https://support.google.com/legal/answer/13505487).

**定义 2.7（类增量学习，CIL）** 假设 T 个任务分布 {Tt}^T_{t=1} 作为序列输入，其中 Tt 表示第 t 个任务的输入空间和标签空间 (Xt, Yt) 上的联合分布。将 X ≜ ∪^T_{t=1} Xt 和 Y ≜ ∪^T_{t=1} Yt 分别表示输入空间和标签空间的并集。在定义 2.4 中定义的内存约束下，类增量学习 (CIL) 旨在找到满足以下条件的最优假设 h* : X → [T] × Y：

```
h* = arg min_h Σ^T_{t=1} E_{(x,y)∼Tt}[1_{h(x)≠(t,y)}]  (8)
```

content_copyUse code [with caution](https://support.google.com/legal/answer/13505487).

**备注** 在 TIL 中，通常具有共享的输入空间 X = Xt, ∀t ∈ [T]，但标签分布 Yt 的空间可以是不同的 (Yi ∩ Yj = ∅, ∀i ≠ j)、部分共享的 (Yi ∩ Yj ≠ ∅, ∃i ≠ j) 或在不同任务之间共享的 (Y = Yt, ∀t ∈ [T])。在 DIL 中，任务以相同的格式定义，即相同的输入空间 X 和相同的输出空间 Y。在推理过程中，没有为假设提供任务 ID，这意味着持续学习模型需要捕获域不变特征和标签之间的模式。DIL 通常被认为比 TIL 更难。CIL 通常被视为最具挑战性的持续学习场景，因为模型需要同时推断标签和任务 ID。CIL 的另一种可能表述是将其表示为 DIL，但输出标签空间是不相交的，即 Yi ∩ Yj = ∅, ∀i ≠ j。

**2.2.2 持续学习技术**

如前面三个定义所述，持续学习的目标是找到一个假设，该假设可以最大限度地降低所有任务/领域的风险。以领域增量学习为例 [260]，在第 t 个学习阶段，理想的训练目标 L(h) 是：...

自回归地预测下一个令牌 xt，并通过最小化负对数似然来训练整个网络：

$LLM(x) ≜ -\sum_{t=1}^N log P(xt|x<t)$, (1)

其中 $P(x_1|x<1) ≜ P(x_1)$ 是第一个令牌的无条件概率估计。三种最流行的仅解码器模型系列是 GPT、PaLM 和 LLaMA。由 OpenAI 开发的 GPT 系列包括 GPT-2 [233]、GPT-3 [27]、ChatGPT [217] 和 GPT-4 [2] 等模型。值得注意的是，GPT-3 是第一个表现出小型 PLM 所没有的新兴能力的 LLM。另一个值得注意的系列是谷歌开发的 PaLM（Pathways Language Model），它与 GPT 系列相当 [50, 7]。虽然 GPT 和 PaLM 系列都是闭源的，但 Meta 发布的 LLaMA 是目前最流行的开源 LLM 系列 [279, 280]。这些模型的权重在非商业许可下提供给研究社区。

掩码语言建模 (MLM) 任务是 BERT [67, 171] 等仅编码器模型的常见预训练目标。在 MLM 中，输入序列中的某些令牌被掩码，表示为 $m(x)$，未掩码部分 $x\m(x)$ 用于预测掩码部分。与传统的 LM 类似，MLM 的总体目标是最小化负对数似然，如以下公式所示：

$L_{MLM}(x) ≜ -\sum_{x_b∈m(x)} log P(x_b|x\m(x))$. (2)

一些编码器-解码器架构模型（例如 T5 [235]）也使用序列到序列 MLM 任务作为预训练目标。它们将掩码句子作为编码器输入，并利用解码器按顺序预测掩码令牌。

**2.1.2 LLM 的适应**

在预训练之后，需要有效地调整 LLM 以更好地服务于下游任务。针对特定目标，已经提出了一系列调整方法。由于 LLM 在预训练期间主要关注生成语言连贯的文本，因此它们的性能可能不一定与人类用户的实际需求相符，也不一定符合人类的价值观、偏好和原则。此外，由于预训练数据的时效性等问题，LLM 也可能遇到知识截止或谬误问题。因此，已经提出了指令调优、模型细化和模型对齐来解决这些问题 [353, 218, 234, 60]。以下是 LLM 三种调整任务的正式定义。

**定义 2.1（指令调优，IT）** 假设 $h(x)$ 是一个以数据 $x$ 作为输入的语言模型，$x$ 通常由自然语言指令或查询组成。指令调优 (IT) 是一种专门的训练方法，旨在增强模型准确有效地响应特定指令的能力。IT 的目标是通过使用一组指定的训练示例 $I = {(x_i, y_{bi})}{i=1}^N$ 来调整 $h$ 的参数，其中 $y{bi}$ 表示 $x$ 的期望输出。这组示例经过精心策划，以针对需要改进性能的特定任务或功能。形式上，更新后的模型 $h'$ 定义如下：

$h'(x_0) = y_{b0}, ∀(x_0, y_{b0}) ∈ I$. (3)

**定义 2.2（模型细化，MR）** 假设我们有一个以数据 $x$（例如，自然语言查询）作为输入的模型 $h(x)$。考虑一个大小为 N 的编辑集 $E = {(x_e, y_e, y_{be})}{e=1}^N$，其中 $y{be}$ 表示 $x_e$ 的真实标签，但模型错误地为 $x_e$ 输出 $y_e$。模型细化 (MR) 旨在有效地将模型从 $h$ 更新为 $h'$，使其能够正确预测编辑集 $E$，同时保留 $E$ 以外的原始输出。形式上，我们的目标是找到满足以下条件的 $h'$：

$h'(x_0) =  
\begin{cases}  
y_{b0} & \text{if } (x_0, y_{b0}) ∈ E \  
h(x_0) & \text{otherwise}  
\end{cases}$. (4)

**定义 2.3（模型对齐，MA）** 考虑一个模型 $h(x)$，它被设计用来处理决策场景中的输入 $x$。定义一个大小为 M 的对齐数据集为 $A = {(x_a, y_a, y_{ba})}{a=1}^M$，其中 $y_a$ 表示模型对输入 $x_a$ 的原始决策，$y{ba}$ 表示符合指定道德准则或期望结果的对齐决策。模型对齐 (MA) 的目标是将 $h$ 修改为 $h'$，以便对于对齐数据集中的任何 $x_a$，$h'(x_a)$ 产生 $y_{ba}$，从而使模型的决策与对齐标准保持一致。形式上，

$h'(x_0) = y_{b0}, ∀(x_0, y_{b0}) ∈ A$. (5)

**备注** 将防止灾难性遗忘一般知识的约束条件纳入 IT，以及在 MA 的优化目标中减少对齐税 [165] 仍然是一个悬而未决的问题。简单地从公式 4 中的模型细化约束条件进行扩展，即 $h'(x_0) = h(x_0), ∀(x_0, y_{b0}) ∈ A^c$，在这种情况下可能过于严格，因为我们当然希望 $A$ 所代表的偏好能够推广到其他类似但不同的输入。

**2.2 持续学习**

当代机器学习模型与人类学习过程不同。人类在完成任务的过程中逐渐积累知识和技能，而不会导致先前任务的性能显著下降 [194, 128, 219, 328, 54, 216, 170, 193]。相反，机器学习模型通常以数据为中心，最小化后续任务的训练损失会导致模型在旧任务上失败，这种现象被称为“灾难性遗忘”。解决这一挑战是持续学习研究的重点。在持续学习社区中，在不遗忘的情况下有效地将模型适应一系列连续任务的问题得到了广泛的研究 [223, 48, 282, 288]。这些研究是在持续学习的著名内存约束下进行的，如下所示。

**定义 2.4（持续学习的内存约束）** 假设 T 组观测值 ${S_t ∼ T_t}{t=1}^T$ 按顺序输入，其中 ${T_t}{t=1}^T$ 表示 T 个任务分布。在 $t > 1$ 的学习阶段，观测值集 ${S_i}_{i=1}^{t-1}$ 无法访问（强约束）或部分可访问（弱约束）。

**备注** 在持续学习的早期阶段，研究主要集中在强内存约束 [140, 161, 4, 173]；随着研究领域的进展，更多精力放在将内存约束放宽到一个小缓冲区用于重放 [239, 38, 29, 260]；一些现代持续学习研究考虑了完全放弃此约束但存在计算预算约束的情况 [31, 228, 283]。

**2.2.1 持续学习的三种类型**

主要有三种类型的持续学习场景：任务增量学习 (TIL)、领域增量学习 (DIL) 和类增量学习 (CIL)。为了为后续讨论奠定基础（如表 3 和第 6.2 节所示），我们遵循 [282, 139, 288] 提出的概念框架，并为这三种持续学习场景提供正式定义。

**定义 2.5（任务增量学习，TIL）** 假设 T 个任务分布 ${T_t}{t=1}^T$ 按顺序输入，其中 $T_t$ 表示第 t 个任务的输入空间和标签空间 $(X_t, Y_t)$ 上的联合分布。将 $X ≜ \bigcup{t=1}^T X_t$ 和 $Y ≜ \bigcup_{t=1}^T Y_t$ 分别表示为输入和标签空间的并集。在定义 2.4 中定义的内存约束下，任务增量学习 (TIL) 旨在找到最优假设 $h^*: X × [T] → Y$，使其满足：

$h^* = arg \min_h \sum_{t=1}^T E_{(x,y)∼T_t}[\mathbb{1}_{h(x,t)≠y}]$. (6)

**定义 2.6（领域增量学习，DIL）** 假设 T 个领域分布 ${D_t}_{t=1}^T$ 按顺序输入，其中 $D_t$ 表示第 t 个共享输入空间和标签空间 $(X, Y)$ 上的联合分布。在定义 2.4 中定义的内存约束下，领域增量学习 (DIL) 旨在找到最优假设 $h^*: X → Y$，使其满足：

$h^* = arg \min_h \sum_{t=1}^T E_{(x,y)∼D_t}[\mathbb{1}_{h(x)≠y}]$. (7)

**定义 2.7（类增量学习，CIL）** 假设 T 个任务分布 ${T_t}{t=1}^T$ 按顺序输入，其中 $T_t$ 表示第 t 个任务的输入空间和标签空间 $(X_t, Y_t)$ 上的联合分布。将 $X ≜ \bigcup{t=1}^T X_t$ 和 $Y ≜ \bigcup_{t=1}^T Y_t$ 分别表示为输入和标签空间的并集。在定义 2.4 中定义的内存约束下，类增量学习 (CIL) 旨在找到最优假设 $h^*: X → [T] × Y$，使其满足：

$h^* = arg \min_h \sum_{t=1}^T E_{(x,y)∼T_t}[\mathbb{1}_{h(x)≠(t,y)}]$. (8)

**备注** 在 TIL 中，通常具有共享的输入空间 $X = X_t, ∀t ∈ [T]$，但标签分布 $Y_t$ 的空间可以是不同的 $(Y_i ∩ Y_j = ∅, ∀i ≠ j)$、部分共享的 $(Y_i ∩ Y_j ≠ ∅, ∃i ≠ j)$ 或在不同任务之间共享的 $(Y = Y_t, ∀t ∈ [T])$。在 DIL 中，任务以相同的格式定义，即相同的输入空间 $X$ 和相同的输出空间 $Y$。在推理过程中，没有为假设提供任务 ID，这意味着持续学习模型需要捕获领域不变特征和标签之间的模式。DIL 通常被认为比 TIL 更难。CIL 通常被视为最具挑战性的持续学习场景，因为模型需要同时推断标签和任务 ID。CIL 的另一种可能公式是将其表示为 DIL，但输出标签空间是不相交的，即 $Y_i ∩ Y_j = ∅, ∀i ≠ j$。

**2.2.2 持续学习技术**

如前三个定义所述，持续学习的目标是找到一个假设，该假设可以最小化所有任务/领域的风险。以领域增量学习为例 [260]，在第 t 个学习阶段，理想的训练目标 $L(h)$ 为：

$L(h) ≜ \sum_{i=1}^{t-1} L_{D_i}(h)  
\bigg| {\text{过去领域}} + L{D_t}(h)  
\bigg| _{\text{当前领域}}$. (9)

由于内存限制（定义 2.4），过去领域的目标通常难以衡量或优化。因此，设计持续学习算法的核心在于在不违反内存约束的情况下为第一项确定合适的代理学习目标。现有的持续学习技术可以大致分为五类：（i）基于重放的，（ii）基于正则化的，（iii）基于架构的，（iv）基于优化的和（v）基于架构的 [61, 288]。在这里，我们将简要介绍前三类持续学习技术，因为它们在持续学习大型语言模型中得到了广泛的应用。

**基于重放的方法** 基于重放的持续学习方法通过为每个任务 $T_i$ 保留一个小型缓冲区 ${M_i}_{i=1}^{t-1}$ 来存储先前观察到的数据示例，从而采用弱内存约束。形式上，这些方法寻求优化以下经验训练目标：

$L_{b_{replay}}(h) ≜ \sum_{i=1}^{t-1} L_{b_{M_i}}(h)  
\bigg| {\text{过去领域的代理}} + L{b_{S_t}}(h)  
\bigg| _{\text{当前领域}}$, (10)

其中 $L_{b_S}$ 表示在示例集 $S$ 上评估的经验损失项。通常被视为持续学习的简单解决方案，基于重放的方法在理论上可能导致泛化界限松散 [260]。尽管如此，它们因其简单性、稳定性和高性能而受到重视，即使使用小的情景内存也是如此 [38, 240]。例如，DER++ [29] 通过重放一小部分过去的示例及其 logits（称为暗经验重放）来证明性能的持续提升。ESM-ER [250] 引入了错误敏感度调制 (ESM) 来减轻由高错误新示例引起的突然表示漂移。基于重放的持续学习研究的一个重要方向是提高缓冲区维护的样本效率。例如，[239] 基于 herding 对样本选择进行优先级排序，以在整个类增量学习过程中准确地建模类均值。[361] 提出存储低保真示例以实现内存高效的样本集维护。RM（Rainbow Memory）[15] 引入了基于每个样本不确定性估计和数据增强的多样性感知内存更新，用于类增量学习。

**基于正则化的方法** 假设 $h_{θ_{t-1}}$ 是在第 t-1 阶段训练后产生的假设，由 $θ_{t-1}$ 参数化。基于正则化的方法使用正则化项作为过去领域损失的代理，该代理由参数空间中的距离决定。

$L_{b_{reg}}(h_θ) ≜ λ · ∥θ - θ_{t-1}∥_Σ  
\bigg| {\text{过去领域的代理}} + L{b_{S_t}}(h_θ)  
\bigg| _{\text{当前领域}}$, (11)

其中 $∥v∥_Σ = v^⊤Σv$ 是在正半定矩阵 $Σ$ 上评估的向量范数，$λ$ 是正则化系数，它是一个超参数，用于平衡过去知识的保留和当前知识的学习。引入矩阵 $Σ$ 的目的是衡量每个参数及其相关性在保留过去知识方面的重要程度。在实践中，为了减少计算开销，通常设计对角矩阵来仅编码每个参数的重要性。例如，弹性权重合并 (EWC) 采用贝叶斯视角，使用 Fisher 信息矩阵 (FIM) 的对角值作为参数 Hessian 矩阵的近似。这形成了一个用于持续学习的顺序最大后验 (MAP) 优化 [140]。内存感知突触 (MAS) 以在线和无监督的方式计算参数重要性，通过训练期间累积的绝对梯度来定义重要性 [4]。还值得注意的是，当 $Σ = I$ 退化为单位矩阵时，正则化项简化为基本的 $l_2$ 惩罚项，对每个参数进行均匀惩罚，这在某些持续学习 LLM 的情况下可能非常有效 [243]。

**基于架构的方法** 动态扩展网络架构以吸收新知识被认为是最有效的持续学习形式 [300, 299]。这种方法主要解决适应性挑战，当任务 ID 在推理过程中可用或可以正确推断时，可以实现零遗忘 [91, 308]。然而，由于任务 ID 推断的难度，架构扩展主要用于任务增量学习，但在领域增量或类增量学习中很少被探索。渐进式神经网络 (PNN) 提出随着新任务的出现学习横向连接的神经元，确保不遗忘并能够将先前学习的神经元迁移到未来的任务 [247]。与 ViT [71] 等预训练的骨干大型模型一起，CoLoR [308] 为不同的任务训练各种低秩自适应 (LoRA) 模块。它估计并存储每个任务的原型，并在测试期间利用预训练模型的自然聚类能力来推断任务 ID，选择相应的 LoRA 组件进行预测生成。在持续学习 LLM 领域，随着参数高效微调 (PEFT) 应用于大型模型 [259, 5, 109, 66, 146, 159] 的兴起，架构扩展再次流行起来，我们将很快深入探讨这一主题 [330, 291, 149, 120, 127, 221, 327, 310]。

**3 持续学习与大型语言模型：概述**

大型语言模型 (LLM) 在各个维度上都很广泛，包括模型参数的大小、预训练数据集、计算资源、项目团队和开发周期 [233, 27, 217, 2, 50, 7, 279, 280]。LLM 的巨大规模给开发团队带来了显着的挑战，尤其是在环境快速变化的情况下保持 LLM 的更新 [6, 127, 68, 120, 119]。例如，在 2023 年，用户每天发布的新推文平均超过 5 亿条 1，即使在“小”规模的数据子集上进行训练也是不可负担的。考虑到 LLM 对下游应用的级联影响，有效可靠地调整 LLM 变得更加重要。下游用户通常缺乏收集和存储大规模数据、维护大规模硬件系统和自己训练 LLM 的专业知识。可回收调优 [231] 是一项开创性研究，明确概述了现代 LLM 生产管道的供应商-消费者结构。在供应商方面，模型在一系列大规模无标签数据集上持续进行预训练。在每次发布预训练模型后，消费者都需要利用更强大、更先进的上游模型来获得更好的下游性能。为了提高下游消费者的微调效率，他们首先对持续预训练的 LLM 进行了一些关键观察，重点关注模式连通性和功能相似性。此外，他们还建议在上游预训练 LLM 进行重大更新后，重复使用过时的微调组件。基于可回收调优 [231] 引入的概念框架，我们为现代生产管道构建了一个全面的框架，涵盖了 LLM 持续预训练、适应和部署的各种研究，如图 1 所示。在本综述中，我们的框架与现有研究 [314] 的不同之处在于，它包含了两个连续性方向：垂直连续性和水平连续性。

**3.1 垂直连续性（垂直持续学习）**

定义：垂直连续性（或垂直持续学习）在现有文献中已经隐式或显式地研究了很长时间；它涉及从通用领域和任务到特定领域和任务的一系列适应过程 [91, 243, 88, 327, 323]。沿着这个轴，训练任务逐渐从通用预训练过渡到下游任务，这些任务通常由生产管道中的不同实体承担 [231]。垂直连续性的特点是数据包容性、任务范围和计算资源的层次结构。图 1 显示了 LLM 中垂直连续性的典型管道，即“预训练”→“领域自适应训练”→“下游微调” [185, 152, 63, 93, 369, 88, 92, 52, 311, 310, 327, 243, 187, 115]：

- **预训练**：在预训练阶段，需要来自不同领域的大量数据来开发通用 LLM。这个阶段需要一个规模相当的研究和开发团队专门负责模型的训练和基准测试，并需要大量的计算资源。
    
- **领域自适应预训练**：随后，下游机构可以选择领域自适应预训练，使用上游供应商无法获得的特定领域数据来针对特定任务调整模型。
    
- **微调**：最后，LLM 在部署之前在带注释的下游任务数据上进行微调。
    

在整个过程中，未标记的特定领域数据集的规模比上游预训练阶段小，但比最终的下游任务微调阶段大。这种模式也扩展到计算资源、团队规模和其他因素。值得注意的是，垂直连续性可能涉及三个以上的阶段 [215, 166, 245, 115]。在实际应用中，在领域自适应预训练期间，可以添加额外的层来适应多个实体，例如具有不同目标但在同一领域内运作的各个部门。

**垂直遗忘**：我们将模型在垂直持续学习过程中对一般知识的性能下降称为“垂直遗忘”。如图 2 所示，通常对于垂直持续学习，上游任务的数据分布部分覆盖下游任务，这意味着模型可以从一个良好的初始化开始进行后续阶段的训练。然而，为了防止垂直遗忘，需要解决两个重大挑战：

- **任务异质性**：由于上游任务和下游任务的制定方式存在固有的差异，任务异质性会导致模型结构和训练方案的差异，这长期以来被认为是一个主要的障碍 [239, 161, 316, 212, 139]。为了缓解这个问题，从业者通常采用一些方法，例如在下游阶段冻结共享参数，或者重新制定下游任务以匹配预训练任务的结构 [330, 291, 149, 221, 327, 310]。
    
- **无法访问的上游数据**：这个挑战主要来自承担垂直持续学习的各个实体之间不同的机密级别。根据不同协议收集和整理的数据可能无法被某些下游实体访问。这种情况比传统 CL 中提出的严格内存约束更具挑战性（定义 2.4），因为后一种情况的算法依赖于在特定时间点访问先前数据以进行参数重要性测量 [140, 4] 或重放 [240, 38, 29, 260]。为了解决无法访问上游数据的挑战，现有方法要么使用公共数据集，要么生成伪示例来创建代理预训练数据集 [230]。
    

**3.2 水平连续性（水平持续学习）**

定义：水平连续性（或水平持续学习）是指跨时间和领域的持续适应，这是持续学习社区广泛探索的一个主题。保持水平连续性的主要原因在于数据分布随时间变化的动态特性。为了与这些内容变化保持同步，LLM 必须增量地学习新出现的数据。否则，重新训练的成本将变得过高且不切实际 [37, 6, 271, 323]。经验证据始终表明，尽管 LLM 具有令人印象深刻的能力，但在面对时间或领域变化时，它们难以有效地泛化到未来未见的数据，尤其是在面对时间或领域变化时 [6, 120, 119, 68]。此外，在适应新的时间领域时，它们难以完全保留过去经验的知识，尽管它们确实表现出更高的抗灾难性遗忘的鲁棒性 [274, 183, 365, 195]。使用复杂的持续学习算法来应对 LLM 中的挑战的必要性仍然是一个悬而未决的问题。例如，在大规模持续预训练期间，主要机构通常能够承担与保留所有历史数据相关的存储成本，从而使内存约束可以忽略不计。一些研究表明，在完全访问历史数据的情况下，简单的稀疏重放技术可以有效地减轻大型模型中的遗忘 [277, 274, 255, 228, 81]。相比之下，许多持续学习研究表明，与朴素解决方案相比，持续学习技术表现出更优越的性能，这表明持续学习技术在 LLM 训练中的重要性 [119, 127, 232, 46]。

**水平遗忘**：我们将模型在水平持续学习过程中对先前任务的性能下降非正式地定义为“水平遗忘”。如图 2 所示，水平持续学习通常涉及类似规模的训练阶段，它们的数据之间可能存在分布重叠。总而言之，解决水平遗忘提出了两个主要挑战：

- **更长的任务序列**：水平持续学习理想情况下涉及许多增量阶段，特别是要适应数据分布中的时间变化。更长的任务序列意味着模型的更多更新步骤，从而导致不可避免地遗忘先前学习的任务。为了应对这一挑战，研究人员采用了具有更强约束的既定持续学习技术，例如持续模型集成 [237]。
    
- **突然的分布变化**：与垂直连续性不同，垂直连续性中的分布变化通常是可预测的，而水平持续学习对顺序学习任务的属性没有施加约束。有证据表明，任务分布的突然变化会导致模型的严重水平遗忘 [30, 250]。
    

**4 持续学习大型语言模型的学习阶段**

图 1 提供了持续学习大型语言模型的概述。沿着垂直连续性轴，出现了现代持续学习的三个主要层。顶层，持续预训练 (CPT)，涉及供应商在与现有数据一起新收集的数据上对 LLM 进行持续的预训练（第 4.1 节）。随着数据量的增加，LLM 的一般能力自然会得到发展。中间层，领域自适应预训练 (DAP)，通过在特定领域的未标记数据上进行额外的预训练，为特定领域的应用准备 LLM（第 4.2 节）。底层，持续微调 (CFT)，针对消费者端的最终下游任务模型（第 4.3 节）。在持续微调中，我们将进一步介绍持续指令调优（第 4.3.3 节）、模型细化（第 4.3.4 节）、模型对齐（第 4.3.5 节）和多模态 LLM（第 4.3.6 节）等主题。

**4.1 持续预训练 (CPT)**

近年来，大型语言模型的发展打破了在接近人类水平的自然语言理解和生成方面的天花板。然而，有效地将这些模型适应不断变化的环境仍然是一个根本性挑战。在表 1 中，我们概述了现有 CPT 论文的基本属性。

**4.1.1 CPT：有效性和效率**

在深入介绍持续预训练 (CPT) 论文之前，重要的是要解决两个基本问题：首先，关于有效性，CPT 是否可以比在广泛数据领域进行的初始训练更能提高下游任务的性能？包括 ELLE [232]、DEMix [91]、CKL [120]、TemporalWiki [119]、LLPT [127] 和 Lifelong-MoE [46] 在内的广泛研究不仅证明了 CPT 对于提高下游性能的必要性，而且还表明，当分布变化是渐进的 [119] 或某种程度上相关的 [91] 时，CPT 可以增强模型对未见数据的泛化能力。

在确认 CPT 的有效性之后，第二个关于效率的问题出现了：考虑到 LLM 中的参数数量众多，以及新旧数据量巨大，如何以计算效率高的方式实现适应性和知识保留变得至关重要。关于效率，大多数研究侧重于有效知识保留的技术 [127, 120, 119, 149]，这与持续学习文献中解决灾难性遗忘问题的方法有很大的重叠。如前所述，这些技术包括重放 [254, 240, 29, 260]、参数正则化 [239, 241, 4] 和架构扩展 [247, 237, 287]。与之前充分利用新兴数据的方法相比，一些研究认识到这种方法在实际生产环境中的不可行性。相反，它们专注于进一步提高适应新分布的效率。例如，ELLE [232] 采用函数保留的模型扩展来促进有效的知识增长；[6] 基于语义变化水平对训练数据进行子采样，以提高训练效率；[323] 采用一种鼓励新颖性和多样性的数据采样策略，从而实现优于全数据训练的性能。尽管尚未得到充分研究，但鉴于最近的研究结果强调数据质量对于 LLM 泛化的重要性 [72, 157, 321, 267]，持续预训练中高效适应的这一方面有望变得更加重要。

**4.1.2 关于 CPT 的一般观察**

表 1 中提出的分析揭示了持续预训练 (CPT) 中普遍存在的研究趋势。首先，很明显，专门针对 CPT 开发的先进技术仍处于起步阶段，需要进一步探索。这一观察结果得到了以下事实的支持：只有大约一半的受审查论文提出了新技术（16 篇论文中的 9 篇，在表 1 的深灰色部分中表示），而剩余的一半论文要么只关注纯适应的影响而不考虑持续学习技术（16 篇论文中的 3 篇，在白色部分中表示），要么对现有持续学习技术的直接应用进行实证研究（16 篇论文中的 4 篇，在浅灰色部分中表示）。其次，虽然研究广泛涵盖了各种持续学习技术，例如重放、参数正则化和架构扩展（如表 1 浅灰色部分所示），但这些技术在系统中的实际应用仍然相对有限。大多数实际实现主要集中在 LLM 的架构扩展上 [6, 55, 91, 68, 231, 46]，只有少数明确使用重放 [231, 46] 和参数正则化 [6, 46]（表 1 深灰色部分）。第三，迫切需要探索持续预训练中更长的增量阶段序列。目前，探索的域的最长序列为八个，具有内容级别的分布变化 [127, 91]。然而，这与现实世界的场景相去甚远，在现实世界中，持续预训练可能更频繁地发生，并且持续数月或数年。在如此漫长的场景中，持续学习技术的功效仍不确定，因为在 EWC [140] 等技术中观察到随着域序列变长，性能可能会下降。此外，在无任务边界的数据流设置中研究 CPT 也是一个重要的研究方向。